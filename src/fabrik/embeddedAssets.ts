// Generated by scripts/embed-assets.ts. Do not edit.
export type EmbeddedAsset = { path: string; contents: string; mode?: number }

export const embeddedAssets: EmbeddedAsset[] = [
  { path: "smithers-runner/workflow.tsx", contents: "#!/usr/bin/env bun\n/**\n * Fabrik Sequential Workflow (Default)\n * \n * For small-to-medium specs with clear milestones.\n * Sequential task implementation with full review loop and human gate.\n * \n * Flow:\n * 1. TaskRalph (per task): Implement → Validate → LightReview → ReviewFix (loop)\n * 2. FullReviewRalph (all tasks done): AllReviewers → ReviewFix → Re-validate (loop)  \n * 3. HumanGate (needsApproval): Approve or reject → feedback → TaskRalph if rejected\n */\n\nimport { Sequence, Parallel, Branch, Ralph } from \"smithers-orchestrator\";\nimport { Workflow, Task, smithers, tables, createSmithers, type TaskContext } from \"./smithers\";\nimport { PiAgent, CodexAgent, ClaudeCodeAgent } from \"smithers-orchestrator\";\nimport { z } from \"zod\";\nimport { readFileSync, readdirSync, existsSync } from \"node:fs\";\nimport { join, resolve, basename } from \"node:path\";\n\n// Config from environment\nconst specPath = resolve(process.env.SMITHERS_SPEC_PATH || \"specs/spec.md\");\nconst isMarkdown = specPath.endsWith(\".md\") || specPath.endsWith(\".mdx\");\nconst reviewersDir = process.env.SMITHERS_REVIEWERS_DIR;\n\n// Parse spec\nfunction parseSpec(path: string) {\n  const raw = readFileSync(path, \"utf8\");\n  return {\n    id: basename(path).replace(/\\.mdx?$/, \"\").replace(/^spec[-_]/, \"\"),\n    title: raw.match(/^#\\s+(.+)$/m)?.[1]?.trim() || \"Untitled\",\n    goals: [],\n    raw: raw.slice(0, 3000),\n  };\n}\n\nconst spec = isMarkdown ? parseSpec(specPath) : JSON.parse(readFileSync(specPath, \"utf8\"));\n\n// Agent factory - Pi with JSON mode\nfunction makeAgent(tier: \"cheap\" | \"standard\" | \"powerful\") {\n  const kind = (process.env.RALPH_AGENT || \"pi\").toLowerCase();\n  const cwd = process.env.SMITHERS_CWD || process.cwd();\n  const base = { cwd };\n  \n  if (kind === \"claude\") return new ClaudeCodeAgent({ ...base, model: \"claude-opus-4\", dangerouslySkipPermissions: true });\n  if (kind === \"codex\") return new CodexAgent({ ...base, model: \"gpt-5.2-codex\", sandbox: \"danger-full-access\" });\n  \n  // Pi: Fireworks preferred, fallback to moonshot\n  const fw = process.env.FIREWORKS_API_KEY;\n  const ms = process.env.API_KEY_MOONSHOT;\n  const provider = fw ? \"fireworks\" : ms ? \"moonshot\" : undefined;\n  const model = fw ? \"fireworks/kimi-k2p5\" : ms ? \"kimi-k2.5\" : \"claude-opus-4\";\n  \n  return new PiAgent({ ...base, model, provider, mode: \"json\", noSession: true });\n}\n\n// Helpers\nconst getReviewers = (names?: string[]): string[] => {\n  if (!reviewersDir || !existsSync(reviewersDir)) return [];\n  const all = readdirSync(reviewersDir).filter(f => f.endsWith(\".md\"));\n  if (!names) return all.map(f => join(reviewersDir, f));\n  return names.map(n => join(reviewersDir, n.replace(/\\.md$/, \"\") + \".md\")).filter(existsSync);\n};\n\nconst readPrompt = (path: string) => { try { return readFileSync(path, \"utf8\"); } catch { return \"\"; } };\n\ninterface Ticket { id: string; title: string; description: string; tier: \"T1\" | \"T2\" | \"T3\" | \"T4\"; model: \"cheap\" | \"standard\" | \"powerful\"; }\n\n// Discover tasks from spec\nfunction Discover({ ctx }: { ctx: TaskContext }) {\n  return (\n    <Task id=\"discover\" output={tables.discover} agent={makeAgent(\"powerful\")}>\n      {`DISCOVER TASKS from spec: ${spec.id}\n\nBreak into sequential implementation tasks (5-10 tasks).\nEach task: coherent, testable, committable.\n\nOUTPUT JSON:\n{\n  \"v\": 1,\n  \"tickets\": [{ \"id\": \"slug\", \"title\": \"...\", \"description\": \"...\", \"tier\": \"T1|T2|T3|T4\", \"acceptanceCriteria\": [], \"dependencies\": null, \"layersRequired\": [], \"reviewsRequired\": [], \"gates\": [\"lint\",\"typecheck\",\"test\"], \"model\": \"cheap|standard|powerful\" }],\n  \"reasoning\": \"...\",\n  \"batchComplete\": true\n}`}\n    </Task>\n  );\n}\n\n// Phase 1: Per-task Ralph loop\nfunction TaskRalph({ ticket, ctx }: { ticket: Ticket; ctx: TaskContext }) {\n  const light = getReviewers([\"CODE-QUALITY.md\", \"MAINTAINABILITY.md\"]);\n  const impl = ctx.latest(tables.report, `${ticket.id}:impl`);\n  const val = ctx.latest(tables.gate, `${ticket.id}:val`);\n  const reviews = light.map((_, i) => ctx.latest(tables.report, `${ticket.id}:rv-${i}`));\n  const issues = reviews.flatMap((r, i) => r?.status === \"changes_requested\" ? [{ rev: basename(light[i]), issues: r.issues }] : []);\n  const approved = reviews.every(r => r?.status === \"approved\");\n\n  return (\n    <Ralph id={`${ticket.id}:loop`} until={approved} maxIterations={5} onMaxReached=\"return-last\">\n      <Sequence>\n        <Task id={`${ticket.id}:impl`} output={tables.report} agent={makeAgent(ticket.model)}>\n          {`IMPLEMENT: ${ticket.title}\\n${ticket.description}\\n${issues.length ? `FEEDBACK:\\n${JSON.stringify(issues)}` : \"\"}\\n1. Read spec, study codebase\\n2. Implement with tests\\n3. Run gates\\n4. Commit with reasoning\\nOUTPUT: { \"v\": 1, \"taskId\": \"${ticket.id}\", \"status\": \"done\", \"work\": [], \"files\": [], \"tests\": [], \"issues\": [], \"next\": [] }`}\n        </Task>\n\n        <Task id={`${ticket.id}:val`} output={tables.gate} agent={makeAgent(\"cheap\")}>\n          {`VALIDATE: run lint, typecheck, test\\nOUTPUT: { \"v\": 1, \"passed\": bool }`}\n        </Task>\n\n        <Branch if={val?.passed !== false} then={\n          <Parallel maxConcurrency={2}>\n            {light.map((p, i) => (\n              <Task key={i} id={`${ticket.id}:rv-${i}`} output={tables.report} agent={makeAgent(\"standard\")} continueOnFail>\n                {`${readPrompt(p)}\\nReview: ${ticket.title}\\nOUTPUT: { \"v\": 1, \"status\": \"approved|changes_requested\", \"issues\": [] }`}\n              </Task>\n            ))}\n          </Parallel>\n        } />\n      </Sequence>\n    </Ralph>\n  );\n}\n\n// Phase 2: Full review Ralph loop\nfunction FullReviewRalph({ ctx }: { ctx: TaskContext }) {\n  const all = getReviewers();\n  const names = all.map(basename);\n  const reviews = names.map((_, i) => ctx.latest(tables.report, `fr-${i}`));\n  const issues = reviews.flatMap((r, i) => r?.status === \"changes_requested\" ? [{ rev: names[i], issues: r.issues }] : []);\n  const approved = reviews.every(r => r?.status === \"approved\");\n\n  return (\n    <Ralph id=\"full-review\" until={approved} maxIterations={5} onMaxReached=\"return-last\">\n      <Sequence>\n        <Parallel maxConcurrency={8}>\n          {all.map((p, i) => (\n            <Task key={i} id={`fr-${i}`} output={tables.report} agent={makeAgent(\"standard\")} continueOnFail>\n              {`${readPrompt(p)}\\nReview entire implementation.\\nOUTPUT: { \"v\": 1, \"status\": \"approved|changes_requested\", \"issues\": [] }`}\n            </Task>\n          ))}\n        </Parallel>\n        \n        <Branch if={issues.length > 0} then={\n          <Sequence>\n            <Task id=\"full-fix\" output={tables.report} agent={makeAgent(\"powerful\")}>\n              {`FIX ALL:\\n${JSON.stringify(issues)}\\nAddress each, re-validate, commit.`}\n            </Task>\n            <Task id=\"full-reval\" output={tables.gate} agent={makeAgent(\"cheap\")}>{`Re-validate`}</Task>\n          </Sequence>\n        } />\n      </Sequence>\n    </Ralph>\n  );\n}\n\n// Phase 3: Human gate\nfunction HumanGate({ ctx }: { ctx: TaskContext }) {\n  return (\n    <Task id=\"human-gate\" output={tables.report} needsApproval label={`Approve: ${spec.id}`}>\n      {`HUMAN REVIEW: ${spec.id}\\n\\nAll automated reviews passed.\\nReview implementation and VCS history.\\nApprove or reject with feedback.`}\n    </Task>\n  );\n}\n\n// Main\nexport default smithers((ctx) => {\n  const discover = ctx.latest(tables.discover, \"discover\");\n  const tickets: Ticket[] = discover?.tickets || [];\n  const allDone = tickets.length > 0 && tickets.every(t => ctx.latest(tables.report, `${t.id}:impl`)?.status === \"done\");\n  const fullReview = ctx.latest(tables.report, \"fr-0\") !== undefined;\n  const human = ctx.latest(tables.report, \"human-gate\");\n\n  return (\n    <Workflow name={spec.id}>\n      <Sequence>\n        <Branch if={!tickets.length} then={<Discover ctx={ctx} />} />\n        {tickets.map(t => <TaskRalph key={t.id} ticket={t} ctx={ctx} />)}\n        <Branch if={allDone && !fullReview} then={<FullReviewRalph ctx={ctx} />} />\n        <Branch if={allDone && fullReview} then={<HumanGate ctx={ctx} />} />\n        <Branch if={human?.status === \"approved\"} then={<Task id=\"done\" output={tables.report}>{{ v: 1, status: \"done\", work: [\"Complete\"] }}</Task>} />\n      </Sequence>\n    </Workflow>\n  );\n});\n" },
  { path: "smithers-runner/workflow-dynamic.tsx", contents: "#!/usr/bin/env bun\n/**\n * Fabrik Dynamic Workflow\n * \n * Runtime ticket discovery for large evolving projects.\n * Discovers 3-5 tickets at a time, implements them, then discovers next batch.\n * \n * Flow:\n * 1. Discover tickets from spec (3-5 at a time)\n * 2. TaskPipeline per ticket (Implement → Validate → LightReview)\n * 3. When all done, loop back to Discover for next batch\n * 4. When batchComplete, FullReview → HumanGate\n */\n\nimport { Sequence, Parallel, Branch, Ralph } from \"smithers-orchestrator\";\nimport { Workflow, Task, smithers, tables, createSmithers, type TaskContext } from \"./smithers\";\nimport { PiAgent, CodexAgent, ClaudeCodeAgent } from \"smithers-orchestrator\";\nimport { z } from \"zod\";\nimport { readFileSync, readdirSync, existsSync } from \"node:fs\";\nimport { join, resolve, basename } from \"node:path\";\n\n// Load spec\nconst specPath = resolve(process.env.SMITHERS_SPEC_PATH || \"specs/spec.md\");\nconst isMarkdown = specPath.endsWith(\".md\") || specPath.endsWith(\".mdx\");\nconst reviewersDir = process.env.SMITHERS_REVIEWERS_DIR;\n\nfunction parseSpec(path: string) {\n  const raw = readFileSync(path, \"utf8\");\n  return {\n    id: basename(path).replace(/\\.mdx?$/, \"\").replace(/^spec[-_]/, \"\"),\n    title: raw.match(/^#\\s+(.+)$/m)?.[1]?.trim() || \"Untitled\",\n    raw,\n  };\n}\n\nconst spec = isMarkdown ? parseSpec(specPath) : JSON.parse(readFileSync(specPath, \"utf8\"));\n\n// Agent factory\nfunction makeAgent(tier: \"cheap\" | \"standard\" | \"powerful\") {\n  const kind = (process.env.RALPH_AGENT || \"pi\").toLowerCase();\n  const cwd = process.env.SMITHERS_CWD || process.cwd();\n  const baseOpts = { cwd };\n  \n  switch (kind) {\n    case \"claude\": return new ClaudeCodeAgent({ ...baseOpts, model: \"claude-opus-4\", dangerouslySkipPermissions: true });\n    case \"codex\": return new CodexAgent({ ...baseOpts, model: \"gpt-5.2-codex\", sandbox: \"danger-full-access\" });\n    default: \n      const key = process.env.FIREWORKS_API_KEY || process.env.API_KEY_MOONSHOT;\n      const provider = process.env.FIREWORKS_API_KEY ? \"fireworks\" : \"moonshot\";\n      const model = provider === \"fireworks\" ? \"fireworks/kimi-k2p5\" : \"kimi-k2.5\";\n      return new PiAgent({ ...baseOpts, model, provider, mode: \"json\", noSession: true });\n  }\n}\n\nconst getReviewers = (names?: string[]): string[] => {\n  if (!reviewersDir || !existsSync(reviewersDir)) return [];\n  const all = readdirSync(reviewersDir).filter(f => f.endsWith(\".md\"));\n  if (!names) return all.map(f => join(reviewersDir, f));\n  return names.map(n => join(reviewersDir, n)).filter(p => existsSync(p));\n};\n\nconst readPrompt = (path: string) => {\n  try { return readFileSync(path, \"utf8\"); } catch { return \"\"; }\n};\n\n// Types\ninterface Ticket {\n  id: string;\n  title: string;\n  description: string;\n  tier: \"T1\" | \"T2\" | \"T3\" | \"T4\";\n}\n\n// Discover: Generate next batch of tickets\nfunction Discover({ ctx }: { ctx: TaskContext }) {\n  const prev = ctx.latest(tables.discover, \"discover\");\n  const completed = prev?.tickets?.filter((t: Ticket) => \n    ctx.latest(tables.report, `${t.id}:report`)\n  )?.map((t: Ticket) => t.id) || [];\n\n  return (\n    <Task id=\"discover\" output={tables.discover} agent={makeAgent(\"powerful\")}>\n      {`DISCOVER NEXT TICKETS\n\nSpec: ${spec.id}\n${completed.length > 0 ? `Completed: ${completed.join(\", \")}` : \"Starting fresh\"}\n\nAnalyze the spec and generate the next 3-5 implementation tickets.\nEach ticket should be:\n- Small enough to implement in one coherent session\n- Testable with clear acceptance criteria  \n- Independent (minimal dependencies on other tickets)\n\nOUTPUT JSON:\n{\n  \"v\": 1,\n  \"tickets\": [\n    {\n      \"id\": \"kebab-case-slug\",\n      \"title\": \"Imperative action description\",\n      \"description\": \"Detailed what and why\",\n      \"tier\": \"T1|T2|T3|T4\",\n      \"acceptanceCriteria\": [\"criteria\"],\n      \"dependencies\": null,\n      \"layersRequired\": [\"L1\",\"L2\"],\n      \"reviewsRequired\": [\"CODE-QUALITY\",\"MAINTAINABILITY\"],\n      \"gates\": [\"lint\",\"typecheck\",\"test\"],\n      \"model\": \"cheap|standard|powerful\"\n    }\n  ],\n  \"reasoning\": \"Why these tickets, in this order\",\n  \"batchComplete\": boolean\n}\n\nSet batchComplete=true when ALL work for this spec is done.`}\n    </Task>\n  );\n}\n\n// TaskPipeline: Single ticket through implement → validate → review\nfunction TaskPipeline({ ticket, ctx }: { ticket: Ticket; ctx: TaskContext }) {\n  const lightReviewers = [\"CODE-QUALITY.md\", \"MAINTAINABILITY.md\"];\n  const reviewerPaths = getReviewers(lightReviewers);\n  \n  const impl = ctx.latest(tables.report, `${ticket.id}:implement`);\n  const val = ctx.latest(tables.gate, `${ticket.id}:validate`);\n  const reviews = reviewerPaths.map((p, i) => ctx.latest(tables.report, `${ticket.id}:review-${i}`));\n  \n  const allApproved = reviews.every(r => r?.status === \"approved\");\n  const issues = reviews.flatMap((r, i) => \n    r?.status === \"changes_requested\" ? [{ reviewer: lightReviewers[i], issues: r.issues }] : []\n  );\n\n  return (\n    <Ralph id={`${ticket.id}:loop`} until={allApproved} maxIterations={5} onMaxReached=\"return-last\">\n      <Sequence>\n        {/* Implement */}\n        <Task id={`${ticket.id}:implement`} output={tables.report} agent={makeAgent(ticket.model)}>\n          {`IMPLEMENT: ${ticket.title}\n\n${ticket.description}\n\n${issues.length > 0 ? `PREVIOUS FEEDBACK:\\n${JSON.stringify(issues, null, 2)}\\n\\nAddress ALL issues.` : \"\"}\n\n1. Read spec, study codebase patterns\n2. Implement completely\n3. Run lint, typecheck, tests\n4. Commit with reasoning traces\n\nOUTPUT JSON:\n{ \"v\": 1, \"taskId\": \"${ticket.id}\", \"tier\": \"${ticket.tier}\", \"status\": \"done\", \"work\": [], \"files\": [], \"tests\": [], \"gates\": [], \"issues\": [], \"next\": [] }`}\n        </Task>\n\n        {/* Validate */}\n        <Task id={`${ticket.id}:validate`} output={tables.gate} agent={makeAgent(\"cheap\")}>\n          {`VALIDATE: ${ticket.title}\nRun: bun run lint && bun run typecheck && bun run test\nOUTPUT JSON: { \"v\": 1, \"passed\": boolean, \"command\": \"...\", \"output\": \"...\", \"durationMs\": number }`}\n        </Task>\n\n        {/* Light Review */}\n        <Branch if={val?.passed !== false} then={\n          <Parallel maxConcurrency={2}>\n            {reviewerPaths.map((path, i) => (\n              <Task key={i} id={`${ticket.id}:review-${i}`} output={tables.report} agent={makeAgent(\"standard\")} continueOnFail>\n                {`${readPrompt(path)}\\n\\nReview: ${ticket.title}\\nOUTPUT JSON: { \"v\": 1, \"taskId\": \"${ticket.id}\", \"status\": \"approved|changes_requested\", \"issues\": [], \"next\": [] }`}\n              </Task>\n            ))}\n          </Parallel>\n        } />\n\n        {/* ReviewFix if needed */}\n        <Branch if={issues.length > 0} then={\n          <Task id={`${ticket.id}:fix`} output={tables.report} agent={makeAgent(\"powerful\")}>\n            {`FIX: ${ticket.title}\\n\\nIssues: ${JSON.stringify(issues)}\\n\\nAddress all, re-validate, commit.`}\n          </Task>\n        } />\n      </Sequence>\n    </Ralph>\n  );\n}\n\n// FullReview: All reviewers after all tickets done\nfunction FullReview({ ctx }: { ctx: TaskContext }) {\n  const allReviewers = getReviewers();\n  const reviewerNames = allReviewers.map(p => basename(p));\n  const reviews = reviewerNames.map((n, i) => ctx.latest(tables.report, `full-review-${i}`));\n  const allApproved = reviews.every(r => r?.status === \"approved\");\n  const issues = reviews.flatMap((r, i) => r?.status === \"changes_requested\" ? [{ reviewer: reviewerNames[i], issues: r.issues }] : []);\n\n  return (\n    <Ralph id=\"full-review\" until={allApproved} maxIterations={5} onMaxReached=\"return-last\">\n      <Sequence>\n        <Parallel maxConcurrency={8}>\n          {allReviewers.map((path, i) => (\n            <Task key={i} id={`full-review-${i}`} output={tables.report} agent={makeAgent(\"standard\")} continueOnFail>\n              {`${readPrompt(path)}\\n\\nReview entire spec implementation.\\nOUTPUT JSON: { \"v\": 1, \"status\": \"approved|changes_requested\", \"issues\": [] }`}\n            </Task>\n          ))}\n        </Parallel>\n        \n        <Branch if={issues.length > 0} then={\n          <Sequence>\n            <Task id=\"full-fix\" output={tables.report} agent={makeAgent(\"powerful\")}>\n              {`FIX ALL REVIEWER ISSUES:\\n${JSON.stringify(issues)}\\n\\nAddress each, re-validate all, commit.`}\n            </Task>\n            <Task id=\"full-revalidate\" output={tables.gate} agent={makeAgent(\"cheap\")}>\n              {`Re-validate after fixes. OUTPUT JSON: { \"v\": 1, \"passed\": boolean }`}\n            </Task>\n          </Sequence>\n        } />\n      </Sequence>\n    </Ralph>\n  );\n}\n\n// HumanGate: Final approval\nfunction HumanGate({ ctx }: { ctx: TaskContext }) {\n  return (\n    <Task id=\"human-gate\" output={tables.report} needsApproval label={`Approve: ${spec.id}`}>\n      {`HUMAN REVIEW: ${spec.id}\\n\\nAll automated reviews passed.\\nReview implementation and commit history.\\nApprove or provide feedback for fixes.`}\n    </Task>\n  );\n}\n\n// Main workflow\nexport default smithers((ctx) => {\n  const discover = ctx.latest(tables.discover, \"discover\");\n  const tickets: Ticket[] = discover?.tickets || [];\n  const batchComplete = discover?.batchComplete || false;\n  \n  const unfinished = tickets.filter((t: Ticket) => !ctx.latest(tables.report, `${t.id}:report`));\n  const allTicketsDone = tickets.length > 0 && unfinished.length === 0;\n  \n  const fullReviewDone = ctx.latest(tables.report, \"full-review-0\") !== undefined;\n  const humanGate = ctx.latest(tables.report, \"human-gate\");\n\n  return (\n    <Workflow name={`dynamic-${spec.id}`}>\n      <Sequence>\n        {/* Discover next batch */}\n        <Branch if={unfinished.length === 0 && !batchComplete} then={<Discover ctx={ctx} />} />\n        \n        {/* Process all tickets in batch */}\n        {unfinished.map((t: Ticket) => <TaskPipeline key={t.id} ticket={t} ctx={ctx} />)}\n        \n        {/* Full review when batch complete */}\n        <Branch if={batchComplete && allTicketsDone && !fullReviewDone} then={<FullReview ctx={ctx} />} />\n        \n        {/* Human gate */}\n        <Branch if={batchComplete && fullReviewDone} then={<HumanGate ctx={ctx} />} />\n        \n        {/* Complete */}\n        <Branch if={humanGate?.status === \"approved\"} then={\n          <Task id=\"complete\" output={tables.report}>{{ v: 1, taskId: \"done\", status: \"done\", work: [\"Complete\"] }}</Task>\n        } />\n      </Sequence>\n    </Workflow>\n  );\n});\n" },
  { path: "smithers-runner/smithers.ts", contents: "/**\n * Smithers Setup\n * \n * Central configuration for all smithers components.\n * Import from here, not directly from smithers-orchestrator.\n */\n\nimport { createSmithers } from \"smithers-orchestrator\";\nimport { z } from \"zod\";\n\n// Define output schemas for type safety\nexport const outputSchemas = {\n  discover: z.object({\n    v: z.literal(1),\n    tickets: z.array(z.object({\n      id: z.string(),\n      title: z.string(),\n      tier: z.enum([\"T1\", \"T2\", \"T3\", \"T4\"]),\n      description: z.string(),\n      acceptanceCriteria: z.array(z.string()),\n      dependencies: z.array(z.string()).nullable(),\n      layersRequired: z.array(z.enum([\"L1\", \"L2\", \"L3\", \"L4\", \"L5\", \"L6\"])),\n      reviewsRequired: z.array(z.string()),\n      gates: z.array(z.enum([\"lint\", \"typecheck\", \"build\", \"test\", \"coverage\"])),\n      model: z.enum([\"cheap\", \"standard\", \"powerful\"]),\n    })).max(5),\n    reasoning: z.string(),\n    batchComplete: z.boolean(),\n  }),\n  \n  gate: z.object({\n    v: z.literal(1),\n    passed: z.boolean(),\n    command: z.string(),\n    output: z.string(),\n    durationMs: z.number(),\n  }),\n  \n  report: z.object({\n    v: z.literal(1),\n    taskId: z.string(),\n    tier: z.string(),\n    status: z.enum([\"done\", \"blocked\", \"failed\"]),\n    work: z.array(z.string()),\n    files: z.array(z.string()),\n    tests: z.array(z.string()),\n    gates: z.array(z.any()),\n    issues: z.array(z.string()),\n    next: z.array(z.string()),\n  }),\n  \n  finalReview: z.object({\n    v: z.number(),\n    reviewer: z.string().optional(),\n    status: z.enum([\"approved\", \"changes_requested\"]),\n    issues: z.array(z.string()).optional(),\n    next: z.array(z.string()).optional(),\n    reviewers: z.array(z.string()).optional(),\n    approvedBy: z.array(z.string()).optional(),\n    rejectedBy: z.array(z.string()).optional(),\n    allIssues: z.array(z.string()).optional(),\n    summary: z.string().optional(),\n  }),\n};\n\n// Create smithers instance\nexport const { Workflow, Task, smithers, tables, db } = createSmithers(\n  outputSchemas,\n  { dbPath: process.env.SMITHERS_DB_PATH || \"./.smithers/workflow.db\" }\n);\n\n// Re-export createSmithers for validation\nexport { createSmithers };\n\n// Re-export types\nexport type { TaskContext } from \"smithers-orchestrator\";\n" },
  { path: "smithers-runner/package.json", contents: "{\n  \"name\": \"fabrik-smithers-runner\",\n  \"type\": \"module\",\n  \"scripts\": {\n    \"start\": \"bun run workflow.tsx\",\n    \"resume\": \"smithers resume workflow.tsx\",\n    \"discover\": \"bun run discover.ts\"\n  },\n  \"dependencies\": {\n    \"smithers-orchestrator\": \"github:evmts/smithers#ea5ece3\",\n    \"react\": \"^19.2.4\",\n    \"react-dom\": \"^19.2.4\",\n    \"zod\": \"^4.3.6\"\n  }\n}\n" },
  { path: "scripts/validate-specs.ts", contents: "import { readdir, readFile, stat } from \"node:fs/promises\"\nimport { join } from \"node:path\"\n\nconst isJson = (name: string) => name.endsWith(\".json\") && !name.endsWith(\".min.json\")\n\nconst isStringArray = (value: unknown): value is string[] =>\n  Array.isArray(value) && value.every((item) => typeof item === \"string\")\n\nconst onlyKeys = (obj: object, keys: string[]) =>\n  Object.keys(obj).every((key) => keys.includes(key))\n\nconst validateSpec = (file: string, obj: Record<string, unknown>, errors: string[]) => {\n  const keys = [\n    \"v\",\n    \"id\",\n    \"title\",\n    \"status\",\n    \"version\",\n    \"lastUpdated\",\n    \"supersedes\",\n    \"dependsOn\",\n    \"goals\",\n    \"nonGoals\",\n    \"req\",\n    \"cfg\",\n    \"accept\",\n    \"assume\"\n  ]\n\n  if (!onlyKeys(obj, keys)) {\n    errors.push(`${file}: unexpected top-level keys`)\n  }\n\n  for (const key of [\"v\", \"id\", \"title\", \"status\", \"version\", \"lastUpdated\", \"goals\", \"nonGoals\", \"req\", \"accept\", \"assume\"]) {\n    if (!(key in obj)) {\n      errors.push(`${file}: missing ${key}`)\n    }\n  }\n\n  if (obj.v !== 1) errors.push(`${file}: v must be 1`)\n  for (const key of [\"id\", \"title\", \"status\", \"version\", \"lastUpdated\"]) {\n    if (typeof obj[key] !== \"string\") errors.push(`${file}: ${key} must be string`)\n  }\n\n  for (const key of [\"supersedes\", \"dependsOn\", \"goals\", \"nonGoals\", \"accept\", \"assume\"]) {\n    const value = obj[key]\n    if (value !== undefined && !isStringArray(value)) {\n      errors.push(`${file}: ${key} must be string[]`)\n    }\n  }\n\n  const req = obj.req\n  if (typeof req !== \"object\" || req === null) {\n    errors.push(`${file}: req must be object`)\n  } else {\n    const reqKeys = [\"api\", \"behavior\", \"obs\"]\n    if (!onlyKeys(req, reqKeys)) errors.push(`${file}: req has unexpected keys`)\n    for (const key of reqKeys) {\n      const value = (req as Record<string, unknown>)[key]\n      if (value === undefined) errors.push(`${file}: req missing ${key}`)\n      else if (!isStringArray(value)) errors.push(`${file}: req.${key} must be string[]`)\n    }\n  }\n\n  const cfg = obj.cfg\n  if (cfg !== undefined) {\n    if (typeof cfg !== \"object\" || cfg === null) {\n      errors.push(`${file}: cfg must be object`)\n    } else {\n      const cfgKeys = [\"env\"]\n      if (!onlyKeys(cfg, cfgKeys)) errors.push(`${file}: cfg has unexpected keys`)\n      const env = (cfg as Record<string, unknown>).env\n      if (env !== undefined && !isStringArray(env)) errors.push(`${file}: cfg.env must be string[]`)\n    }\n  }\n}\n\nconst validateTodo = (file: string, obj: Record<string, unknown>, errors: string[]) => {\n  const keys = [\"v\", \"id\", \"tdd\", \"dod\", \"tasks\"]\n  if (!onlyKeys(obj, keys)) errors.push(`${file}: unexpected top-level keys`)\n  for (const key of keys) {\n    if (!(key in obj)) errors.push(`${file}: missing ${key}`)\n  }\n  if (obj.v !== 1) errors.push(`${file}: v must be 1`)\n  if (typeof obj.id !== \"string\") errors.push(`${file}: id must be string`)\n  if (typeof obj.tdd !== \"boolean\") errors.push(`${file}: tdd must be boolean`)\n  if (!isStringArray(obj.dod)) errors.push(`${file}: dod must be string[]`)\n\n  if (!Array.isArray(obj.tasks)) {\n    errors.push(`${file}: tasks must be array`)\n  } else {\n    for (const [index, task] of obj.tasks.entries()) {\n      if (typeof task !== \"object\" || task === null) {\n        errors.push(`${file}: tasks[${index}] must be object`)\n        continue\n      }\n      const taskKeys = [\"id\", \"do\", \"verify\"]\n      if (!onlyKeys(task, taskKeys)) errors.push(`${file}: tasks[${index}] unexpected keys`)\n      for (const key of taskKeys) {\n        const value = (task as Record<string, unknown>)[key]\n        if (value === undefined) errors.push(`${file}: tasks[${index}] missing ${key}`)\n        else if (typeof value !== \"string\") errors.push(`${file}: tasks[${index}].${key} must be string`)\n      }\n    }\n  }\n}\n\nconst validateDir = async (dir: string) => {\n  const entries = await readdir(dir)\n  const errors: string[] = []\n\n  for (const entry of entries) {\n    const fullPath = join(dir, entry)\n    const info = await stat(fullPath)\n    if (!info.isFile()) continue\n    if (!isJson(entry)) continue\n\n    const raw = await readFile(fullPath, \"utf8\")\n    const json = JSON.parse(raw) as Record<string, unknown>\n    if (entry.endsWith(\".todo.json\")) validateTodo(entry, json, errors)\n    else validateSpec(entry, json, errors)\n  }\n\n  if (errors.length > 0) {\n    console.error(`Schema validation errors:\\n${errors.join(\"\\n\")}`)\n    process.exit(1)\n  }\n\n  console.log(\"All spec/todo JSON files passed schema checks.\")\n}\n\nconst target = process.argv[2] ?? \"specs\"\n\nvalidateDir(target).catch((error) => {\n  console.error(error)\n  process.exit(1)\n})\n" },
  { path: "scripts/minify-specs.ts", contents: "import { readdir, readFile, writeFile, stat } from \"node:fs/promises\"\nimport { join } from \"node:path\"\n\nconst isJson = (name: string) => name.endsWith(\".json\") && !name.endsWith(\".min.json\")\n\nconst minifyFile = async (filePath: string) => {\n  const raw = await readFile(filePath, \"utf8\")\n  const json = JSON.parse(raw)\n  const minPath = filePath.replace(/\\.json$/, \".min.json\")\n  await writeFile(minPath, JSON.stringify(json), \"utf8\")\n}\n\nconst minifyDir = async (dir: string) => {\n  const entries = await readdir(dir)\n  for (const entry of entries) {\n    const fullPath = join(dir, entry)\n    const info = await stat(fullPath)\n    if (!info.isFile()) {\n      continue\n    }\n    if (isJson(entry)) {\n      await minifyFile(fullPath)\n    }\n  }\n}\n\nconst target = process.argv[2] ?? \"specs\"\n\nminifyDir(target)\n  .then(() => {\n    console.log(`Minified JSON in ${target}`)\n  })\n  .catch((error) => {\n    console.error(error)\n    process.exit(1)\n  })\n" },
  { path: "prompts/DEFAULT-IMPLEMENTER.md", contents: "# Default Implementer Prompt\n\nStudy /docs to become familiar with the codebase architecture.\n\nStudy the spec and todo JSON to learn the goal at hand.\n\nLook at recent commits to see what has been done.\n\nPick the most important task from the TODO list for implementation of the spec and implement that. Focus on completion of that task. If you encounter blocking errors, fix them, verify them, commit them, get the task done.\n\nBefore making changes search codebase (don't assume an item is not implemented) using parallel subagents. Think hard.\n\nWrite tests, verify your work builds, run the dev server (you can access the logs) and use chrome dev tools mcp to check the website at the very end, going through the user flow.\n\nImportant: When authoring documentation (ie. ts doc, tests or documentation) capture the why tests and the backing implementation is important.\n\nAfter implementing functionality or resolving problems, run the tests for that unit of code that was improved.\nWhen all tests and verifications pass commit your work. If functionality is missing then it's your job to add it as per the application specifications.\n\nCommit message rules:\n- Use Conventional Commits: type(scope): subject\n- Include spec id, todo id, and run id in the message body or trailer\n- When debugging/fixing root causes, include: cause → reasoning → fix, plus relevant error output\n- If `jj git push --bookmark <branch>` fails with \"Refusing to create new remote bookmark\", run:\n  `jj bookmark track <branch> --remote=origin` then retry push\n- Avoid literal `\\n` in commit messages. Use a proper multi-line body:\n  - Preferred: `jj describe -m \"$(cat <<'EOF'\\n<subject>\\n\\n<trailers>\\nEOF\\n)\"`\n  - Or: `printf '%s\\n\\n%s\\n' \"<subject>\" \"<trailers>\" | jj describe -m -`\n- Example:\n  feat(spec-020-fabrik-v0-2-0): implement dispatch auth\n  \n  todo: git-credentials-vm\n  spec: 020-fabrik-v0-2-0\n  run: 20260203T120945Z\n  cause: GH auth relied on host keychain; VM had no token\n  reasoning: VM needs env-based auth; ralph.env already contains GITHUB_TOKEN\n  fix: source ralph.env and export GH_TOKEN during dispatch\n  error: gh auth status -> \"token in default is invalid\"\n\nUpdate the TODO.md file noting what has been done, attach a screenshot of the UI confirming it's done for frontend changes.\n" },
  { path: "prompts/DEFAULT-REVIEWER.md", contents: "# Default Reviewer Prompt\n\nReview the implementation against the spec and todo. Focus on:\n\n- Correctness and completeness\n- Tests and verification steps\n- Security risks and edge cases\n- Strict spec compliance\n\nConfirm changes were pushed to the single spec branch/bookmark (no `push-*` branches).\nCheck commit messages follow Conventional Commits and include spec/todo/run plus root-cause notes when relevant.\nVerify task reports include rootCause/reasoning/fix/error/commit when applicable.\n\nReport issues clearly and suggest next steps.\n" },
  { path: "prompts/reviewers/SECURITY.md", contents: "# Security Reviewer\n\nReview for security vulnerabilities and best practices.\n\n## Checklist\n\n- [ ] No hardcoded secrets or credentials in code\n- [ ] Input validation at all entry points (prevent injection)\n- [ ] Proper error handling (no information leakage in error messages)\n- [ ] Authentication/authorization checks where applicable\n- [ ] Secure defaults (deny by default, least privilege)\n- [ ] No SQL injection vectors (parameterized queries only)\n- [ ] No XSS vulnerabilities (output encoding where needed)\n- [ ] Dependencies are up to date (no known CVEs)\n- [ ] Sensitive data encrypted at rest and in transit\n- [ ] Audit logging for sensitive operations\n\n## Effect-TS Specific\n\n- [ ] Effect error channels don't leak sensitive internals\n- [ ] Service requirements properly scoped (least privilege)\n- [ ] No direct Promise rejection exposure\n\nFlag any security issue as `changes_requested` with severity:\n- `CRITICAL`: Data breach, auth bypass, injection vulnerability\n- `HIGH`: Potential security risk with clear exploitation path\n- `MEDIUM`: Defense in depth improvement recommended\n" },
  { path: "prompts/reviewers/CODE-QUALITY.md", contents: "# Code Quality Reviewer\n\nReview for general code quality, readability, and maintainability fundamentals.\n\n## Checklist\n\n- [ ] Functions are focused and single-purpose (SRP)\n- [ ] Variable names are descriptive and intent-revealing\n- [ ] No magic numbers or strings (use named constants)\n- [ ] Consistent formatting and style\n- [ ] Comments explain WHY, not WHAT (code should be self-documenting)\n- [ ] No dead code or unused imports\n- [ ] Error handling is comprehensive, not just happy-path\n- [ ] No deeply nested conditionals (prefer early returns)\n- [ ] Async code properly handled (no floating Promises)\n\n## TypeScript Specific\n\n- [ ] Strict typing enabled (no `any`, minimal `unknown` with validation)\n- [ ] Type inference used appropriately (not over-typed)\n- [ ] Generics used correctly (not over-engineered)\n- [ ] Null/undefined handling explicit (Option/Maybe types preferred)\n\n## Effect-TS Specific\n\n- [ ] Effects are composed, not nested\n- [ ] Error channels are explicit and handled\n- [ ] Resource management uses Scope/acquireRelease\n- [ ] No Effect.runPromise in library code\n\nFlag quality issues as `changes_requested` or `approved` with suggestions.\n" },
  { path: "prompts/reviewers/SIMPLICITY.md", contents: "# Minimal Simplicity Reviewer\n\nReview against \"simple is better than complex\" principles. Code should be as simple as possible, but no simpler.\n\n## Tigerstyle Alignment\n\n1. **DENSITY**: Is the code concise without being cryptic?\n   - One idea per line\n   - No unnecessary abstraction layers\n   - Remove boilerplate and ceremony\n\n2. **LOCALITY**: Are related concepts close together?\n   - No jumps across files for understanding\n   - Cohesive functions and modules\n   - Minimize cognitive distance\n\n3. **EXPLICITNESS**: Are all side effects visible?\n   - No hidden control flow\n   - No magic conventions\n   - Dependencies explicitly declared\n\n## Anti-Patterns to Flag\n\n- [ ] Over-engineering: Abstract factories for simple cases\n- [ ] Premature optimization: Complex caching for unclear benefit\n- [ ] Deep inheritance hierarchies (prefer composition)\n- [ ] Unnecessary indirection (interface with single implementation)\n- [ ] \"Enterprise\" patterns applied where functions suffice\n\n## Approval Criteria\n\n- Could a junior developer understand this in 5 minutes?\n- Is there a shorter way to express this intent?\n- Are we solving the problem we have, not might have?\n\nFlag complexity without justification as `changes_requested`.\n" },
  { path: "prompts/reviewers/TEST-COVERAGE.md", contents: "# Test Coverage Reviewer\n\nReview for comprehensive testing strategy and test quality.\n\n## Layer 4 (L4) Requirements\n\n### Unit Tests\n- [ ] Happy path covered for all public functions\n- [ ] Edge cases identified and tested (empty inputs, boundaries)\n- [ ] Error paths tested (Effect failure branches)\n- [ ] No tests that just \"pass through\" without verification\n\n### Property-Based Tests (Critical)\n- [ ] Invariants have `@property` TSDoc comments with names\n- [ ] Property tests for:\n  - **Conservation**: Nothing created/destroyed (e.g., money, tokens)\n  - **Idempotency**: Same input → same output (deterministic)\n  - **Commutativity**: Order doesn't matter for independent ops\n  - **Associativity**: Grouping doesn't affect result\n\n### Integration Tests\n- [ ] End-to-end flows work with real (or test) services\n- [ ] Database constraints actually enforced (test failures)\n- [ ] External API boundaries handled correctly\n\n### Effect-TS Testing\n- [ ] `Effect.TestClock` used for time-dependent logic\n- [ ] `TestContext` provided for all service dependencies\n- [ ] Both success and failure branches in Effect pipelines tested\n\n## T1/T2 Specific\n\nFor T1 (Critical) and T2 (Important) code:\n- [ ] Every invariant named and tested\n- [ ] Database constraints verified (try to violate them, confirm rejection)\n- [ ] Failure scenarios enumerated and covered\n\n## Measurement\n\n- Line coverage ≥ 80% (T3/T4), ≥ 90% (T1/T2)\n- Branch coverage ≥ 70% (T3/T4), ≥ 85% (T1/T2)\n- Invariant coverage: 100% (every @property has a test)\n\nFlag missing test coverage as `changes_requested` for critical paths.\n" },
  { path: "prompts/reviewers/MAINTAINABILITY.md", contents: "# Maintainability Reviewer\n\nReview for long-term code health and team scalability.\n\n## Documentation\n\n- [ ] README or module docs explain the \"why\" and \"how\"\n- [ ] Complex business logic has context comments\n- [ ] API changes documented (breaking vs non-breaking)\n- [ ] Architecture Decision Records (ADRs) for major choices\n\n## Code Organization\n\n- [ ] Clear module boundaries (high cohesion, low coupling)\n- [ ] Public API surface is minimal and intentional\n- [ ] Internal modules marked/separated from public\n- [ ] No circular dependencies\n\n## Observability\n\n- [ ] Structured logging for important operations\n- [ ] Error contexts include actionable information\n- [ ] Metrics/TODOs documented for production (L5 preparation)\n\n## Onboarding\n\n- [ ] New developer could fix a bug in this code within 1 hour\n- [ ] No tribal knowledge required (all context in code/docs)\n- [ ] Examples provided for complex operations\n\n## Effect-TS Specific\n\n- [ ] Service interfaces are stable and well-documented\n- [ ] Error types are actionable (contain debugging context)\n- [ ] Resource lifecycles are clear and documented\n\n## Versioning\n\n- [ ] Breaking changes explicitly identified\n- [ ] Migration path provided for API changes\n\nFlag maintainability issues as `approved` with suggestions (not blocking unless severe).\n" },
  { path: "prompts/reviewers/TIGERSTYLE.md", contents: "# Tigerstyle Audit Reviewer\n\nReview against Tigerstyle principles: code should be consistent, explicit, dense, and defensive.\n\n## Core Principles\n\n### 1. CONSISTENCY\n- [ ] Code follows established patterns (no exceptions without justification)\n- [ ] Naming conventions consistent across codebase\n- [ ] Structure mirrors similar modules elsewhere\n- [ ] \"One way to do it\" - no arbitrary variation\n\n### 2. EXPLICITNESS\n- [ ] All side effects visible (no hidden mutations)\n- [ ] Imports/dependencies explicit (no implicit globals)\n- [ ] Control flow obvious (no magic, no surprises)\n- [ ] Configuration explicit (not scattered across files)\n\n### 3. DENSITY\n- [ ] One idea per line\n- [ ] No unnecessary ceremony or boilerplate\n- [ ] Concise but not cryptic (clarity > brevity, but both matter)\n- [ ] Remove comments that just restate code\n\n### 4. LOCALITY\n- [ ] Related concepts close together (same file/section)\n- [ ] No jumping across files to understand a flow\n- [ ] Cohesive modules (high cohesion, low coupling)\n- [ ] Temporal locality: setup/use/teardown close together\n\n## Defensive Structure\n\n### 5. FAIL FAST\n- [ ] Guard clauses at function entry (validate early)\n- [ ] Assertions for invariants (Effect.assert, not comments)\n- [ ] No silent failures (all errors explicit)\n- [ ] Invalid states prevented, not handled\n\n### 6. IMMUTABILITY\n- [ ] Prefer `const` over `let`\n- [ ] Mutations explicit and localized\n- [ ] Data transformations return new values\n- [ ] No shared mutable state (use Effect's concurrency primitives)\n\n### 7. TYPE SAFETY\n- [ ] Branded types for domain values (no primitive obsession)\n- [ ] Phantom types for state machines (invalid states unrepresentable)\n- [ ] No `any` (use `unknown` with validation if needed)\n- [ ] Exhaustive matching for all unions\n\n## Composability\n\n### 8. FUNCTION COMPOSITION\n- [ ] Functions return Effects for chaining\n- [ ] Single responsibility (do one thing, do it well)\n- [ ] Pure functions where possible (testable, predictable)\n- [ ] Dependencies injected, not hardcoded\n\n### 9. RESOURCE SAFETY\n- [ ] Resources acquired and released properly\n- [ ] Scope management for lifecycles\n- [ ] No resource leaks (connections, file handles)\n- [ ] Cleanup in error paths (Effect.acquireRelease)\n\n### 10. OBSERVABILITY\n- [ ] Errors typed (not thrown exceptions)\n- [ ] Tracing/debugging possible without breakpoints\n- [ ] Context preserved in error chains\n\n## Severity Levels\n\n- `CRITICAL`: Type safety violation, hidden mutation, resource leak\n- `WARNING`: Consistency issue, density problem\n- `SUGGESTION`: Style preference\n\nFlag ANY Tigerstyle violation as `changes_requested` with specific line references.\n" },
  { path: "prompts/reviewers/CORRECTNESS-GUARANTEES.md", contents: "# Correctness & Invariant Validation Reviewer\n\nReview for code correctness through layered guarantees. Applies to ALL critical invariants, not just billing (which is one example of T1 code).\n\n## Step 1: Classify Criticality Tier\n\n| Tier | Examples | Layers Required |\n|------|----------|-----------------|\n| **T1 (Critical)** | Money, access control, signing, auth tokens, irreversible state changes | **ALL 6** (L1-L5 + Simulation) |\n| **T2 (Important)** | User data, business logic, state machines, queues | **L1-L5** (Simulation optional) |\n| **T3 (Standard)** | Features, UI state, caching | **L1-L4** |\n| **T4 (Low)** | Analytics, logging, metrics | **L1, L4** |\n\n**REQUIREMENT**: For T1/T2 code, ALL applicable guarantee layers MUST be present.\n\n## Step 2: Verify the 6 Guarantee Layers\n\n### L1 - TYPES (Compile-time enforcement)\n- [ ] Branded types for domain values (no primitive obsession: `string`/`number`)\n- [ ] Phantom types for state machines (invalid transitions unrepresentable)\n- [ ] Error channel explicit (all failure modes in Effect type)\n- [ ] Exhaustive matching (`Match.exhaustive` for all unions)\n\n### L2 - RUNTIME (Fail-fast assertions)\n- [ ] Preconditions: `Effect.assert` before operations (guard clauses)\n- [ ] Postconditions: `Effect.assert` after operations (invariants hold)\n- [ ] Smart constructors: Schema validation returning `Effect<T, ValidationError>`\n- [ ] Boundary validation: All external input validated at entry points\n\n### L3 - PERSISTENCE (Last line of defense)\n- [ ] DB constraints: UNIQUE for idempotency, CHECK for valid ranges\n- [ ] Partial indexes: State-dependent constraints (e.g., only one ACTIVE per user)\n- [ ] Foreign keys: Referential integrity enforced\n- [ ] Triggers: Auto-maintained invariants where app logic might fail\n\n### L4 - TESTS (Behavioral verification)\n- [ ] `@property` TSDoc comments: Every invariant has a name and description\n- [ ] Unit tests: Happy path and specific edge cases covered\n- [ ] Property-based tests: Randomized inputs verify invariants (conservation, idempotency)\n- [ ] Constraint tests: DB schema actually has the constraints\n\n### L5 - MONITORING (Production defense)\n- [ ] Alerts: Impossible states trigger alerts (e.g., \"double X detected\")\n- [ ] Metrics: Key invariants tracked (e.g., operation count per period)\n- [ ] Anomaly detection: Unusual patterns flagged automatically\n\n### L6 - SIMULATION (T1 only)\n- [ ] Seed-based: Deterministic, reproducible 24/7 simulation plan\n- [ ] Invariant checking: Simulation validates all guarantees\n- [ ] Failure injection: Network, DB, external API failures tested\n\n## Step 3: Verify Domain-Specific Invariants\n\n### Example: Billing (T1)\n- [ ] Idempotency: Deterministic keys + temporal uniqueness + DB UNIQUE constraint\n- [ ] State exclusion: CANCELED items never processed (type + runtime + DB filter)\n- [ ] Exactly-once: Period advancement with postcondition asserts\n- [ ] Conservation: Money neither created nor destroyed (property test)\n\n### Example: Auth/Access Control (T1)\n- [ ] RBAC: Phantom types for permission levels\n- [ ] Token expiry: Temporal assertions + DB cleanup\n- [ ] Audit logging: Immutable append-only records\n\n### Example: State Machines (T2)\n- [ ] Phantom types preventing invalid transitions\n- [ ] `Match.exhaustive` for all state + event combinations\n- [ ] DB check constraints on status fields\n\n### Example: Distributed Operations (T1/T2)\n- [ ] Determinism: Same inputs always produce same outputs\n- [ ] Commutativity: Order of independent ops doesn't matter\n- [ ] Idempotency: Duplicate requests are safely ignored\n- [ ] Observability: All operations traceable end-to-end\n\n## Verification Checklists\n\n### For T1 Code:\n- [ ] All 6 layers present (Types, Runtime, Persistence, Tests, Monitoring, Simulation)\n- [ ] Invariants documented with `@property` TSDoc\n- [ ] No primitive obsession (branded types everywhere)\n- [ ] DB constraints exist and are tested\n- [ ] Effect.assert for pre/postconditions\n- [ ] Seed-based simulation plan documented\n\n### For T2 Code:\n- [ ] Layers 1-5 present (Simulation optional)\n- [ ] State machine phantom types\n- [ ] Property tests for core invariants\n- [ ] Monitoring TODOs in place\n\n### For T3/T4 Code:\n- [ ] Layers 1-4 (L5/L6 optional)\n- [ ] Basic property tests for complex logic\n\n## Severity\n\n- `CRITICAL`: Missing guarantee layer for T1/T2 code\n- `HIGH`: Missing L5 monitoring for T1\n- `WARNING`: Incomplete property test coverage\n\nMark `changes_requested` if ANY required layer is missing for the criticality tier.\n\n## Confidence Calculation\n\n```\nT1 Confidence = L1 × L2 × L3 × L4 × L5 × L6\n             ≈ 0.65 × 0.95 × 0.99 × 0.95 × 0.98 × 0.99\n             ≈ 99.5%\n\nEach missing layer multiplies risk. No single layer is sufficient.\n```\n" },
  { path: "prompts/reviewers/production-monitoring.md", contents: "# Production Monitoring: Invariant Verification in Production\n\n> **Layer 5 of the Guarantee Hierarchy: Catch what escaped all other layers.**\n\nThis guide defines how to monitor critical invariants in production using our observability stack:\n- **Grafana** (Loki/Mimir/Tempo) → System health, metrics, traces\n- **Sentry** → Errors, regressions, profiling\n- **PostHog** → User impact, behavior, funnels\n\nSee `specs/Infrastructure-Setup.md` for full architecture.\n\n---\n\n## Monitoring Philosophy\n\n### The Role of Production Monitoring\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                                                                         │\n│   Layers 1-4 PREVENT bad states:                                        │\n│   Types → Assertions → DB Constraints → Tests                           │\n│                                                                         │\n│   Layer 5 DETECTS when prevention failed:                               │\n│   Monitoring → Alerts → Human intervention                              │\n│                                                                         │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n**If Layer 5 fires, something is already wrong.** The goal is:\n1. **Detect fast** - Minimize time-to-detection\n2. **Alert the right person** - Route to owner\n3. **Provide context** - What, where, how bad\n4. **Enable action** - Clear playbook to follow\n\n### Alert Categories\n\n| Category | Tool | Example | Response Time |\n|----------|------|---------|---------------|\n| **System Health** | Grafana | 5xx rate > 1%, latency p99 > 2s | < 5 min |\n| **Invariant Violation** | Sentry + Grafana | Double charge detected | < 1 min |\n| **Error Spike** | Sentry | New exception in billing code | < 15 min |\n| **User Impact** | PostHog | Subscription funnel drop > 20% | < 1 hour |\n\n---\n\n## Critical Invariant Alerts\n\n### For Subscription Billing (from `docs/guides/guarantee-hierarchy.md`)\n\nThese alerts detect violations of the three billing guarantees.\n\n#### Alert: Double Charge Detection (Guarantee #2)\n\n**Invariant:** No subscription should have > 1 successful charge per day.\n\n**Implementation:**\n\n```typescript\n// In renewal cron, after recording payment event\nconst chargesCount = await countChargesForSubscriptionToday(subscriptionId)\n\nif (chargesCount > 1) {\n  // CRITICAL: This should be impossible if layers 1-4 work\n  Sentry.captureMessage(\"DOUBLE_CHARGE_DETECTED\", {\n    level: \"fatal\",\n    tags: {\n      invariant: \"NO_DOUBLE_CHARGE\",\n      subscriptionId,\n      chargesCount,\n    },\n    extra: {\n      chargeEvents: await getChargeEventsForToday(subscriptionId),\n    },\n  })\n\n  // Also emit metric for Grafana alerting\n  metrics.increment(\"billing.invariant_violation\", {\n    type: \"double_charge\",\n    subscriptionId,\n  })\n}\n```\n\n**Grafana Alert Rule:**\n\n```yaml\n# grafana/alerts/billing-invariants.yaml\ngroups:\n  - name: billing_invariants\n    rules:\n      - alert: DoubleChargeDetected\n        expr: increase(billing_invariant_violation_total{type=\"double_charge\"}[5m]) > 0\n        for: 0m  # Alert immediately\n        labels:\n          severity: critical\n          team: billing\n        annotations:\n          summary: \"CRITICAL: Double charge detected\"\n          description: \"Subscription {{ $labels.subscriptionId }} was charged multiple times\"\n          runbook_url: \"https://docs.internal/runbooks/double-charge\"\n```\n\n**Sentry Alert:**\n- Create alert for issues with tag `invariant:NO_DOUBLE_CHARGE`\n- Severity: Critical\n- Notify: #billing-alerts + on-call\n\n---\n\n#### Alert: Canceled Subscription Charge Attempt (Guarantee #1)\n\n**Invariant:** Canceled subscriptions should never reach the charge function.\n\n**Implementation:**\n\n```typescript\n// At the start of chargeSubscription(), as defense-in-depth\nconst chargeSubscription = (sub: ChargeableSubscription) =>\n  Effect.gen(function* () {\n    // This should be impossible due to type system, but verify anyway\n    if ((sub as any)._status === \"CANCELED\") {\n      Sentry.captureMessage(\"CANCELED_SUBSCRIPTION_CHARGE_ATTEMPT\", {\n        level: \"fatal\",\n        tags: {\n          invariant: \"CANCELED_NEVER_CHARGED\",\n          subscriptionId: sub.id,\n          status: (sub as any)._status,\n        },\n      })\n\n      metrics.increment(\"billing.invariant_violation\", {\n        type: \"canceled_charge_attempt\",\n      })\n\n      return yield* Effect.fail(new SubscriptionNotChargeableError({\n        subscriptionId: sub.id,\n        currentStatus: \"CANCELED\",\n      }))\n    }\n\n    // ... rest of charge logic\n  })\n```\n\n---\n\n#### Alert: Period Not Advancing (Guarantee #3)\n\n**Invariant:** After successful charge, period_end must be in the future.\n\n**Implementation:**\n\n```typescript\n// After updating subscription post-charge\nconst updated = await updateSubscriptionPeriod(sub.id, newPeriodEnd)\n\n// Verify the invariant\nif (new Date(updated.currentPeriodEnd) <= new Date()) {\n  Sentry.captureMessage(\"PERIOD_NOT_ADVANCED\", {\n    level: \"error\",\n    tags: {\n      invariant: \"PERIOD_MUST_ADVANCE\",\n      subscriptionId: sub.id,\n    },\n    extra: {\n      expectedPeriodEnd: newPeriodEnd,\n      actualPeriodEnd: updated.currentPeriodEnd,\n    },\n  })\n}\n```\n\n---\n\n#### Alert: Idempotency Key Collision (Guarantee #2)\n\n**Invariant:** Idempotency key collisions should be caught by DB constraint.\n\n**Implementation:**\n\n```typescript\n// When recording payment event\nconst recordPaymentEvent = (event: PaymentEvent) =>\n  Effect.gen(function* () {\n    const result = yield* Effect.tryPromise({\n      try: () => supabase.from(\"subscription_payment_events\").insert(event),\n      catch: (error) => {\n        // Check if it's an idempotency violation\n        if (error.message?.includes(\"unique\") || error.code === \"23505\") {\n          // This is EXPECTED for retries - log but don't alert\n          console.log(`Idempotent retry detected: ${event.idempotencyKey}`)\n\n          metrics.increment(\"billing.idempotent_retry\", {\n            subscriptionId: event.userSubscriptionId,\n          })\n\n          return new IdempotencyViolationError({ existingKey: event.idempotencyKey })\n        }\n\n        // Unexpected error - alert\n        Sentry.captureException(error, {\n          tags: { operation: \"record_payment_event\" },\n        })\n\n        return new DbError({ cause: error })\n      },\n    })\n\n    return result\n  })\n```\n\n**Grafana Alert for Excessive Retries:**\n\n```yaml\n- alert: ExcessiveIdempotentRetries\n  expr: rate(billing_idempotent_retry_total[5m]) > 10\n  for: 5m\n  labels:\n    severity: warning\n    team: billing\n  annotations:\n    summary: \"High rate of idempotent payment retries\"\n    description: \"May indicate cron job running too frequently or retry storm\"\n```\n\n---\n\n## System Health Alerts\n\n### Renewal Cron Health\n\n```yaml\n# grafana/alerts/cron-health.yaml\ngroups:\n  - name: cron_health\n    rules:\n      # Cron didn't run\n      - alert: RenewalCronMissing\n        expr: absent(cron_subscription_renewal_last_run_timestamp) or\n              (time() - cron_subscription_renewal_last_run_timestamp) > 90000  # 25 hours\n        for: 5m\n        labels:\n          severity: warning\n          team: platform\n        annotations:\n          summary: \"Subscription renewal cron hasn't run in 25+ hours\"\n\n      # Cron failed\n      - alert: RenewalCronFailed\n        expr: cron_subscription_renewal_last_status != 1\n        for: 0m\n        labels:\n          severity: critical\n          team: billing\n        annotations:\n          summary: \"Subscription renewal cron failed\"\n\n      # Cron duration anomaly\n      - alert: RenewalCronSlow\n        expr: cron_subscription_renewal_duration_seconds > 300  # 5 min\n        for: 0m\n        labels:\n          severity: warning\n          team: billing\n        annotations:\n          summary: \"Renewal cron took > 5 minutes\"\n```\n\n### Database Constraint Verification\n\n```yaml\n# Weekly check that constraints still exist\n- alert: BillingConstraintsMissing\n  expr: pg_constraint_exists{constraint=\"subscription_payment_events_idempotency_idx\"} != 1\n  for: 5m\n  labels:\n    severity: critical\n    team: platform\n  annotations:\n    summary: \"CRITICAL: Billing idempotency constraint missing from database\"\n    description: \"The unique constraint that prevents double-charging is missing\"\n```\n\n---\n\n## Sentry Configuration\n\n### Issue Alerts for Billing Code\n\n```javascript\n// sentry.config.js\nSentry.init({\n  // ... other config\n\n  beforeSend(event) {\n    // Tag billing-related errors\n    if (event.transaction?.includes(\"/api/subscriptions\") ||\n        event.transaction?.includes(\"/api/cron/subscription-renewal\")) {\n      event.tags = {\n        ...event.tags,\n        domain: \"billing\",\n        critical: \"true\",\n      }\n    }\n    return event\n  },\n})\n```\n\n**Sentry Alert Rules:**\n\n1. **New Issue in Billing Code**\n   - Filter: `domain:billing`\n   - Trigger: New issue\n   - Action: Notify #billing-alerts\n\n2. **Invariant Violation**\n   - Filter: `tags.invariant:*`\n   - Trigger: Any event\n   - Action: Page on-call + notify #billing-alerts\n\n3. **Payment Provider Errors**\n   - Filter: `error.type:BasePayError`\n   - Trigger: > 5 events in 5 min\n   - Action: Notify #billing-alerts\n\n---\n\n## PostHog Configuration\n\n### Subscription Funnel Monitoring\n\n```javascript\n// Track subscription lifecycle events\nposthog.capture(\"subscription_started\", {\n  subscriptionId,\n  tier: \"horoscope-plus\",\n  amount: 5.0,\n})\n\nposthog.capture(\"subscription_renewal_success\", {\n  subscriptionId,\n  periodNumber: 2,\n})\n\nposthog.capture(\"subscription_renewal_failed\", {\n  subscriptionId,\n  failureReason: \"insufficient_funds\",\n})\n\nposthog.capture(\"subscription_canceled\", {\n  subscriptionId,\n  reason: \"user_requested\",\n  periodsCompleted: 3,\n})\n```\n\n**PostHog Alerts:**\n\n1. **Subscription Start Drop**\n   - Funnel: Visit subscribe page → Complete subscription\n   - Alert if: Conversion drops > 20% week-over-week\n\n2. **Renewal Failure Spike**\n   - Event: `subscription_renewal_failed`\n   - Alert if: Count > 2x average\n\n3. **Cancellation Spike**\n   - Event: `subscription_canceled`\n   - Alert if: Count > 2x average in 24h\n\n---\n\n## Instrumentation Checklist\n\n### For Every Critical Operation\n\n```typescript\n/**\n * Instrumentation template for billing operations.\n */\nconst billingOperation = (operationName: string) =>\n  Effect.gen(function* () {\n    const startTime = Date.now()\n    const traceId = crypto.randomUUID()\n\n    // 1. Log start (Grafana/Loki)\n    console.log(JSON.stringify({\n      level: \"info\",\n      operation: operationName,\n      traceId,\n      timestamp: new Date().toISOString(),\n    }))\n\n    // 2. Start span (Grafana/Tempo via OpenTelemetry)\n    const span = tracer.startSpan(operationName, {\n      attributes: { \"billing.operation\": operationName },\n    })\n\n    try {\n      // ... operation logic ...\n\n      // 3. Record success metric (Grafana/Mimir)\n      metrics.increment(`billing.${operationName}.success`)\n      metrics.histogram(`billing.${operationName}.duration`, Date.now() - startTime)\n\n      // 4. Track in PostHog if user-facing\n      posthog.capture(`billing_${operationName}_success`, { traceId })\n\n      span.setStatus({ code: SpanStatusCode.OK })\n    } catch (error) {\n      // 5. Record failure metric\n      metrics.increment(`billing.${operationName}.failure`, {\n        error_type: error.constructor.name,\n      })\n\n      // 6. Capture in Sentry with context\n      Sentry.captureException(error, {\n        tags: {\n          operation: operationName,\n          traceId,\n        },\n      })\n\n      span.setStatus({ code: SpanStatusCode.ERROR, message: error.message })\n      throw error\n    } finally {\n      span.end()\n    }\n  })\n```\n\n---\n\n## Alert Response Playbooks\n\n### Playbook: Double Charge Detected\n\n**Severity:** CRITICAL - Customer impact, potential refund needed\n\n1. **Immediate (< 5 min):**\n   - Acknowledge alert\n   - Check Sentry for full context\n   - Identify affected subscription(s)\n\n2. **Investigation (< 30 min):**\n   - Pull payment events from DB for affected subscription\n   - Check Grafana traces for the renewal cron run\n   - Identify if idempotency constraint was bypassed (how?)\n\n3. **Mitigation:**\n   - If customer was charged twice: Initiate refund via Base Pay\n   - If cron bug: Disable cron, deploy fix\n   - If constraint missing: Restore constraint immediately\n\n4. **Follow-up:**\n   - Root cause analysis\n   - Add/fix test coverage\n   - Update guarantee hierarchy if needed\n\n### Playbook: Renewal Cron Failed\n\n**Severity:** HIGH - Subscriptions won't renew, revenue impact\n\n1. **Immediate:**\n   - Check Sentry for exception\n   - Check Grafana logs for cron output\n\n2. **Investigation:**\n   - Was it a transient error (Base Pay down)?\n   - Was it a code bug?\n   - How many subscriptions were affected?\n\n3. **Mitigation:**\n   - If transient: Wait and monitor next run\n   - If bug: Fix and manually trigger renewal for missed subscriptions\n   - If Base Pay down: Wait for recovery, then catch up\n\n---\n\n## Dashboard Requirements\n\nEvery monitoring dashboard must have:\n\n```yaml\nDashboard Metadata:\n  owner: \"@billing-team\"\n  purpose: \"Monitor subscription billing health and invariants\"\n  updated: \"2024-01-15\"\n\nFor each panel:\n  what_it_shows: \"Brief description\"\n  what_normal_looks_like: \"Expected ranges/patterns\"\n  what_action_to_take: \"If abnormal, do X\"\n  related_playbook: \"link to playbook\"\n```\n\n### Required Dashboards\n\n1. **Billing Health Overview**\n   - Renewal success rate\n   - Failed renewals by reason\n   - Active subscriptions count\n   - MRR (Monthly Recurring Revenue)\n\n2. **Billing Invariant Monitor**\n   - Double charge count (should be 0)\n   - Canceled charge attempts (should be 0)\n   - Period advancement failures (should be 0)\n   - Idempotent retry rate\n\n3. **Cron Job Health**\n   - Last run timestamp\n   - Run duration\n   - Success/failure status\n   - Subscriptions processed per run\n\n---\n\n## Verification: Is Monitoring Sound?\n\nRun this checklist periodically:\n\n```\n□ All three billing invariants have alerts configured\n□ Alerts fire to the correct channel/person\n□ Alerts have been tested (trigger manually)\n□ Playbooks exist and are up to date\n□ Dashboards have owners and descriptions\n□ Sampling rates are appropriate (not missing events)\n□ Correlation IDs propagate across all systems\n□ Sentry, Grafana, PostHog all have the same user_id\n```\n\n### Testing Alert Effectiveness\n\n```typescript\n// Periodically inject test events to verify alerting works\nif (process.env.ALERT_TEST_MODE === \"true\") {\n  // Emit a fake invariant violation\n  metrics.increment(\"billing.invariant_violation\", {\n    type: \"test_double_charge\",\n    test: \"true\",\n  })\n\n  Sentry.captureMessage(\"TEST_INVARIANT_VIOLATION\", {\n    level: \"warning\",\n    tags: { test: \"true\", invariant: \"TEST\" },\n  })\n}\n```\n\n---\n\n## Summary: Tool Responsibilities\n\n| Concern | Primary Tool | What to Configure |\n|---------|-------------|-------------------|\n| \"Is billing broken?\" | Grafana | Metrics + alerts for cron health, error rates |\n| \"Why did billing break?\" | Sentry | Exception tracking, release regression |\n| \"Who was affected?\" | PostHog | Funnel analysis, cohort of failed renewals |\n| \"Was an invariant violated?\" | All three | Metric in Grafana, exception in Sentry, event in PostHog |\n\n---\n\n🫡🇩🇪 Trust but verify. Every layer can fail. Production monitoring is the last line of defense.\n" },
  { path: "prompts/reviewers/nasa-10-rules.md", contents: "# NASA Engineering Principles Reviewer\n\nReview against NASA-style engineering discipline and the \"Power of Ten\" rules for safety-critical code.\n\n## Guarantee Hierarchy (L1-L5)\n\nCRITICAL: Check that ALL applicable layers are implemented:\n\n### L1 - TYPES (Compile-time enforcement)\n- [ ] Branded types for domain values (e.g., `UserId` not `string`)\n- [ ] Phantom types for state machines (invalid transitions unrepresentable)\n- [ ] Error channels explicit in Effect types (all failures known)\n- [ ] Exhaustive matching (`Match.exhaustive` for all unions)\n\n### L2 - RUNTIME (Fail-fast assertions)\n- [ ] Preconditions: `Effect.assert` before operations\n- [ ] Postconditions: `Effect.assert` after operations (invariants hold)\n- [ ] Smart constructors: Schema validation returning `Effect<T, ValidationError>`\n- [ ] Boundary validation: All external input validated at entry points\n\n### L3 - PERSISTENCE (Database constraints)\n- [ ] UNIQUE constraints for idempotency\n- [ ] Partial indexes for state-dependent constraints\n- [ ] CHECK constraints for valid ranges\n- [ ] Foreign keys for referential integrity\n- [ ] Triggers for auto-maintained invariants\n\n### L4 - TESTS (Behavioral verification)\n- [ ] `@property` TSDoc comments naming every invariant\n- [ ] Property-based tests (randomized inputs)\n- [ ] Constraint verification (DB actually enforces constraints)\n\n### L5 - MONITORING (Production defense)\n- [ ] TODOs for production alerts (e.g., \"detect double X\")\n- [ ] Metrics tracking for invariants\n- [ ] Anomaly detection planning\n\n## NASA \"Power of Ten\" Rules\n\n1. **Simple control flow**\n   - [ ] No recursion (use explicit loops with bounds)\n   - [ ] Bounded loops only (fixed upper limits)\n   - [ ] No dynamic dispatch where static suffices\n\n2. **Fixed upper bounds**\n   - [ ] All allocations bounded (no unbounded growth)\n   - [ ] Array/collection sizes have limits\n   - [ ] No while(true) without guaranteed exit\n\n3. **No dynamic memory after init**\n   - [ ] Pre-allocated pools where possible\n   - [ ] Effect's Scope for resource management\n   - [ ] No runtime allocation in hot paths (T1 only)\n\n4. **Short functions**\n   - [ ] Max 60 lines per function\n   - [ ] Single responsibility enforced\n   - [ ] Early returns preferred over deep nesting\n\n5. **Minimum two assertions**\n   - [ ] Preconditions checked (guard clauses)\n   - [ ] Postconditions verified (invariants hold)\n   - [ ] Loop invariants where applicable\n\n6. **Data scope minimization**\n   - [ ] Variables declared at smallest scope\n   - [ ] No module-level mutable state\n   - [ ] Function parameters preferred over shared state\n\n7. **Check return values**\n   - [ ] All Effect errors handled (no unhandled channels)\n   - [ ] No floating Promises (all awaited/caught)\n   - [ ] Service errors explicitly matched\n\n8. **Limited preprocessor**\n   - [ ] No magic (no hidden control flow from decorators)\n   - [ ] No compile-time code generation obscuring logic\n   - [ ] Explicit is better than implicit\n\n9. **Pointer discipline** (TypeScript: reference safety)\n   - [ ] No `null` without `Option/Maybe` types\n   - [ ] No undefined without explicit handling\n   - [ ] References validated before dereference\n\n10. **Compile with warnings** (strict TypeScript)\n    - [ ] `strict: true` enforced\n    - [ ] No `any` types\n    - [ ] Exhaustive switch cases\n    - [ ] Unused variables flagged\n\n## Fabrik-Specific Rules (from AGENTS.md)\n\n- [ ] **State Management**: No `db.state.set()` during render\n- [ ] **VM Self-Heal**: Heartbeat logic present for long-running tasks\n- [ ] **VCS Enforcement**: Every task pushes to branch (`jj git push --branch`)\n- [ ] **Host/VM Decoupling**: Code can run standalone (no host dependency)\n\n## Effect-TS Safety Patterns\n\n- [ ] Error channels explicit (not thrown exceptions)\n- [ ] Smart constructors for branded types\n- [ ] Phantom types preventing invalid state transitions\n- [ ] `Match.exhaustive` for all unions\n\n## Severity\n\n- `CRITICAL`: Missing guarantee layer for T1/T2 code, Power of Ten violation\n- `WARNING`: L5 monitoring not planned, minor assertion missing\n\nFlag any violation with severity. Missing layers for critical code = `changes_requested`.\n" },
  { path: "prompts/reviewers/guarantee-hierarchy.md", contents: "# Guarantee Hierarchy: Layered Safety for Critical Systems\n\n> **Principle:** No single layer provides sufficient safety. Layer guarantees for exponential confidence.\n\n---\n\n## The Hierarchy\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│                                                                         │\n│   Layer 5: MONITORING         (Production Defense)                      │\n│   ├─ Alerts on invariant violations                                     │\n│   ├─ Anomaly detection                                                  │\n│   └─ Confidence: Catches what escaped all other layers                  │\n│                                                                         │\n├─────────────────────────────────────────────────────────────────────────┤\n│                                                                         │\n│   Layer 4: TESTS              (Behavioral Verification)                 │\n│   ├─ Unit tests: specific cases                                         │\n│   ├─ Property tests: randomized inputs                                  │\n│   ├─ Integration tests: real system behavior                            │\n│   └─ Confidence: ~95% with layers 1-3                                   │\n│                                                                         │\n├─────────────────────────────────────────────────────────────────────────┤\n│                                                                         │\n│   Layer 3: PERSISTENCE        (Database Constraints)                    │\n│   ├─ UNIQUE constraints                                                 │\n│   ├─ CHECK constraints                                                  │\n│   ├─ Foreign keys                                                       │\n│   ├─ Triggers for complex invariants                                    │\n│   └─ Confidence: ~90% with layers 1-2                                   │\n│                                                                         │\n├─────────────────────────────────────────────────────────────────────────┤\n│                                                                         │\n│   Layer 2: RUNTIME            (Effect Assertions & Schema)              │\n│   ├─ Effect.assert for preconditions/postconditions                     │\n│   ├─ Schema validation at boundaries                                    │\n│   ├─ Smart constructors returning Effect<T, ValidationError>            │\n│   └─ Confidence: ~80% with layer 1                                      │\n│                                                                         │\n├─────────────────────────────────────────────────────────────────────────┤\n│                                                                         │\n│   Layer 1: TYPES              (Compile-Time Guarantees)                 │\n│   ├─ Branded/nominal types                                              │\n│   ├─ Phantom types for state machines                                   │\n│   ├─ Error channel typing                                               │\n│   ├─ Exhaustive pattern matching                                        │\n│   └─ Confidence: ~65% (TypeScript limitations)                          │\n│                                                                         │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## Layer 1: Types (Compile-Time)\n\n**Goal:** Make invalid states unrepresentable.\n\n### Pattern 1.1: Branded Types\n\nUse for values that have domain meaning beyond their primitive type.\n\n```typescript\nimport { Schema } from \"effect\"\n\n// ❌ BAD: Primitive obsession\nconst charge = (amount: number, subscriptionId: string) => ...\n\n// ✅ GOOD: Branded types enforce valid construction\nconst PositiveAmount = Schema.Number.pipe(\n  Schema.positive(),\n  Schema.brand(\"PositiveAmount\")\n)\ntype PositiveAmount = Schema.Schema.Type<typeof PositiveAmount>\n\nconst SubscriptionId = Schema.String.pipe(\n  Schema.pattern(/^sub_[a-zA-Z0-9]{24}$/),\n  Schema.brand(\"SubscriptionId\")\n)\ntype SubscriptionId = Schema.Schema.Type<typeof SubscriptionId>\n\nconst charge = (amount: PositiveAmount, subscriptionId: SubscriptionId) => ...\n```\n\n**When to use:**\n- IDs (UserId, SubscriptionId, OrderId)\n- Monetary values (PositiveAmount, NonNegativeBalance)\n- Validated strings (Email, PhoneNumber, IdempotencyKey)\n- Constrained numbers (Percentage, PortNumber)\n\n### Pattern 1.2: Phantom Types for State Machines\n\nUse when operations are only valid in certain states.\n\n```typescript\n// State encoded in the type parameter\ninterface Subscription<Status extends \"ACTIVE\" | \"PAST_DUE\" | \"CANCELED\"> {\n  readonly _status: Status\n  readonly id: SubscriptionId\n  readonly userId: UserId\n  readonly currentPeriodEnd: Date\n}\n\n// Type aliases for clarity\ntype ActiveSubscription = Subscription<\"ACTIVE\">\ntype CanceledSubscription = Subscription<\"CANCELED\">\n\n// Operations constrained by state\nconst charge = (sub: Subscription<\"ACTIVE\" | \"PAST_DUE\">) =>\n  Effect<ChargeResult, ChargeError, BasePayService>\n\nconst cancel = (sub: ActiveSubscription) =>\n  Effect<CanceledSubscription, never, DbService>\n\n// ❌ COMPILE ERROR: Can't charge canceled subscription\nconst badCharge = (sub: CanceledSubscription) => charge(sub) // Type error!\n```\n\n**When to use:**\n- Subscription states (Active, Canceled, Suspended)\n- Order states (Pending, Paid, Shipped, Delivered)\n- Document states (Draft, Published, Archived)\n- Connection states (Disconnected, Connecting, Connected)\n\n### Pattern 1.3: Error Channel Typing\n\nExplicit about what can fail.\n\n```typescript\n// ❌ BAD: Unknown failure modes\nconst processPayment = (amount: number): Promise<Result> => ...\n\n// ✅ GOOD: Every failure mode is typed\nclass InsufficientFundsError extends Data.TaggedError(\"InsufficientFundsError\")<{\n  readonly available: PositiveAmount\n  readonly required: PositiveAmount\n}> {}\n\nclass IdempotencyError extends Data.TaggedError(\"IdempotencyError\")<{\n  readonly existingEventId: string\n  readonly attemptedKey: IdempotencyKey\n}> {}\n\nclass SubscriptionNotActiveError extends Data.TaggedError(\"SubscriptionNotActiveError\")<{\n  readonly subscriptionId: SubscriptionId\n  readonly currentStatus: string\n}> {}\n\nconst processPayment = (\n  sub: ActiveSubscription,\n  amount: PositiveAmount\n): Effect<\n  PaymentResult,\n  InsufficientFundsError | IdempotencyError | SubscriptionNotActiveError,\n  BasePayService | DbService\n> => ...\n```\n\n### Pattern 1.4: Exhaustive Matching\n\nNo missed cases.\n\n```typescript\nimport { Match } from \"effect\"\n\nconst handleSubscriptionStatus = Match.type<Subscription<any>>().pipe(\n  Match.when({ _status: \"ACTIVE\" }, (s) => processActive(s)),\n  Match.when({ _status: \"PAST_DUE\" }, (s) => processPastDue(s)),\n  Match.when({ _status: \"CANCELED\" }, (s) => processCanceled(s)),\n  Match.when({ _status: \"EXPIRED\" }, (s) => processExpired(s)),\n  Match.exhaustive // ❌ Compile error if case missing!\n)\n```\n\n---\n\n## Layer 2: Runtime (Assertions & Validation)\n\n**Goal:** Catch violations at runtime before they cause damage.\n\n### Pattern 2.1: Preconditions with Effect.assert\n\n```typescript\nconst chargeSubscription = (sub: ActiveSubscription) =>\n  Effect.gen(function* () {\n    const now = new Date()\n\n    // PRECONDITION: Period must have ended (can't charge early)\n    yield* Effect.assert(\n      sub.currentPeriodEnd <= now,\n      () => new PrematureChargeError({\n        subscriptionId: sub.id,\n        periodEnd: sub.currentPeriodEnd,\n        attemptedAt: now,\n      })\n    )\n\n    // ... charge logic ...\n  })\n```\n\n### Pattern 2.2: Postconditions\n\n```typescript\nconst advancePeriod = (sub: ActiveSubscription, days: number) =>\n  Effect.gen(function* () {\n    const oldPeriodEnd = sub.currentPeriodEnd\n    const newPeriodEnd = new Date(oldPeriodEnd.getTime() + days * 86400000)\n\n    // ... update logic ...\n\n    // POSTCONDITION: Period must have advanced\n    yield* Effect.assert(\n      newPeriodEnd > oldPeriodEnd,\n      () => new InvariantViolationError({\n        invariant: \"PERIOD_MUST_ADVANCE\",\n        old: oldPeriodEnd,\n        new: newPeriodEnd,\n      })\n    )\n\n    return { ...sub, currentPeriodEnd: newPeriodEnd }\n  })\n```\n\n### Pattern 2.3: Smart Constructors\n\nOnly way to create a type is through validated Effect.\n\n```typescript\nconst makeIdempotencyKey = (\n  subscriptionId: SubscriptionId,\n  date: Date\n): Effect<IdempotencyKey, ValidationError, never> =>\n  Effect.gen(function* () {\n    const dateStr = date.toISOString().slice(0, 10)\n    const key = `renewal-${subscriptionId}-${dateStr}`\n\n    // Validate the constructed key\n    return yield* Schema.decode(IdempotencyKeySchema)(key)\n  })\n\n// Usage - must handle ValidationError\nconst key = yield* makeIdempotencyKey(subId, today)\n```\n\n### Pattern 2.4: Boundary Validation\n\nValidate ALL external input at system boundaries.\n\n```typescript\n// API route handler\nexport const POST = (request: Request) =>\n  Effect.gen(function* () {\n    const body = yield* Effect.tryPromise(() => request.json())\n\n    // BOUNDARY: Validate external input\n    const input = yield* Schema.decodeUnknown(CreateSubscriptionSchema)(body)\n\n    // Now `input` is fully typed and validated\n    return yield* createSubscription(input)\n  }).pipe(\n    Effect.catchTag(\"ParseError\", (e) =>\n      Effect.succeed(Response.json({ error: \"Invalid input\" }, { status: 400 }))\n    )\n  )\n```\n\n---\n\n## Layer 3: Persistence (Database Constraints)\n\n**Goal:** Last line of defense. Even if application logic has bugs, database prevents invalid states.\n\n### Pattern 3.1: Unique Constraints for Idempotency\n\n```sql\n-- Prevents duplicate payment records even if app logic fails\nCREATE UNIQUE INDEX subscription_payment_events_idempotency_idx\nON subscription_payment_events (provider, user_subscription_id, idempotency_key);\n```\n\n### Pattern 3.2: Partial Unique Index for State Constraints\n\n```sql\n-- Only one ACTIVE subscription per user per provider\nCREATE UNIQUE INDEX user_subscriptions_single_active_idx\nON user_subscriptions (user_id, provider)\nWHERE status IN ('ACTIVE', 'IN_TRIAL');\n```\n\n### Pattern 3.3: Check Constraints\n\n```sql\n-- Amount must be positive\nALTER TABLE subscription_payment_events\nADD CONSTRAINT positive_amount CHECK (amount > 0);\n\n-- Status must be valid\nALTER TABLE user_subscriptions\nADD CONSTRAINT valid_status CHECK (\n  status IN ('ACTIVE', 'PAST_DUE', 'CANCELED', 'EXPIRED', 'IN_TRIAL')\n);\n```\n\n### Pattern 3.4: Triggers for Complex Invariants\n\n```sql\n-- Auto-populate charge amount from plan (immutable after creation)\nCREATE TRIGGER user_subscriptions_apply_plan_defaults\nBEFORE INSERT ON user_subscriptions\nFOR EACH ROW EXECUTE FUNCTION apply_plan_defaults();\n```\n\n---\n\n## Layer 4: Tests (Behavioral Verification)\n\n**Goal:** Verify that the system behaves correctly for specific scenarios.\n\n### Pattern 4.1: Property Tests with TSDoc\n\n```typescript\n/**\n * @property IDEMPOTENCY_DETERMINISM\n * Same inputs MUST produce same output (pure function).\n */\nit(\"same subscription + same day = same key\", () => {\n  fc.assert(\n    fc.property(fc.uuid(), fc.date(), (subId, date) => {\n      const key1 = generateIdempotencyKey(subId, date)\n      const key2 = generateIdempotencyKey(subId, date)\n      expect(key1).toBe(key2)\n    })\n  )\n})\n```\n\n### Pattern 4.2: Invariant Tests\n\n```typescript\n/**\n * @property CANCELED_NEVER_CHARGED\n * A CANCELED subscription must NEVER appear in renewal results.\n */\nit(\"CANCELED subscription excluded from renewal query\", async () => {\n  // Setup: Create subscription, cancel it\n  const sub = await createTestSubscription({ status: \"CANCELED\" })\n\n  // Execute: Run renewal query\n  const renewals = await getSubscriptionsForRenewal()\n\n  // Verify: Canceled subscription not included\n  expect(renewals.map(r => r.id)).not.toContain(sub.id)\n})\n```\n\n### Pattern 4.3: Constraint Verification Tests\n\n```typescript\n/**\n * @property DATABASE_CONSTRAINT_EXISTS\n * Verify the unique constraint exists at SQL level.\n */\nit(\"idempotency constraint exists on payment_events\", async () => {\n  const constraints = await getTableConstraints(\"subscription_payment_events\")\n  const idempotencyConstraint = constraints.find(c =>\n    c.name.includes(\"idempotency\")\n  )\n\n  expect(idempotencyConstraint).toBeDefined()\n  expect(idempotencyConstraint.type).toBe(\"UNIQUE\")\n})\n```\n\n---\n\n## Layer 5: Monitoring (Production Defense)\n\n**Goal:** Catch violations that escaped all other layers.\n\n> **Full guide:** `docs/guides/production-monitoring.md`\n>\n> Covers: Grafana alerts, Sentry configuration, PostHog funnels, incident playbooks\n\n### Pattern 5.1: Invariant Violation Alerts\n\n```typescript\nconst chargeSubscription = (sub: ActiveSubscription) =>\n  Effect.gen(function* () {\n    // ... charge logic ...\n\n    // Count charges for this subscription today\n    const chargesCount = yield* countChargesForDay(sub.id, today)\n\n    // MONITORING: Alert if impossible state\n    if (chargesCount > 1) {\n      // Sentry for debugging context\n      Sentry.captureMessage(\"DOUBLE_CHARGE_DETECTED\", {\n        level: \"fatal\",\n        tags: { invariant: \"NO_DOUBLE_CHARGE\", subscriptionId: sub.id },\n      })\n\n      // Grafana metric for alerting\n      yield* metrics.increment(\"billing.invariant_violation\", {\n        type: \"double_charge\",\n      })\n    }\n  })\n```\n\n### Pattern 5.2: Anomaly Detection\n\n```typescript\n// Track in metrics (flows to Grafana/Mimir)\nconst recordChargeAttempt = (sub: ActiveSubscription) =>\n  Effect.gen(function* () {\n    yield* metrics.increment(\"subscription.charge.attempt\", {\n      subscriptionId: sub.id,\n      status: sub._status,\n    })\n  })\n\n// Grafana alert rules (defined in grafana/alerts/)\n// - Alert if charge attempts > 2 per subscription per day\n// - Alert if canceled subscription has charge attempt\n// - Alert if payment events exceed expected count\n```\n\n### Pattern 5.3: Tool Routing\n\n| Concern | Tool | Why |\n|---------|------|-----|\n| \"Is it broken?\" | Grafana | System metrics, traces, logs |\n| \"Why is it broken?\" | Sentry | Stack traces, releases, profiling |\n| \"Who was affected?\" | PostHog | Funnels, cohorts, user impact |\n\n---\n\n## Applying the Hierarchy: Decision Framework\n\nFor each critical invariant, work through this checklist:\n\n```\n┌─────────────────────────────────────────────────────────────────────────┐\n│ INVARIANT: [Describe the property that must hold]                       │\n├─────────────────────────────────────────────────────────────────────────┤\n│                                                                         │\n│ 1. TYPE LAYER                                                           │\n│    □ Can this be encoded in types? (branded, phantom, union)            │\n│    □ Can invalid states be made unrepresentable?                        │\n│    □ Are all error cases typed in the Effect error channel?             │\n│                                                                         │\n│ 2. RUNTIME LAYER                                                        │\n│    □ Are there preconditions to assert?                                 │\n│    □ Are there postconditions to verify?                                │\n│    □ Is input validated at boundaries?                                  │\n│                                                                         │\n│ 3. PERSISTENCE LAYER                                                    │\n│    □ Can a database constraint enforce this?                            │\n│    □ Is there a unique constraint needed?                               │\n│    □ Should a trigger maintain the invariant?                           │\n│                                                                         │\n│ 4. TEST LAYER                                                           │\n│    □ Is there a unit test for the happy path?                           │\n│    □ Is there a test for the violation case?                            │\n│    □ Is there a property test for the invariant?                        │\n│    □ Is the database constraint tested?                                 │\n│                                                                         │\n│ 5. MONITORING LAYER                                                     │\n│    □ Would a violation be detectable in production?                     │\n│    □ Is there an alert for this failure mode?                           │\n│    □ Are metrics tracking this behavior?                                │\n│                                                                         │\n└─────────────────────────────────────────────────────────────────────────┘\n```\n\n---\n\n## Example: Subscription Billing Guarantees\n\n### Guarantee: \"Canceled subscriptions are never charged\"\n\n| Layer | Implementation |\n|-------|---------------|\n| **Types** | `charge(sub: Subscription<\"ACTIVE\" \\| \"PAST_DUE\">)` - Canceled not in union |\n| **Runtime** | `Effect.assert(sub.status !== \"CANCELED\", ...)` |\n| **Persistence** | Renewal query: `WHERE status IN ('ACTIVE', 'PAST_DUE')` |\n| **Tests** | `it(\"CANCELED subscription excluded from renewal\")` |\n| **Monitoring** | Alert if charge attempt on canceled subscription |\n\n### Guarantee: \"No double-charging\"\n\n| Layer | Implementation |\n|-------|---------------|\n| **Types** | `IdempotencyKey` branded type - can't use arbitrary string |\n| **Runtime** | Smart constructor validates key format |\n| **Persistence** | `UNIQUE INDEX (provider, subscription_id, idempotency_key)` |\n| **Tests** | `it(\"duplicate idempotency key rejected by constraint\")` |\n| **Monitoring** | Alert if payment_events count > 1 per subscription per day |\n\n### Guarantee: \"Exactly once per period\"\n\n| Layer | Implementation |\n|-------|---------------|\n| **Types** | `PositiveDays` branded type for period advancement |\n| **Runtime** | Postcondition: `newPeriodEnd > oldPeriodEnd` |\n| **Persistence** | `current_period_end` only updated on successful charge |\n| **Tests** | `it(\"period advances only on success\")` |\n| **Monitoring** | Alert if charge count > 1 while period unchanged |\n\n---\n\n## TypeScript Limitations (Honest Assessment)\n\nEffect-TS cannot provide:\n\n| Property | Why Not | Mitigation |\n|----------|---------|------------|\n| \"x + y = z\" (arithmetic) | No dependent types | Unit tests |\n| \"List is sorted\" | No refinement proofs | Runtime assertion |\n| \"True for ALL inputs\" | No theorem prover | Property tests |\n| \"Happens before Y\" | No temporal logic | Integration tests |\n| \"DB constraint exists\" | Types don't know SQL | Schema tests |\n\n**Bottom line:** Effect gives ~65% safety through types. Layers 2-5 provide the remaining ~30%. The last ~5% requires human vigilance and good engineering culture.\n\n---\n\n🫡🇩🇪 Prussian virtues: Defense in depth, multiple barriers, assume each can fail.\n" },
  { path: "README.md", contents: "# Local Ralph/Wisp Development Environment\n\n**Humans write specs. Agents ship features.**\n\nRun a workforce of isolated coding agents locally. Write a specification, dispatch it to your Ralph fleet, get notified when it ships. Smithers is required.\n\n## The Vision\n\n```\n┌─────────────────────────────────────────────────────────────────────┐\n│                                                                     │\n│   Human writes spec ──► Ralphs implement ──► Ralphs review ──►     │\n│                                │                  │                 │\n│                                └──── iterate ─────┘                 │\n│                                         │                           │\n│                                         ▼                           │\n│                              \"Feature X shipped\" ──► Human          │\n│                                                                     │\n└─────────────────────────────────────────────────────────────────────┘\n```\n\nYou stay in the loop for:\n- Writing specifications\n- Answering questions when agents get stuck\n- Receiving \"shipped\" notifications\n\nAgents handle:\n- Implementation\n- Code review (agent-to-agent)\n- Iteration on feedback\n- PR creation\n\n## Architecture\n\n```\n┌──────────────────────────────────────────────────────────────────┐\n│  Host Machine                                                    │\n│  ├── LAOS (Grafana/Loki/Tempo/Prometheus/Sentry/PostHog) ◄──     │\n│  │   all agents report here                                     │\n│  ├── Message queue (filesystem) ◄── agents coordinate           │\n│  │                                                               │\n│  ├── ralph-1 (VM) ──── Smithers workflow ── feat/auth           │\n│  ├── ralph-2 (VM) ──── Smithers workflow ── feat/dashboard      │\n│  ├── ralph-3 (VM) ──── Smithers workflow ── fix/api-error       │\n│  │                                                               │\n│  └── ralph-review (VM) ── reviews reports, sends feedback       │\n└──────────────────────────────────────────────────────────────────┘\n```\n\nEach VM has the repo cloned and works on its own branch. For advanced parallel work, use [Jujutsu (jj)](https://github.com/martinvonz/jj) which handles multiple changes natively.\n\n## Quick Start\n\n### 1. Setup infrastructure\n\n```bash\n# Start LAOS (shared host observability stack)\n# Source of truth: https://github.com/dtechvision/laos\nmkdir -p ~/git\nif [[ -d ~/git/laos/.git ]]; then\n  (cd ~/git/laos && git pull)\nelse\n  git clone https://github.com/dtechvision/laos.git ~/git/laos\nfi\ncd ~/git/laos\ndocker compose up -d\n\n# Optional: create a shared env file so LAOS endpoints get copied into VMs\ncd /path/to/local-isolated-ralph\n./scripts/create-ralph-env.sh\n# Edit ~/.config/ralph/ralph.env and set:\n# macOS (Lima):  LAOS_HOST=host.lima.internal\n# Linux (libvirt): LAOS_HOST=192.168.122.1\n\n# Create VMs (4 implementers + 1 reviewer)\nfor i in 1 2 3 4; do ./scripts/create-ralph.sh ralph-$i 2 4 20; done\n./scripts/create-ralph.sh ralph-review 2 4 20\n\n# Setup base image in one VM, then snapshot for cloning\n./scripts/setup-base-vm.sh  # Run inside VM\n```\n\n### 2. Compound Engineering: Spec → Todo → Run\n\n**Principle**: 80% Planning, 20% Execution. Each cycle compounds quality.\n\n#### Step 1: Spec erstellen (40%)\n\n```bash\n# Interview-Guide ausgeben (self-contained, kein externes File nötig)\n./dist/fabrik spec interview | tee /tmp/spec-interview.txt\n\n# Mit Agent durchführen → Output: specs/feature.json\ncat /tmp/spec-interview.txt | claude-code\n\n# Validieren\n./dist/fabrik spec validate\n```\n\n#### Step 2: Todo generieren (40%)\n\n```bash\n# Todo-Guide ausgeben\n./dist/fabrik todo generate | tee /tmp/todo-guide.txt\n\n# Mit Agent durchführen → Output: specs/feature.todo.json\ncat /tmp/todo-guide.txt | claude-code\n\n# Validieren\n./dist/fabrik spec validate\n```\n\n#### Step 3: Workflow starten (20%)\n\n```bash\n# Run dispatch\n./dist/fabrik run \\\n  --spec specs/feature.json \\\n  --todo specs/feature.todo.json \\\n  --vm ralph-1 \\\n  --project ~/projects/my-app     # Optional: Ziel-Repo\n```\n\n**Implicit Assumption**: Ohne `--project` arbeitet der Agent in einem frischen Clone innerhalb der VM.\n\n### 3. Launch Smithers\n\n```bash\n# Run a Smithers workflow (spec/todo JSON; minified on dispatch)\n./dist/fabrik run --spec specs/010-weekly-summary.json --vm ralph-1\n\n# With local project directory synced to VM\n./dist/fabrik run --spec specs/010-weekly-summary.json --vm ralph-1 --project ~/projects/my-app\n\n# With iteration limit (stops after 20 Smithers iterations)\n./dist/fabrik run --spec specs/010-weekly-summary.json --vm ralph-1 --project ~/projects/my-app --iterations 20\n\n# Or start multiple Ralphs on different specs (fleet)\n./dist/fabrik fleet --specs-dir specs --vm-prefix ralph\n```\n\n### 4. Watch and wait\n\n```bash\n# Grafana for logs/traces\nopen http://localhost:3010\n\n# Or attach to a VM session directly\n# limactl shell <vm> or ssh ralph@<ip>\n\n# Watch for blocked tasks and get desktop notifications\nfabrik runs watch --vm ralph-1\n```\n\nWhen done, Smithers writes task outputs into its SQLite db (`.smithers/<spec>.db`) and exits when all tasks are done.\n\n### Desktop notifications\n\n`fabrik runs watch` will send notifications when blocked tasks appear.\n\nInstall a notifier:\n- macOS: `brew install terminal-notifier`\n- Linux: `sudo apt install libnotify-bin` (provides `notify-send`)\n\n## Workflows\n\n| Pattern | Use Case | Setup | Time |\n|---------|----------|-------|------|\n| **Compound Engineering** | 80/20 Planning/Execution | `fabrik spec interview` → `fabrik todo generate` → `fabrik run` | 40/40/20% |\n| **Single Ralph** | One feature at a time | 1 VM, feature branch | Sequential |\n| **Multi-Ralph Fleet** | Parallel features | N VMs, fleet dispatch | Parallel |\n| **Multi-Ralph per VM** | Resource constrained | 2-4 Ralphs in 1 VM | Density |\n\n**Compound Effect**: Each cycle makes the next faster (compound interest on quality).\n\nSee **[WORKFLOW.md](./WORKFLOW.md)** for detailed patterns.\n\n## Documentation\n\n| Document | Description | Self-Contained |\n|----------|-------------|----------------|\n| [QUICKSTART.md](./QUICKSTART.md) | End-to-end tutorial | ❌ (needs Repo) |\n| [WORKFLOW.md](./WORKFLOW.md) | Workflow patterns, 80/20 Rule | ❌ (needs Repo) |\n| [specs/INTERVIEW.md](./specs/INTERVIEW.md) | 10-Question Interview Guide | ✅ (via `fabrik spec interview`) |\n| [prompts/COMPOUND-ENGINEERING.md](./prompts/COMPOUND-ENGINEERING.md) | Todo Generation | ✅ (via `fabrik todo generate`) |\n| [prompts/reviewers/](./prompts/reviewers/) | 8 Reviewer Prompts | ⚠️ (if available) |\n| [OBSERVABILITY.md](./OBSERVABILITY.md) | Telemetry, LAOS Setup | ❌ (needs Repo) |\n| [SETUP-MACOS.md](./SETUP-MACOS.md) | macOS setup with Lima | ❌ (needs Repo) |\n| [SETUP-LINUX.md](./SETUP-LINUX.md) | Linux setup with libvirt | ❌ (needs Repo) |\n| [CI-CD.md](./CI-CD.md) | CI/CD with self-hosted runners | ❌ (needs Repo) |\n| [dtechvision/laos](https://github.com/dtechvision/laos) | LAOS Observability (external) | N/A |\n\n## Scripts\n\n| Script | Purpose |\n|--------|---------|\n| `create-ralph.sh` | Create a new Ralph VM |\n| `setup-base-vm.sh` | Install tools inside VM (run once, snapshot) |\n| `smithers-fleet.sh` | Dispatch multiple Smithers workflows |\n| `smithers-spec-runner.tsx` | Default Smithers workflow for spec/todo |\n| `smithers-reviewer.tsx` | Smithers reviewer workflow template |\n| `cleanup-workdirs.sh` | Cleanup old immutable workdirs |\n| `record-human-feedback.sh` | Record human review decision/notes |\n| `list-ralphs.sh` | Show all VMs and status |\n| `cleanup-ralphs.sh` | Delete VMs |\n\n## CLI (Fabrik)\n\nBuild and run the single binary CLI:\n\n```bash\nbun install\nbun run build\n./dist/fabrik flow\n```\n\n### Standalone binary (embedded assets)\n\nThe `fabrik` binary embeds:\n- default prompts + reviewer prompts\n- default Smithers workflows\n- helper scripts (dispatch/cleanup/fleet)\n- docs (README/WORKFLOW/QUICKSTART/specs README)\n\nIf `LOCAL_RALPH_HOME` (or `~/git/local-isolated-ralph`) is missing, `fabrik` writes embedded assets\nto `~/.cache/fabrik/embedded/<hash>/` and runs from there.\n\nCommon commands:\n\n```bash\n# === COMPOUND ENGINEERING: PLANNING (80%) ===\n\n# Spec Interview: 10-Fragen Guide (self-contained)\nfabrik spec interview | tee /tmp/spec-prompt.txt\ncat /tmp/spec-prompt.txt | claude-code  # Output: specs/feature.json\n\n# Todo Generation: Task-Decomposition Guide (self-contained)  \nfabrik todo generate | tee /tmp/todo-prompt.txt\ncat /tmp/todo-prompt.txt | claude-code   # Output: specs/feature.todo.json\n\n# Validate JSON Schema\nfabrik spec validate\nfabrik spec minify   # Optional: .min.json für Dispatch\n\n# === COMPOUND ENGINEERING: EXECUTION (20%) ===\n\n# Single Run\nfabrik run --spec specs/feature.json --todo specs/feature.todo.json --vm ralph-1\n\n# Mit Ziel-Repo außerhalb VM\nfabrik run ... --project ~/projects/my-app\n\n# Mit Custom Reviewern\nfabrik run ... --review-max 3 --review-models ./reviewer-models.json\n\n# Fleet (Multi-VM)\nfabrik fleet --specs-dir specs --vm-prefix ralph\n\n# === MONITORING & REVIEW ===\n\n# Desktop Notifications bei Blockierung\nfabrik runs watch --vm ralph-1\n\n# Run Details\nfabrik runs list --limit 10\nfabrik runs show --id 42  # Mit failure_reason wenn verfügbar\n\n# Human Gate (bindend, kein Timeout)\nfabrik feedback --vm ralph-1 --spec specs/feature.json \\\n  --decision approve --notes \"Implementation correct\"\n\n# === INFRASTRUKTUR ===\n\n# LAOS (Observability)\nfabrik laos up\nfabrik laos status\nfabrik laos logs --follow\nfabrik laos down\n\n# Credentials sync\nfabrik credentials sync --vm ralph-1\n\n# Dependency maintenance\nfabrik deps check\nfabrik deps update --bun\nfabrik deps update --smithers\nfabrik deps update --bun\nfabrik deps update --smithers\nfabrik deps update --bun --smithers\n```\n\nDependency policy:\n- Direct deps are pinned (no `latest`/range drift).\n- New direct deps require explicit approval.\n- CI enforces policy with `bun run deps:policy`.\n- Install the local pre-commit hook once: `bun run hooks:install`.\n\n`fabrik laos` clones/pulls `https://github.com/dtechvision/laos` with **jj** (or `git` if jj is missing)\ninto `~/.cache/fabrik/laos` and runs `docker compose`.\n\n### Use the CLI from another repo\n\nFrom any repo (e.g. `~/git/<your-repo>`):\n\n```bash\n# Build once (in local-ralph)\ncd ~/git/local-isolated-ralph\nbun install\nbun build src/fabrik/bin.ts --compile --outfile dist/fabrik\n\n# Use from another repo\ncd ~/git/<your-repo>\n~/git/local-isolated-ralph/dist/fabrik spec validate\n~/git/local-isolated-ralph/dist/fabrik spec minify\n~/git/local-isolated-ralph/dist/fabrik run --spec specs/001-foo.json --vm ralph-1\n```\n\n### Binary Releases (GitHub)\n\nThe repo ships prebuilt `fabrik` binaries for:\n- macOS ARM64 (`darwin-arm64`)\n- Linux x64 (`linux-x64`)\n- Linux ARM64 (`linux-arm64`)\n\nRelease process:\n\n```bash\ngit tag v0.1.0\ngit push origin v0.1.0\n```\n\nOr trigger the workflow manually with a tag (GitHub Actions UI).\n\nIf your local-ralph repo lives elsewhere, set:\n\n```bash\nexport LOCAL_RALPH_HOME=/path/to/local-isolated-ralph\n```\n\n### Smithers (Required Orchestration + JJ)\n\nSmithers is required. Fabrik dispatches minified spec/todo JSON for token efficiency and Smithers executes tasks with durable state. It always runs an agent reviewer and writes review outputs to the Smithers SQLite db (`review_report`, `review_summary`) along with a `human_gate` row for human approval. Version control is JJ (colocated Git backend).\n\nDefault models:\n- Claude: `opus`\n- Codex: `gpt-5.2-codex` (reasoning `medium`, sandbox `danger-full-access`)\n\nPROMPT control:\n- Pass `--prompt` to prepend a per-run `PROMPT.md` (implementation instructions).\n- Pass `--review-prompt` to prepend reviewer instructions.\nThese files are prepended before the spec/todo content in Smithers.\nDefaults live in `prompts/DEFAULT-IMPLEMENTER.md` and `prompts/DEFAULT-REVIEWER.md`.\nReview pipeline (default):\n- Security\n- Code Quality\n- Minimal Simplicity\n- Test Coverage\n- Maintainability\n\nReviewer prompts live in `prompts/reviewers/*.md` and are copied into each run.\n\nReviewer model config (optional):\nCreate `reviewer-models.json` to map reviewers to models:\n\n```json\n{\n  \"_default\": \"sonnet\",\n  \"security\": \"sonnet\",\n  \"code-quality\": \"sonnet\",\n  \"simplicity\": \"sonnet\",\n  \"test-coverage\": \"sonnet\",\n  \"maintainability\": \"sonnet\"\n}\n```\n\nBackpressure:\n- If any reviewer requests changes, Smithers generates follow-up review tasks in the workflow and records them in the SQLite db.\n- The review pipeline reruns after review tasks.\n- Only when all reviewers approve does the human gate row appear.\n\nRun context audit:\n- Each run writes `reports/run-context.json` with prompt contents + hashes.\n\n```bash\n# Install in VM if missing\n# bun add -g github:evmts/smithers#ea5ece3b156ebd32990ec9c528f9435c601a0403\n\n# Local workflow (uses scripts/smithers-spec-runner.tsx by default)\n./dist/fabrik run --spec specs/000-base.json --vm ralph-1\n\n# With custom prompts\n./dist/fabrik run --spec specs/000-base.json --vm ralph-1 \\\n  --prompt ./prompts/PROMPT-implementer.md \\\n  --review-prompt ./prompts/PROMPT-reviewer.md\n\n# Custom TODO and workflow\n./dist/fabrik run --spec specs/010-weekly-summary.json --todo specs/010-weekly-summary.todo.json \\\n  --workflow scripts/smithers-spec-runner.tsx --model sonnet --vm ralph-1\n\n# Review runs automatically after tasks; Smithers writes review outputs + human gate into the SQLite db.\n```\n\n### Smithers Workflow Diagram\n\n```\nspec.json + todo.json\n   (minified on dispatch)\n          │\n          ▼\n  Smithers workflow\n  (Ralph loop in React)\n          │\n          ├─ task 1 → task_report row\n          ├─ task 2 → task_report row\n          └─ task N → task_report row\n          │\n          ▼\n     DONE / BLOCKED / FAILED\n```\n\n### Reviewer Template (Standalone)\n\nUse the built-in Smithers reviewer workflow:\n\n```bash\n./dist/fabrik run --spec specs/feature.json --vm ralph-review --workflow scripts/smithers-reviewer.tsx\n```\n\n### JJ Primer (Required VCS)\n\nJJ uses a colocated Git backend. The repo still has `.git`, but you use `jj` commands.\n\n```\nClone:              jj git clone <url> <dir>\nInit in repo:       jj git init\nStart change:       jj new master\nStatus:             jj status\nDiff:               jj diff\nDescribe change:    jj describe\nPush change:        jj git push --change @\n```\n\nSet your JJ identity (recommended):\n```bash\njj config set --user user.name \"Your Name\"\njj config set --user user.email \"you@company.com\"\n```\n\nIf JJ identity is missing, fabrik falls back to git identity (if set) or uses defaults.\n\n### Changesets + JJ\n\nChangesets stays the same; JJ only replaces Git commands locally:\n\n```bash\n# Create a changeset for your PR\nbunx changeset\n\n# Work in a new JJ change\njj new master\n\n# Review + commit\njj status\njj diff\njj describe\n\n# Push the change\njj git push --change @\n```\n\n### fabrik run Options\n\n```bash\n./dist/fabrik run --spec <path> --vm <vm-name> [--todo <path>] \\\n  [--project <dir>] [--repo <url>] [--ref <branch>] [--include-git] \\\n  [--workflow <path>] [--report-dir <path>] [--model <name>] \\\n  [--prompt <path>] [--review-prompt <path>] [--review-models <path>] [--review-max <n>] \\\n  [--iterations <n>] [--follow]\n\n# Example with .git included (enables push from synced project)\nRALPH_AGENT=pi ./dist/fabrik run --include-git --spec specs/000-base.json --vm ralph-1 --project ~/projects/app --iterations 20\n```\n\n- `--include-git` - Include `.git` in sync (otherwise agent must clone from repo URL)\n- `--spec` - Spec JSON (minified on dispatch for Smithers mode)\n- `--todo` - TODO JSON (minified on dispatch for Smithers mode)\n- `--workflow` - Smithers workflow script (default: `scripts/smithers-spec-runner.tsx`)\n- `--report-dir` - Report output directory inside VM (default: workdir/reports)\n- `--model` - Model name for Smithers agent\n- `--prompt` - PROMPT.md prepended to every task prompt\n- `--review-prompt` - Reviewer PROMPT.md prepended to review prompt\n- `--review-max` - Max review reruns before human gate (default: 2)\n- `--review-models` - JSON map of reviewer_id -> model\n- `RALPH_AGENT` - Agent to use: `pi` (default), `claude`, `codex`\n- `MAX_ITERATIONS` - Max loops (default: 100, 0 = unlimited)\n\nEach dispatch creates a timestamped work directory (`/home/ralph/work/<vm>/<project>-<timestamp>/`), enabling parallel dispatches to the same VM.\n\nFailure reporting:\n- `fabrik runs show --id <run-id>` prints `failure_reason` when a run fails (derived from `reports/smithers.log`).\n- Stale or missing heartbeats are marked as `failure_reason: stale_process`.\n\n## Resource Planning\n\n| Host RAM | Recommended Setup |\n|----------|-------------------|\n| 16GB | 4 light VMs (2 CPU, 4GB each) |\n| 32GB | 8 light VMs or 4 medium VMs |\n| 64GB+ | 8+ medium VMs, or density mode |\n\n**Density mode:** Run 2-4 Ralphs per VM when working on separate directories.\n\n## Credentials Setup\n\nAgents need `GITHUB_TOKEN` to push code and create PRs.\n\n1. Create token: https://github.com/settings/tokens/new (scopes: `repo`, `workflow`)\n2. Add to `~/.config/ralph/ralph.env`:\n   ```bash\n   export GITHUB_TOKEN=\"ghp_your_token_here\"\n   ```\n3. Run `./scripts/create-ralph-env.sh` to create the env file, or `./scripts/sync-credentials.sh <vm>` to update existing VMs\n\nThe token is used by both `git push/pull` (credential helper) and `gh` CLI (auto-detects env var).\n\nAgent auth files are synced to VMs when you run `fabrik credentials sync` (or the bash equivalent).\n\nRequired by default (pi):\n- `~/.pi/agent/auth.json` (created by `pi` then `/login`)\n\nOptional (only if using `RALPH_AGENT=codex`):\n- `~/.codex/auth.json` (created by `codex login`)\n\nOptional (only if using `RALPH_AGENT=claude`):\n- `~/.claude` or `~/.claude.json` (created by `claude login` / `claude setup-token`)\n\n## Prerequisites\n\n```bash\n# Docker (for LAOS)\ndocker --version\n\n# SSH key (for VM access)\nls ~/.ssh/id_rsa.pub || ssh-keygen -t rsa -b 4096\n\n# macOS: Colima 0.6+\nbrew install colima docker\n\n# Linux: libvirt + KVM\nsudo apt install qemu-kvm libvirt-daemon-system virtinst\n```\n\n## The Goal\n\n```\nBefore:  Human writes code, human reviews code, human ships\nAfter:   Human writes spec ──────────────────► Human gets \"shipped\" notification\n                           (agents do the rest)\n```\n\n## Disk Usage\n\nDisk usage to watch:\n  - ~/.lima/ - VM disks (20GB+ per VM)\n  - ~/.cache/ralph/ - Downloaded images (~6GB per\n  architecture)\n  - ~/vms/ralph/ - libvirt VM disks on Linux\n\nFor the cloud-hosted version of this, see [Sprites](https://sprites.dev) + [Wisp](https://github.com/thruflo/wisp).\n### Immutable Runs + Local DB\n\nEach Smithers run gets a new workdir. Runs are tracked in a local SQLite DB:\n\n```\n~/.cache/ralph/ralph.db\n```\n\nCleanup old runs:\n\n```bash\n./scripts/cleanup-workdirs.sh ralph-1 --keep 5\n```\n\nRecord human feedback:\n\n```bash\n./scripts/record-human-feedback.sh --vm ralph-1 --spec specs/010-weekly-summary.json \\\n  --decision approve --notes \"Looks good.\"\n```\nSpec is explicit:\n- You choose the spec with `--spec`, not inside the prompt.\n\nContext stack now:\n\n```\n[\n  PROMPT.md (global instructions, if provided),\n  spec.json-derived system prompt,\n  task.do / task.verify,\n  JJ instructions,\n  report schema\n]\n```\n\nReviewer stack:\n\n```\n[\n  REVIEW_PROMPT.md (if provided),\n  reviewer-specific prompt (from prompts/reviewers/*.md),\n  spec.json-derived system prompt,\n  Smithers db task_report rows,\n  review schema\n]\n```\n" },
  { path: "WORKFLOW.md", contents: "# Workflow Guide: Compound Engineering with Fabrik\n\n**Scope**: Complete workflow from Spec creation to Human Gate.\n\n**Implicit Assumption**: Reader has completed QUICKSTART.md and understands the 80/20 rule (80% Planning, 20% Execution).\n\n---\n\n## 1. Compound Engineering: The 4 Principles\n\n### 1.1 Plan thoroughly before writing code\n- Spec is the contract. Changes cost 10x.\n- No implementation without completed interview.\n\n### 1.2 Review to catch issues and capture learnings\n- 8 Reviewers (automatic, parallel).\n- Every finding becomes a reusable pattern.\n\n### 1.3 Codify knowledge so it's reusable\n- `@property` TSDoc names invariants explicitly.\n- Branded Types prevent primitive obsession.\n- Todo templates documented in `prompts/reviewers/`.\n\n### 1.4 Keep quality high so future changes are easy\n- 6 Guarantee Layers (L1-L6).\n- Higher quality = faster next cycle.\n\n---\n\n## 2. The Workflow (Step-by-Step)\n\n### Phase 1: Spec Creation (40% of time)\n\n```bash\n# Step 1: Output interview guide\n./dist/fabrik spec interview | tee /tmp/spec-interview.txt\n\n# Step 2: Run with agent\n# Input: Conversation with agent about the 10 questions\n# Output: specs/{id}.json\ncat /tmp/spec-interview.txt | claude-code\n\n# Step 3: Validate\n./dist/fabrik spec validate\n```\n\n**The 10 Questions** (implicit in `fabrik spec interview`):\n1. IDENTITY: Kebab-case ID\n2. TITLE: One sentence, active voice, NO implementation\n3. STATUS: draft | ready | in-progress | review | done | superseded\n4. GOALS: 3-7 outcomes, MUST accomplish, NO implementation details\n5. NON-GOALS: Explicitly out of scope (prevents creep)\n6. API: Interfaces, signatures, branded types, error channels\n7. BEHAVIOR: Business rules, state transitions, edge cases\n8. OBSERVABILITY: Metrics, logs, alerts, health checks\n9. ACCEPTANCE: Testable criteria, performance thresholds\n10. ASSUMPTIONS: What could change (deps, platform, volume)\n\n**Critical**: Spec must have `status: \"ready\"` before next step.\n\n---\n\n### Phase 2: Todo Generation (40% of time)\n\n```bash\n# Step 1: Output todo guide\n./dist/fabrik todo generate | tee /tmp/todo-guide.txt\n\n# Step 2: Run with agent\n# Input: specs/{id}.json\n# Output: specs/{id}.todo.json\ncat /tmp/todo-guide.txt | claude-code\n\n# Step 3: Validate\n./dist/fabrik spec validate\n```\n\n**Criticality Tier** (determines DoD):\n\n| Tier | Examples | Layers |\n|------|----------|--------|\n| T1 | Money, Auth, Signing, irreversible State | ALL 6 (L1-L5 + Simulation) |\n| T2 | User data, Business logic, State machines | L1-L5 |\n| T3 | Features, UI state, Caching | L1-L4 |\n| T4 | Analytics, Logging, Metrics | L1, L4 |\n\n**T1 DoD** (all must be checked):\n- [ ] L1: Branded types\n- [ ] L2: Effect.assert for pre/postconditions\n- [ ] L3: DB UNIQUE/CHECK constraints\n- [ ] L4: @property TSDoc on every invariant test\n- [ ] L4: Property-based tests (conservation, idempotency)\n- [ ] L4: 90%+ line coverage, 85%+ branch coverage\n- [ ] L5: TODOs for production alerts\n- [ ] L6: Seed-based simulation plan\n- [ ] Review: All 8 reviewers approved\n- [ ] VCS: Pushed to GitHub, CI passed\n- [ ] Human: Gate cleared\n\n---\n\n### Phase 3: Execution (20% of time)\n\n```bash\n# Single-VM Workflow\n./dist/fabrik run \\\n  --spec specs/feature.json \\\n  --todo specs/feature.todo.json \\\n  --vm ralph-1 \\\n  --project /path/to/target/repo        # Optional: target repo outside VM\n```\n\n**Internal Flow**:\n\n```\nspec.json + todo.json (minified)\n           │\n           ▼\n    smithers-spec-runner.tsx\n           │\n           ├─ Sequential Tasks (with skipIf on error)\n           ├─ JJ: jj new main && jj bookmark create feature-1\n           ├─ Work → jj describe → jj git push --branch feature-1\n           │\n           ▼\n    Review Loop (Ralph until maxIterations)\n           ├─ 8 Reviewers parallel\n           ├─ On \"changes_requested\": Generate review tasks\n           └─ Resubmit until \"approved\" or max reached\n           │\n           ▼\n    Human Gate (blocked)\n           └─ Waits for: fabrik feedback --decision approve\n```\n\n---\n\n## 3. VCS Strategies (JJ)\n\n### 3.1 Single-Ralph: Feature Branch\n\n```bash\n# In VM (automatic by agent)\njj new main\njj bookmark create feature-1\n# ... work ...\njj describe -m \"feat(feature-1): implement X\"\njj git push --branch feature-1\n```\n\n**Implicit Assumption**: Agent works in `/home/ralph/work/...` directory, not on host.\n\n### 3.2 Multi-Ralph: Separate VMs\n\n```bash\n# Host: Start multiple runs\n./dist/fabrik run --spec specs/auth.json --vm ralph-1 &\n./dist/fabrik run --spec specs/dashboard.json --vm ralph-2 &\n./dist/fabrik run --spec specs/api-fix.json --vm ralph-3 &\n\n# Monitor\n./dist/fabrik runs watch --vm ralph-1 &\n./dist/fabrik runs watch --vm ralph-2 &\n./dist/fabrik runs watch --vm ralph-3 &\n```\n\n**Implicit Assumption**: Each VM has own workdir. No collisions possible.\n\n### 3.3 Multi-Ralph: Fleet Mode\n\n```bash\n./dist/fabrik fleet \\\n  --specs-dir specs \\\n  --vm-prefix ralph \\\n  --project /path/to/repo\n```\n\n**Implicit Assumption**: Fleet matches specs/*.json to available VMs (ralph-1, ralph-2, ...).\n\n---\n\n## 4. Review Pipeline (8 Reviewers)\n\n**Parallel Execution**:\n\n```\nParallel:\n  ├─ security\n  ├─ code-quality\n  ├─ simplicity\n  ├─ test-coverage\n  ├─ maintainability\n  ├─ tigerstyle\n  ├─ nasa-10-rules\n  └─ correctness-guarantees\n```\n\n**Reviewer Prompts**: `prompts/reviewers/{id}.md`\n\n**Custom Models** (optional):\n```json\n// reviewer-models.json\n{\n  \"_default\": \"sonnet\",\n  \"security\": \"opus\",\n  \"correctness-guarantees\": \"opus\"\n}\n```\n\n```bash\n./dist/fabrik run ... --review-models ./reviewer-models.json --review-max 3\n```\n\n---\n\n## 5. Human Gate\n\n**State**: After review loop, `human_gate` row written:\n\n```json\n{\n  \"v\": 1,\n  \"status\": \"blocked\",\n  \"reason\": \"Human review required before next spec run.\"\n}\n```\n\n**Actions**:\n\n```bash\n# Approve\n./dist/fabrik feedback \\\n  --vm ralph-1 \\\n  --spec specs/feature.json \\\n  --decision approve \\\n  --notes \"Implementation correct. Tests pass.\"\n\n# Reject (with reason for re-run)\n./dist/fabrik feedback \\\n  --vm ralph-1 \\\n  --spec specs/feature.json \\\n  --decision reject \\\n  --notes \"Security issue in auth flow. Fix and re-run.\"\n```\n\n**Implicit Assumption**: No automatic transition from \"blocked\". Human decision is binding.\n\n---\n\n## 6. Monitoring & Debugging\n\n### 6.1 Live Monitoring\n\n```bash\n# Terminal 1: Desktop notifications\n./dist/fabrik runs watch --vm ralph-1\n\n# Terminal 2: Stream logs\n./dist/fabrik laos logs --follow\n\n# Browser: Grafana\nopen http://localhost:3010/explore\n```\n\n### 6.2 Post-Mortem\n\n```bash\n# Run details\n./dist/fabrik runs show --id <run-id>\n\n# Output includes:\n# - failure_reason (if failed)\n# - blocked_task (if blocked)\n# - reports/run-context.json (prompt hashes)\n# - .smithers/*.db (SQLite with all reports)\n\n# Inspect SQLite\nsqlite3 .smithers/feature.db \"SELECT * FROM taskReport;\"\nsqlite3 .smithers/feature.db \"SELECT * FROM reviewReport;\"\nsqlite3 .smithers/feature.db \"SELECT * FROM humanGate;\"\n```\n\n---\n\n## 7. Compound Effect: The Flywheel\n\n**Month 1**: Slower than \"just coding\" (planning overhead)\n**Month 3**: Same speed, fewer bugs\n**Month 6**: Faster than traditional (patterns established)\n**Month 12**: 2-3x Velocity (compound interest on quality)\n\n**Mechanism**:\n1. Spec → Reusable requirement patterns\n2. Todo → Reusable task templates\n3. Reviewers → Reusable checklists\n4. L1-L6 → Each change safer than previous\n\n---\n\n## 8. Command Reference\n\n| Command | Purpose | Output |\n|---------|---------|--------|\n| `fabrik spec interview` | 10-question guide | Terminal (pipe to agent) |\n| `fabrik todo generate` | Todo guide | Terminal (pipe to agent) |\n| `fabrik spec validate` | JSON Schema check | Exit code 0/1 |\n| `fabrik spec minify` | Generate .min.json | Filesystem |\n| `fabrik run ...` | Workflow dispatch | SQLite + Reports |\n| `fabrik runs list` | Overview all runs | Table |\n| `fabrik runs show --id X` | Single run detail | JSON |\n| `fabrik runs watch` | Desktop notifications | Desktop popup |\n| `fabrik feedback ...` | Human Gate decision | SQLite update |\n| `fabrik fleet ...` | Multi-VM dispatch | SQLite + Reports |\n\n---\n\n## 9. Implicit Assumptions (Critical)\n\n1. **VCS**: JJ installed and configured (`jj --version`)\n2. **Auth**: `~/.pi/agent/auth.json` exists (or codex/claude equivalent)\n3. **Token**: `GITHUB_TOKEN` set and valid (scope: `repo`, `workflow`)\n4. **LAOS**: Running on localhost:3010 (for logs/metrics)\n5. **VMs**: Exist and reachable (`fabrik laos status` shows healthy)\n6. **Network**: VMs can reach GitHub (firewall/egress allowed)\n7. **Disk**: VMs have >10GB free for repos + dependencies\n8. **Order**: Spec → Todo → Run (binding, not skippable)\n9. **Human Gate**: Requires explicit feedback (no timeout)\n10. **Review**: 8 reviewers run parallel (network/bandwidth required)\n" },
  { path: "LEARNINGS.md", contents: "# Fabrik Learnings - Handoff Document\n\n**Date**: 2026-02-15  \n**Status**: ✅ Ready for production use  \n**Last Updated**: After sync fix and credential validation\n\n---\n\n## Quick Start for New Developer\n\n### 1. Build the CLI\n\n```bash\ncd ~/git/local-isolated-ralph\nbun install\nbun run build\n\n# Verify\n./dist/fabrik --version\n```\n\n### 2. Validate Your Environment\n\n```bash\n# Check ralph.env is properly configured\n./dist/fabrik credentials validate\n\n# If issues found, run fix script\n./scripts/validate-ralph-env.sh\n\n# Sync to VM\n./dist/fabrik credentials sync --vm ralph-1\n```\n\n### 3. Run a Spec\n\n```bash\n# Default: sequential workflow (small-to-medium specs)\n./dist/fabrik run \\\n  --spec specs/feature.md \\\n  --project ~/my-app \\\n  --vm ralph-1 \\\n  --follow\n\n# Dynamic: runtime discovery (large specs >20 tasks)\n./dist/fabrik run \\\n  --spec specs/big-prd.md \\\n  --project ~/my-app \\\n  --vm ralph-1 \\\n  --dynamic \\\n  --follow\n```\n\n---\n\n## Architecture Overview\n\n### Workflow Selection\n\n| Mode | File | Use Case | Command |\n|------|------|----------|---------|\n| **Sequential** (default) | `workflow.tsx` | 5-20 tasks, clear milestones | `fabrik run --spec ...` |\n| **Dynamic** | `workflow-dynamic.tsx` | >20 tasks, evolving scope | `fabrik run --spec ... --dynamic` |\n| **Custom** | Your file | Special requirements | `fabrik run --workflow ./custom.tsx` |\n\n### Three-Phase Execution (Both Workflows)\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│ Phase 1: Task Implementation (Ralph Loop)                       │\n│ Implement → Validate → LightReview → ReviewFix (if issues)      │\n│     ↑__________________________________________↓                │\n│ Loop until CODE-QUALITY + MAINTAINABILITY approve                │\n└─────────────────────────────────────────────────────────────────┘\n                              ↓ All tasks done\n┌─────────────────────────────────────────────────────────────────┐\n│ Phase 2: Full Review (Ralph Loop)                                │\n│ All 8 Reviewers (parallel) → ReviewFix → Re-validate             │\n│     ↑______________________________________________↓             │\n│ Loop until ALL reviewers approve, then re-run to validate        │\n└─────────────────────────────────────────────────────────────────┘\n                              ↓ All reviews passed\n┌─────────────────────────────────────────────────────────────────┐\n│ Phase 3: Human Gate (needsApproval)                              │\n│ Human reviews → Approve (DONE) or Reject → Feedback → Phase 1    │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n### Reviewers\n\n**Per-Task (Light Review):**\n- `CODE-QUALITY.md`\n- `MAINTAINABILITY.md`\n\n**Full Review (All 8 in Parallel):**\n- `CODE-QUALITY.md`\n- `MAINTAINABILITY.md`\n- `SECURITY.md`\n- `SIMPLICITY.md`\n- `TIGERSTYLE.md`\n" },
  { path: "OBSERVABILITY.md", contents: "# Observability & Analytics for Coding Agents\n\nRalph uses **LAOS** (Local Analytics and Observability Stack) as the shared telemetry backend. This guide covers setup, querying, and troubleshooting.\n\n**LAOS Repository:** https://github.com/dtechvision/laos\n\n## Quick Start\n\n### 1. Start LAOS on the Host\n\n```bash\nmkdir -p ~/git\nif [[ -d ~/git/laos/.git ]]; then\n  (cd ~/git/laos && git pull)\nelse\n  git clone https://github.com/dtechvision/laos.git ~/git/laos\nfi\ncd ~/git/laos && ./scripts/laos-up.sh\n```\n\n### 2. Configure Ralph Environment\n\n```bash\ncd /path/to/local-isolated-ralph\n./scripts/create-ralph-env.sh\n```\n\nEdit `~/.config/ralph/ralph.env`:\n\n```bash\n# macOS (Lima): export LAOS_HOST=\"host.lima.internal\"\n# Linux (libvirt): export LAOS_HOST=\"192.168.122.1\"\nexport LAOS_HOST=\"<your-host>\"\n\n# Telemetry endpoints\nexport OTEL_EXPORTER_OTLP_ENDPOINT=\"http://${LAOS_HOST}:4317\"\nexport LOKI_URL=\"http://${LAOS_HOST}:3100\"\nexport SENTRY_DSN=\"http://<key>@${LAOS_HOST}:9000/1\"\nexport POSTHOG_HOST=\"http://${LAOS_HOST}:8001\"\nexport POSTHOG_API_KEY=\"phc_xxx\"\nexport PYROSCOPE_SERVER_ADDRESS=\"http://${LAOS_HOST}:4040\"\n```\n\n> **Platform Selection:** Set `LAOS_PLATFORM=linux/arm64` for Apple Silicon or ARM64 Linux. Default is `linux/amd64`.\n\n### 3. Sync to VMs\n\n```bash\n./scripts/sync-credentials.sh ralph-1\n# or: fabrik credentials sync --vm ralph-1\n```\n\n### 4. Access Dashboards\n\n| Service | URL | Credentials |\n|---------|-----|-------------|\n| Grafana | http://localhost:3010 | admin/admin |\n| Sentry | http://localhost:9000 | Create on first run |\n| PostHog | http://localhost:8001 | Setup wizard |\n| Pyroscope | http://localhost:4040 | None |\n| Prometheus | http://localhost:9090 | None |\n\n## Query Reference\n\n### Health Checks\n\n```bash\ncurl http://$LAOS_HOST:3100/ready  # Loki\ncurl http://$LAOS_HOST:3200/ready  # Tempo\ncurl http://$LAOS_HOST:9090/-/ready  # Prometheus\ncurl http://$LAOS_HOST:4040/ready  # Pyroscope\ncurl -I http://localhost:8001  # PostHog (expect 302/200)\n```\n\n### Query Patterns by Tool\n\n| Tool | URL/Endpoint | Example Query | Filters/Labels |\n|------|-------------|---------------|----------------|\n| **Loki** | `:3100` | `{service_name=\"smithers\"} \\|= \"ERROR\"` | `vm`, `trace_id`, `level` |\n| **Tempo** | `:4318` | Search by trace ID or `vm=ralph-1` | `service.name`, `task` |\n| **Prometheus** | `:9090` | `rate(http_requests_total[5m])` | `job`, `status`, `vm` |\n| **Pyroscope** | `:4040` | Flame graph: `process_cpu` | `spec_id`, `vm`, `agent_type` |\n| **Sentry** | `:9000` | Issues → Stack trace + breadcrumbs | `trace_id` → links to Tempo |\n| **PostHog** | `:8001` | Events → Real-time stream | `distinct_id`, `source` |\n\n### Detailed Query Examples\n\n**Loki (Logs):**\n```logql\n# All Smithers logs\n{service_name=\"smithers\"}\n\n# Errors only\n{service_name=\"smithers\"} |= \"ERROR\"\n\n# Specific VM\n{service_name=\"smithers\", vm=\"ralph-1\"}\n\n# Parse JSON\n{service_name=\"smithers\"} | json | line_format \"{{.level}}: {{.message}}\"\n```\n\n**Prometheus (Metrics):**\n```promql\n# Service health\nup{job=\"agent-metrics\"}\n\n# Request rate\nrate(http_requests_total{job=\"smithers\"}[5m])\n\n# Error rate\nrate(http_requests_total{status=~\"5..\"}[5m])\n\n# P95 latency\nhistogram_quantile(0.95, rate(task_duration_seconds_bucket[5m]))\n```\n\n**Pyroscope (Profiles):**\n1. **View:** Select app → profile type (`process_cpu`, `memory`, `wall`)\n2. **Compare:** Select two time ranges → \"Compare\" → diff flame graph\n3. **Correlate:** In Tempo trace, click span → \"View Profile\"\n\n**Sentry (Headless verification):**\n```bash\nEVENT_ID=$(uuidgen | tr -d '-' | tr 'A-Z' 'a-z')\nDSN=\"http://YOUR_KEY@localhost:9000/2\"\nprintf '{\"event_id\":\"%s\"}\\n{\"type\":\"event\"}\\n{\"message\":\"test\",\"level\":\"error\"}\\n' \\\n  \"$EVENT_ID\" > /tmp/envelope.txt\ncurl -X POST \"http://localhost:9000/api/2/envelope/\" \\\n  -H \"Content-Type: application/x-sentry-envelope\" \\\n  --data-binary @/tmp/envelope.txt\n```\n\n## Smithers Integration\n\n### Effect-TS Observability Layer\n\n```typescript\nimport * as Otlp from \"@effect/opentelemetry/Otlp\"\nimport { NodeHttpClient } from \"@effect/platform-node\"\nimport { Config, Effect, Layer } from \"effect\"\n\nexport const OtlpLive = Layer.unwrapEffect(\n  Effect.gen(function* () {\n    const otlpEndpoint = yield* Config.string(\"OTLP_ENDPOINT\").pipe(\n      Config.orElse(() => Config.succeed(\"http://localhost:4318\")),\n    )\n    const serviceName = yield* Config.string(\"SERVICE_NAME\").pipe(\n      Config.orElse(() => Config.succeed(\"ralph-agent\")),\n    )\n    return Otlp.layer({\n      baseUrl: otlpEndpoint,\n      resource: { serviceName, attributes: { \"deployment.environment\": \"development\" } },\n    }).pipe(Layer.provide(NodeHttpClient.layerUndici))\n  }),\n)\n```\n\n### Task Instrumentation\n\n```typescript\nconst instrumentedTask = Effect.gen(function* () {\n  yield* Effect.logInfo(\"Starting task\")\n  const result = yield* processTask()\n  yield* Metric.counter(\"tasks_completed\").pipe(Metric.increment)\n  return result\n}).pipe(Effect.withSpan(\"task-execution\", { attributes: { task_id: \"001\", vm: \"ralph-1\" } }))\n```\n\n### Profiling with Labels\n\n```typescript\nexport const handleSpecRun = (spec: string) =>\n  Effect.gen(function* () {\n    const profiling = yield* Profiling\n    return yield* profiling.withLabels(\n      { spec_id: spec, vm: process.env.VM_NAME || \"unknown\" },\n      Effect.promise(() => runSmithersWorkflow(spec)),\n    )\n  })\n```\n\n## Troubleshooting\n\n### No Telemetry Appearing\n\n```bash\n# 1. Verify LAOS is running\ncd ~/git/laos && docker compose ps\n\n# 2. Check service health\ncurl http://$LAOS_HOST:3100/ready  # Loki, etc.\n\n# 3. Check LAOS_HOST (macOS: host.lima.internal, Linux: 192.168.122.1)\n\n# 4. Sync credentials\n./scripts/sync-credentials.sh ralph-1\n\n# 5. Test from inside VM\nlimactl shell ralph-1\ncurl http://$LAOS_HOST:3100/ready\n```\n\n### Root Cause Analysis Flow\n\n```\nGrafana Dashboard → \"Error rate spike\"\n       ↓\nSentry → \"NullReferenceException in auth.ts:42\"\n       ↓\nTempo Trace → DB call span = 5s\n       ↓\nLoki Logs → \"Connection timeout to postgres\"\n       ↓\nPyroscope → CPU saturated on connection pool\n```\n\nAll signals linked by `trace_id` and `span_id`.\n\n### Common Issues\n\n| Issue | Solution |\n|-------|----------|\n| macOS ARM64 platform errors | `softwareupdate --install-rosetta --agree-to-license` |\n| Port conflicts | `lsof -i :3010 :9000 :8001` |\n| PostHog slow startup | Normal, wait for `curl -I localhost:8001` to return 302 |\n| Reset everything | `docker compose down -v && docker compose up -d` |\n\n## Further Reading\n\n- **LAOS Repository:** https://github.com/dtechvision/laos\n- **LAOS Setup Guide:** `~/git/laos/SETUP-LAOS.md`\n- **Effect + Telemetry:** `~/git/laos/examples/observability-layer.ts`\n- **Profiling:** `~/git/laos/PYROSCOPE.md`\n" },
  { path: "QUICKSTART.md", contents: "# Compound Engineering: Quickstart\n\n**Prerequisite**: Complete platform-specific setup first (SETUP-MACOS.md or SETUP-LINUX.md).\n\n**Implicit Assumption**: All commands run from `local-isolated-ralph` directory unless specified otherwise.\n\n---\n\n## 1. Pre-flight Check\n\n```bash\n# Agent authentication\npi --version        # Must be installed\npi /login           # Run once, creates ~/.pi/agent/auth.json\n\n# GitHub Token (for push/PR)\nexport GITHUB_TOKEN=\"ghp_...\"   # Or in ~/.config/ralph/ralph.env\n\n# Optional: Alternative agents\n# codex login        # Only if RALPH_AGENT=codex\n# claude auth login  # Only if RALPH_AGENT=claude\n```\n\n**Implicit Assumption**: Without `GITHUB_TOKEN`, the agent cannot push branches. Workflow will block.\n\n---\n\n## 2. Start LAOS (Observability)\n\n```bash\nfabrik laos up\nfabrik laos status   # Must show \"healthy\"\n```\n\n**Implicit Assumption**: LAOS runs on localhost:3010 (Grafana). Agent sends logs there.\n\n---\n\n## 3. Create VM\n\n```bash\nfabrik laos up                              # 1. Observability\n./scripts/create-ralph.sh ralph-1 4 8 30    # 2. VM (4 CPU, 8GB RAM, 30GB disk)\n./scripts/setup-base-vm.sh                  # 3. Setup (run INSIDE the VM)\n```\n\n**Implicit Assumption**: `setup-base-vm.sh` must run INSIDE the VM, not on the host.\n\n**macOS**: `colima ssh -p ralph-1`\n**Linux**: `ssh ralph@$(virsh domifaddr ralph-1 | grep ipv4 | awk '{print $4}' | cut -d/ -f1)`\n\n---\n\n## 4. Compound Engineering Workflow\n\n**Principle**: 80% Planning, 20% Execution\n\n### Phase 1: Create Spec (40%)\n\n```bash\n# Output interview guide (self-contained, no external files needed)\n./dist/fabrik spec interview | tee /tmp/interview-prompt.txt\n\n# Run with agent, Output: specs/feature.json\ncat /tmp/interview-prompt.txt | claude-code\n\n# Validate\n./dist/fabrik spec validate\n```\n\n**Critical**: Spec must exist before Todo. Order is binding.\n\n### Phase 2: Generate Todo (40%)\n\n```bash\n# Output todo guide\n./dist/fabrik todo generate | tee /tmp/todo-prompt.txt\n\n# Run with agent, Input: specs/feature.json, Output: specs/feature.todo.json\ncat /tmp/todo-prompt.txt | claude-code\n\n# Validate\n./dist/fabrik spec validate\n```\n\n**Implicit Assumption**: Todo without Spec is invalid. Link via identical `id`.\n\n### Phase 3: Dispatch Workflow (20%)\n\n```bash\n# Single run\n./dist/fabrik run \\\n  --spec specs/feature.json \\\n  --todo specs/feature.todo.json \\\n  --vm ralph-1 \\\n  --project /path/to/target/repo    # Optional: target repo outside VM\n```\n\n**Implicit Assumption**: `--project` copies repo into VM. Agent works there, not on host.\n\n---\n\n## 5. Monitoring\n\n```bash\n# Terminal 1: Watch\n./dist/fabrik runs watch --vm ralph-1\n\n# Browser: Grafana\nopen http://localhost:3010\n\n# Check status\n./dist/fabrik runs list --vm ralph-1\n./dist/fabrik runs show --id <run-id>\n```\n\n**Implicit Assumption**: `runs watch` requires `terminal-notifier` (macOS) or `libnotify-bin` (Linux) for desktop notifications.\n\n---\n\n## 6. Human Gate (Review)\n\nAfter 8 reviewers (automatic) → Human Gate:\n\n```bash\n# Approve or reject\n./dist/fabrik feedback \\\n  --vm ralph-1 \\\n  --spec specs/feature.json \\\n  --decision approve \\\n  --notes \"Implementation correct, tests pass\"\n```\n\n**Implicit Assumption**: Without explicit feedback, run stays `blocked`. No automatic timeout.\n\n---\n\n## Summary: The Compound Cycle\n\n```\n┌────────────────────────────────────────────────────────────────┐\n│  80% PLANNING                                                  │\n│  ├── fabrik spec interview  → specs/feature.json              │\n│  └── fabrik todo generate     → specs/feature.todo.json       │\n├────────────────────────────────────────────────────────────────┤\n│  20% EXECUTION                                                 │\n│  └── fabrik run --spec ... --todo ... --vm ralph-1             │\n│      └── 8 Reviewers → Human Gate → Done                       │\n└────────────────────────────────────────────────────────────────┘\n```\n\n**Compound Effect**: Each completed cycle makes the next faster (reusable patterns, established reviewers).\n\n---\n\n## Troubleshooting\n\n| Symptom | Cause | Solution |\n|---------|-------|----------|\n| \"token in default is invalid\" | GITHUB_TOKEN missing/invalid | `export GITHUB_TOKEN=...` or in `ralph.env` |\n| \"blocked\" forever | Human Gate waiting | `fabrik feedback --decision approve ...` |\n| \"stale_process\" | VM heartbeat timeout | Check VM: `fabrik runs show --id <id>` |\n| Reviewers find nothing | Prompt missing | Check reviewer prompts in `prompts/reviewers/` |\n\n---\n\n## Command Reference\n\n| Command | Purpose |\n|---------|---------|\n| `fabrik spec interview` | 10-question interview guide (self-contained) |\n| `fabrik todo generate` | Todo generation guide (self-contained) |\n| `fabrik spec validate` | Validate Spec/Todo JSON |\n| `fabrik run --spec X --todo Y --vm Z` | Workflow dispatch |\n| `fabrik runs watch --vm Z` | Desktop notifications on block |\n| `fabrik feedback --vm Z --spec X --decision approve` | Release Human Gate |\n| `fabrik laos up/status/down` | Observability stack |\n\n---\n\n## Implicit Assumptions (Critical)\n\n1. **Agent-Auth**: `~/.pi/agent/auth.json` exists (created via `pi /login`)\n2. **GitHub Token**: `GITHUB_TOKEN` is set (for push/PR)\n3. **LAOS**: Running on localhost:3010 (logs/metrics)\n4. **VM**: `ralph-1` exists and is reachable\n5. **Network**: VMs can reach GitHub (for clone/push)\n6. **Disk**: VM has sufficient space for repo + dependencies\n7. **Order**: Spec → Todo → Run (binding)\n8. **Human Gate**: Must explicitly confirm (no auto-approve)\n" },
  { path: "specs/README.md", contents: "# Specs Workflow (Human Guide)\n\nThis repo follows a strict, test-driven flow for all features.\n\n## Flow\n1) **PRD → Spec**\n   - Human drafts `PRD.md` using `specs/templates/PRD.template.md`.\n   - Human verifies PRD with `specs/PRD-GUIDE.md`.\n   - Agent drafts `spec.json` from the approved PRD.\n   - Human reviews and edits `spec.json`.\n\n2) **Spec → TODO**\n   - Agent generates `todo.json` from the approved spec.\n\n3) **TODO → Implementation (Smithers)**\n   - Smithers runs tasks in order with tests first.\n   - Write `task_report` rows per task in the Smithers db (includes root-cause fields).\n\n4) **Manual Review Checkpoints**\n   - Review after each spec before proceeding to the next.\n\n## Diagram\n\n```\nPRD.md → spec.json → todo.json → fabrik dispatch (minify) → Smithers workflow → task_report rows\n                               (token-efficient input)    (per task)\n```\n\n## Files\n- Specs (human): `specs/*.json`\n- TODOs (human): `specs/*.todo.json`\n- Minified inputs: generated in the run workdir (gitignored)\n\n## Current Specs\n- `000-base`\n- `020-fabrik-v0-2-0`\n- `021-fabrik-run-persistence`\n- `022-fabrik-doctor`\n\n## Report Format (per task)\n`task_report` rows include:\n- `status`, `work`, `files`, `tests`, `issues`, `next`\n- `rootCause`, `reasoning`, `fix`, `error`, `commit`\n\n## Minified Inputs (Smithers)\n- `fabrik run` minifies spec/todo JSON on dispatch and writes the minified copies into the run workdir.\n- Minified files are **not** tracked in git.\n\n## Testing Requirements\n- TDD is mandatory.\n- Use `@effect/vitest` and Effect DI for external services.\n- Definition of Done: `bun test`, `bun run typecheck`.\n\n## Start Here\n- Read `specs/templates/PRD.template.md` and `specs/PRD-GUIDE.md`.\n- Read `specs/000-base.md`, `specs/000-base.json`, and `specs/000-base.todo.json`.\n- Implement in order, with tests first.\n" }
]
