// Generated by scripts/embed-assets.ts. Do not edit.
export type EmbeddedAsset = { path: string; contents: string; mode?: number }

export const embeddedAssets: EmbeddedAsset[] = [
  { path: "scripts/smithers-spec-runner.tsx", contents: "#!/usr/bin/env smithers\n/** @jsxImportSource smithers-orchestrator */\nimport { existsSync, mkdirSync, readFileSync, readdirSync } from \"node:fs\"\nimport { dirname, join, resolve } from \"node:path\"\nimport { z } from \"zod\"\nimport {\n  createSmithers,\n  Sequence,\n  Parallel,\n  Ralph,\n  PiAgent,\n  CodexAgent,\n  ClaudeCodeAgent\n} from \"smithers-orchestrator\"\n\ntype Spec = {\n  id: string\n  title: string\n  goals: string[]\n  nonGoals: string[]\n  req: {\n    api: string[]\n    behavior: string[]\n    obs: string[]\n  }\n  accept: string[]\n  assume: string[]\n}\n\ntype TodoTask = { id: string; do: string; verify: string }\ntype Todo = { id: string; tdd: boolean; dod: string[]; tasks: TodoTask[] }\n\ntype Review = {\n  v: number\n  reviewer: string\n  status: \"approved\" | \"changes_requested\"\n  issues: string[]\n  next: string[]\n}\n\ntype ReviewSummary = {\n  v: number\n  status: \"approved\" | \"changes_requested\"\n  issues: string[]\n  next: string[]\n}\n\ntype Report = {\n  v: number\n  taskId: string\n  status: \"done\" | \"blocked\" | \"failed\"\n  work: string[]\n  files: string[]\n  tests: string[]\n  issues: string[]\n  next: string[]\n}\n\ntype HumanGate = {\n  v: number\n  status: \"blocked\"\n  reason: string\n}\n\nconst env = process.env\nconst specPath = resolve(env.SMITHERS_SPEC_PATH ?? env.SPEC_PATH ?? \"specs/000-base.json\")\nconst todoPath = resolve(env.SMITHERS_TODO_PATH ?? env.TODO_PATH ?? \"specs/000-base.todo.json\")\nconst reportDir = resolve(env.SMITHERS_REPORT_DIR ?? env.REPORT_DIR ?? \"reports\")\nconst promptPath = env.SMITHERS_PROMPT_PATH\nconst reviewPromptPath = env.SMITHERS_REVIEW_PROMPT_PATH\nconst reviewersDir = env.SMITHERS_REVIEWERS_DIR ?? \"prompts/reviewers\"\nconst reviewModelsPath = env.SMITHERS_REVIEW_MODELS_FILE\nconst execCwd = env.SMITHERS_CWD ? resolve(env.SMITHERS_CWD) : process.cwd()\nconst agentKind = (env.SMITHERS_AGENT ?? env.RALPH_AGENT ?? \"pi\").toLowerCase()\nconst modelOverride = env.SMITHERS_MODEL ?? env.MODEL\nconst providerOverride = env.SMITHERS_PROVIDER ?? env.PI_PROVIDER\nconst reviewMax = Number(env.SMITHERS_REVIEW_MAX ?? 2)\n\nconst spec = JSON.parse(readFileSync(specPath, \"utf8\")) as Spec\nconst todo = JSON.parse(readFileSync(todoPath, \"utf8\")) as Todo\n\nconst dbPath = resolve(env.SMITHERS_DB_PATH ?? join(\".smithers\", `${spec.id}.db`))\nif (!existsSync(dirname(dbPath))) {\n  mkdirSync(dirname(dbPath), { recursive: true })\n}\nif (!existsSync(reportDir)) {\n  mkdirSync(reportDir, { recursive: true })\n}\n\nconst reportSchema = z.object({\n  v: z.number(),\n  taskId: z.string(),\n  status: z.enum([\"done\", \"blocked\", \"failed\"]),\n  work: z.array(z.string()),\n  files: z.array(z.string()),\n  tests: z.array(z.string()),\n  issues: z.array(z.string()),\n  next: z.array(z.string())\n})\n\nconst reviewSchema = z.object({\n  v: z.number(),\n  reviewer: z.string(),\n  status: z.enum([\"approved\", \"changes_requested\"]),\n  issues: z.array(z.string()),\n  next: z.array(z.string())\n})\n\nconst reviewSummarySchema = z.object({\n  v: z.number(),\n  status: z.enum([\"approved\", \"changes_requested\"]),\n  issues: z.array(z.string()),\n  next: z.array(z.string())\n})\n\nconst humanGateSchema = z.object({\n  v: z.number(),\n  status: z.literal(\"blocked\"),\n  reason: z.string()\n})\n\nconst { Workflow, Task, smithers } = createSmithers(\n  {\n    taskReport: reportSchema,\n    reviewReport: reviewSchema,\n    reviewSummary: reviewSummarySchema,\n    humanGate: humanGateSchema\n  },\n  { dbPath }\n)\n\nconst systemPrompt = [\n  `Spec ID: ${spec.id}`,\n  `Title: ${spec.title}`,\n  \"\",\n  \"Goals:\",\n  ...spec.goals.map((g) => `- ${g}`),\n  \"\",\n  \"Non-goals:\",\n  ...spec.nonGoals.map((g) => `- ${g}`),\n  \"\",\n  \"API requirements:\",\n  ...spec.req.api.map((r) => `- ${r}`),\n  \"\",\n  \"Behavior requirements:\",\n  ...spec.req.behavior.map((r) => `- ${r}`),\n  \"\",\n  \"Observability requirements:\",\n  ...spec.req.obs.map((r) => `- ${r}`),\n  \"\",\n  \"Acceptance criteria:\",\n  ...spec.accept.map((a) => `- ${a}`),\n  \"\",\n  \"Assumptions:\",\n  ...spec.assume.map((a) => `- ${a}`),\n  \"\",\n  `TDD required: ${todo.tdd ? \"yes\" : \"no\"}`,\n  \"Definition of done:\",\n  ...todo.dod.map((d) => `- ${d}`)\n].join(\"\\n\")\n\nconst loadPrompt = (path?: string): string => {\n  if (!path) return \"\"\n  try {\n    if (!existsSync(path)) return \"\"\n    return readFileSync(path, \"utf8\").trim()\n  } catch {\n    return \"\"\n  }\n}\n\nconst globalPrompt = loadPrompt(promptPath)\nconst reviewerPrompt = loadPrompt(reviewPromptPath)\n\ntype Reviewer = {\n  id: string\n  title: string\n  prompt: string\n}\n\n// Fallback reviewers if prompts/reviewers/ directory doesn't exist or files missing.\n// These are loaded from prompts/reviewers/*.md when available.\n// File naming: prompts/reviewers/{REVIEWER-ID}.md (uppercase with hyphens)\nconst defaultReviewers: Reviewer[] = [\n  { id: \"security\", title: \"Security\", prompt: \"\" },\n  { id: \"code-quality\", title: \"Code Quality\", prompt: \"\" },\n  { id: \"simplicity\", title: \"Minimal Simplicity\", prompt: \"\" },\n  { id: \"test-coverage\", title: \"Test Coverage\", prompt: \"\" },\n  { id: \"maintainability\", title: \"Maintainability\", prompt: \"\" },\n  { id: \"tigerstyle\", title: \"Tigerstyle Audit\", prompt: \"\" },\n  { id: \"nasa-10-rules\", title: \"NASA Engineering Principles\", prompt: \"\" },\n  { id: \"correctness-guarantees\", title: \"Correctness & Invariant Validation\", prompt: \"\" }\n]\n\nconst loadReviewers = (): Reviewer[] => {\n  if (!reviewersDir || !existsSync(reviewersDir)) return defaultReviewers\n  const files = readdirSync(reviewersDir).filter((f) => f.toLowerCase().endsWith(\".md\"))\n  if (files.length === 0) return defaultReviewers\n  return files.map((file) => {\n    const id = file.replace(/\\.md$/i, \"\").toLowerCase()\n    const title = file.replace(/\\.md$/i, \"\").replace(/[-_]/g, \" \")\n    const prompt = loadPrompt(join(reviewersDir, file))\n    return { id, title, prompt }\n  })\n}\n\nconst reviewers = loadReviewers()\n\nconst loadReviewModels = (): Record<string, string> => {\n  if (!reviewModelsPath) return {}\n  try {\n    if (!existsSync(reviewModelsPath)) return {}\n    const raw = readFileSync(reviewModelsPath, \"utf8\")\n    const parsed = JSON.parse(raw)\n    if (!parsed || typeof parsed !== \"object\") return {}\n    const map: Record<string, string> = {}\n    for (const [key, value] of Object.entries(parsed)) {\n      if (typeof value === \"string\") map[key.toLowerCase()] = value\n    }\n    return map\n  } catch {\n    return {}\n  }\n}\n\nconst reviewModels = loadReviewModels()\nconst reviewDefaultModel = reviewModels._default ?? reviewModels.default ?? reviewModels[\"*\"] ?? modelOverride\n\nconst taskSchemaExample = JSON.stringify(\n  {\n    v: 1,\n    taskId: \"task-id\",\n    status: \"done | blocked | failed\",\n    work: [\"...\"],\n    files: [\"...\"],\n    tests: [\"...\"],\n    issues: [\"...\"],\n    next: [\"...\"]\n  },\n  null,\n  2\n)\n\nconst reviewSchemaExample = JSON.stringify(\n  {\n    v: 1,\n    reviewer: \"security\",\n    status: \"approved | changes_requested\",\n    issues: [\"...\"],\n    next: [\"...\"]\n  },\n  null,\n  2\n)\n\nconst makeAgent = (model?: string) => {\n  const resolvedModel = model ?? modelOverride\n  if (agentKind === \"claude\") {\n    return new ClaudeCodeAgent({\n      model: resolvedModel ?? \"opus\",\n      dangerouslySkipPermissions: true,\n      cwd: execCwd\n    })\n  }\n  if (agentKind === \"codex\") {\n    return new CodexAgent({\n      model: resolvedModel ?? \"gpt-5.2-codex\",\n      sandbox: \"danger-full-access\",\n      dangerouslyBypassApprovalsAndSandbox: true,\n      skipGitRepoCheck: true,\n      cd: execCwd,\n      cwd: execCwd\n    })\n  }\n  return new PiAgent({\n    model: resolvedModel ?? undefined,\n    provider: providerOverride ?? undefined,\n    mode: \"text\",\n    print: true,\n    cwd: execCwd\n  })\n}\n\nconst taskAgent = makeAgent(modelOverride)\n\nconst taskNodes = todo.tasks.map((task) => ({\n  nodeId: `task-${task.id}`,\n  task\n}))\n\nconst hasBlockingTask = (ctx: { outputMaybe: (table: string, key: { nodeId: string }) => Report | undefined }) => {\n  return taskNodes.some(({ nodeId }) => {\n    const report = ctx.outputMaybe(\"taskReport\", { nodeId }) as Report | undefined\n    return report ? report.status !== \"done\" : false\n  })\n}\n\nconst shouldSkipTask = (\n  ctx: { outputMaybe: (table: string, key: { nodeId: string }) => Report | undefined },\n  index: number\n) => {\n  if (index === 0) return false\n  return taskNodes.slice(0, index).some(({ nodeId }) => {\n    const report = ctx.outputMaybe(\"taskReport\", { nodeId }) as Report | undefined\n    return report ? report.status !== \"done\" : false\n  })\n}\n\nconst buildReviewTasks = (ctx: { latest: (table: string, nodeId: string) => Review | undefined }) => {\n  const tasks: Array<{ id: string; reviewer: Reviewer; text: string }> = []\n  for (const reviewer of reviewers) {\n    const nodeId = `review-${reviewer.id}`\n    const review = ctx.latest(\"reviewReport\", nodeId) as Review | undefined\n    if (!review) continue\n    const items = [...(review.issues ?? []), ...(review.next ?? [])].filter(Boolean)\n    items.forEach((item, index) => {\n      tasks.push({\n        id: `review-task-${reviewer.id}-${index + 1}`,\n        reviewer,\n        text: `[${reviewer.title}] ${item}`\n      })\n    })\n  }\n  return tasks\n}\n\nconst combineReviews = (ctx: { outputMaybe: (table: string, key: { nodeId: string; iteration?: number }) => Review | undefined; iteration: number }) => {\n  const reviews = reviewers\n    .map((reviewer) => ctx.outputMaybe(\"reviewReport\", { nodeId: `review-${reviewer.id}`, iteration: ctx.iteration }) as Review | undefined)\n    .filter(Boolean) as Review[]\n  const issues = reviews.flatMap((r) => r.issues ?? [])\n  const next = reviews.flatMap((r) => r.next ?? [])\n  const status = reviews.length > 0 && reviews.every((r) => r.status === \"approved\") ? \"approved\" : \"changes_requested\"\n  return { v: 1, status, issues, next } satisfies ReviewSummary\n}\n\nexport default smithers((ctx) => {\n  const blocking = hasBlockingTask(ctx)\n  const latestSummary = ctx.latest(\"reviewSummary\", \"review-summary\") as ReviewSummary | undefined\n  const reviewApproved = latestSummary?.status === \"approved\"\n  const reviewIterations = ctx.iterationCount(\"reviewSummary\", \"review-summary\")\n  const reviewMaxIterations = Math.max(1, reviewMax + 1)\n  const maxReviewReached = reviewIterations >= reviewMaxIterations && !reviewApproved\n\n  const gateReason = reviewApproved\n    ? \"Human review required before next spec run.\"\n    : maxReviewReached\n      ? \"Reviewers requested changes. Max retries reached; human decision required.\"\n      : \"Reviewers requested changes. Human decision required.\"\n\n  const reviewTasks = buildReviewTasks(ctx)\n  const needsReviewTasks = latestSummary?.status === \"changes_requested\"\n\n  return (\n    <Workflow name=\"spec-workflow\">\n      <Sequence>\n        {taskNodes.map(({ nodeId, task }, index) => (\n          <Task\n            key={nodeId}\n            id={nodeId}\n            output=\"taskReport\"\n            outputSchema={reportSchema}\n            skipIf={shouldSkipTask(ctx, index)}\n            agent={taskAgent}\n          >\n            {[\n              globalPrompt,\n              systemPrompt,\n              \"\",\n              `Task ${index + 1}/${taskNodes.length}: ${task.id}`,\n              \"\",\n              \"Do:\",\n              task.do,\n              \"\",\n              \"Verify:\",\n              task.verify,\n              \"\",\n              \"Engineering Standards (MUST comply - NASA/Tigerstyle):\",\n              \"\",\n              \"1. Classify Criticality Tier (T1-T4):\",\n              \"   - T1 (Critical/Money/Auth): Needs ALL 6 layers (L1-L5 + Simulation)\",\n              \"   - T2 (Important/State): Needs L1-L5, Simulation optional\",\n              \"   - T3-T4 (Standard/Low): Needs L1-L4\",\n              \"\",\n              \"2. Implement Guarantee Layers (Defense in Depth):\",\n              \"   * L1 (Types): Branded types for domain values (UserId, not string). Phantom types for state machines.\",\n              \"   * L2 (Runtime): Effect.assert for preconditions/postconditions. Fail fast on violations.\",\n              \"   * L3 (Persistence): DB constraints (UNIQUE for idempotency, CHECK for valid values).\",\n              \"   * L4 (Tests): @property TSDoc naming each invariant. Property-based tests for correctness.\",\n              \"   * L5 (Monitoring): TODOs/alerts for production (e.g., 'detected double X').\",\n              \"   * L6 (Simulation): T1 only - seed-based 24/7 simulation plan.\",\n              \"\",\n              \"3. Tigerstyle Principles:\",\n              \"   - No primitive obsession (branded types > raw primitives)\",\n              \"   - Immutable data structures (const > let, avoid mutation)\",\n              \"   - Explicit dependencies (Effect requirements, not hidden globals)\",\n              \"   - Fail fast with guard clauses (assert early, assert often)\",\n              \"\",\n              \"4. NASA Power of Ten:\",\n              \"   - Bounded loops (no infinite recursion, fixed upper limits)\",\n              \"   - Short functions (<60 lines, single responsibility)\",\n              \"   - Check all return values (Effect error channels handled)\",\n              \"   - Explicit assertions (pre/postconditions verified)\",\n              \"\",\n              \"Version control (GitHub-compatible):\",\n              \"- Use jj. GitHub requires named branches for PRs; never use anonymous changes.\",\n              `- Create branch: \\`jj new main && jj bookmark create ${spec.id}-${task.id}\\`.`\n              \"- Work normally (jj auto-snapshots files).\",\n              `- Describe: \\`jj describe -m \"...\"\\` (required before push).`,\n              `- Push to GitHub: \\`jj git push --branch ${spec.id}-${task.id}\\`.`,\n              \"  (This creates/updates the branch on origin for PR creation).\",\n              \"- If push fails (conflict), rebase: `jj rebase -d main` then force-push.\",\n              \"- If still failing, set status=failed with details.\",\n              \"\",\n              \"Output:\",\n              \"Return a single JSON object that matches this schema:\",\n              taskSchemaExample\n            ]\n              .filter((line) => line !== \"\")\n              .join(\"\\n\")}\n          </Task>\n        ))}\n\n        <Ralph\n          id=\"review-loop\"\n          until={reviewApproved}\n          maxIterations={reviewMaxIterations}\n          onMaxReached=\"return-last\"\n          skipIf={blocking}\n        >\n          <Sequence>\n            {needsReviewTasks && reviewTasks.length > 0 ? (\n              <Sequence>\n                {reviewTasks.map((task, index) => (\n                  <Task\n                    key={task.id}\n                    id={task.id}\n                    output=\"taskReport\"\n                    outputSchema={reportSchema}\n                    agent={taskAgent}\n                  >\n                    {[\n                      globalPrompt,\n                      systemPrompt,\n                      \"\",\n                      `Review Task ${index + 1}/${reviewTasks.length}: ${task.id}`,\n                      \"\",\n                      \"Do:\",\n                      task.text,\n                      \"\",\n                      \"Verify:\",\n                      \"Update code/tests and verify relevant tests pass.\",\n                      \"\",\n                      \"Engineering Standards (MUST comply - NASA/Tigerstyle):\",\n                      \"\",\n                      \"1. Classify Criticality Tier (T1-T4):\",\n                      \"   - T1 (Critical/Money/Auth): Needs ALL 6 layers (L1-L5 + Simulation)\",\n                      \"   - T2 (Important/State): Needs L1-L5, Simulation optional\",\n                      \"   - T3-T4 (Standard/Low): Needs L1-L4\",\n                      \"\",\n                      \"2. Implement Guarantee Layers (Defense in Depth):\",\n                      \"   * L1 (Types): Branded types for domain values (UserId, not string). Phantom types for state machines.\",\n                      \"   * L2 (Runtime): Effect.assert for preconditions/postconditions. Fail fast on violations.\",\n                      \"   * L3 (Persistence): DB constraints (UNIQUE for idempotency, CHECK for valid values).\",\n                      \"   * L4 (Tests): @property TSDoc naming each invariant. Property-based tests for correctness.\",\n                      \"   * L5 (Monitoring): TODOs/alerts for production (e.g., 'detected double X').\",\n                      \"   * L6 (Simulation): T1 only - seed-based 24/7 simulation plan.\",\n                      \"\",\n                      \"3. Tigerstyle Principles:\",\n                      \"   - No primitive obsession (branded types > raw primitives)\",\n                      \"   - Immutable data structures (const > let, avoid mutation)\",\n                      \"   - Explicit dependencies (Effect requirements, not hidden globals)\",\n                      \"   - Fail fast with guard clauses (assert early, assert often)\",\n                      \"\",\n                      \"4. NASA Power of Ten:\",\n                      \"   - Bounded loops (no infinite recursion, fixed upper limits)\",\n                      \"   - Short functions (<60 lines, single responsibility)\",\n                      \"   - Check all return values (Effect error channels handled)\",\n                      \"   - Explicit assertions (pre/postconditions verified)\",\n                      \"\",\n                      \"Version control (GitHub-compatible):\",\n                      \"- Use jj. GitHub requires named branches for PRs; never use anonymous changes.\",\n                      `- Create branch: \\`jj new main && jj bookmark create ${spec.id}-${task.id}\\`.`\n                      \"- Work normally (jj auto-snapshots files).\",\n                      `- Describe: \\`jj describe -m \"...\"\\` (required before push).`,\n                      `- Push to GitHub: \\`jj git push --branch ${spec.id}-${task.id}\\`.`,\n                      \"  (This creates/updates the branch on origin for PR creation).\",\n                      \"- If push fails (conflict), rebase: `jj rebase -d main` then force-push.\",\n                      \"- If still failing, set status=failed with details.\",\n                      \"\",\n                      \"Output:\",\n                      \"Return a single JSON object that matches this schema:\",\n                      taskSchemaExample\n                    ]\n                      .filter((line) => line !== \"\")\n                      .join(\"\\n\")}\n                  </Task>\n                ))}\n              </Sequence>\n            ) : null}\n\n            <Parallel>\n              {reviewers.map((reviewer) => {\n                const modelOverride = reviewModels[reviewer.id.toLowerCase()] ?? reviewDefaultModel\n                const reviewerAgent = makeAgent(modelOverride)\n                return (\n                  <Task\n                    key={reviewer.id}\n                    id={`review-${reviewer.id}`}\n                    output=\"reviewReport\"\n                    outputSchema={reviewSchema}\n                    agent={reviewerAgent}\n                  >\n                    {[\n                      reviewerPrompt,\n                      reviewer.prompt,\n                      systemPrompt,\n                      \"\",\n                      `Reviewer: ${reviewer.title}`,\n                      `Set reviewer to \"${reviewer.id}\" in the JSON output.`,\n                      \"Review the implementation against the spec, todo, and task reports.\",\n                      \"Focus on correctness, tests, security, and strict spec compliance.\",\n                      \"Verify changes were pushed (jj git push --change @) if applicable.\",\n                      \"\",\n                      \"Output:\",\n                      \"Return a single JSON object that matches this schema:\",\n                      reviewSchemaExample\n                    ]\n                      .filter((line) => line !== \"\")\n                      .join(\"\\n\")}\n                  </Task>\n                )\n              })}\n            </Parallel>\n\n            <Task id=\"review-summary\" output=\"reviewSummary\" outputSchema={reviewSummarySchema}>\n              {combineReviews(ctx)}\n            </Task>\n          </Sequence>\n        </Ralph>\n\n        <Task\n          id=\"human-gate\"\n          output=\"humanGate\"\n          outputSchema={humanGateSchema}\n          skipIf={blocking || !latestSummary}\n        >\n          {{ v: 1, status: \"blocked\", reason: gateReason }}\n        </Task>\n      </Sequence>\n    </Workflow>\n  )\n})\n" },
  { path: "scripts/smithers-reviewer.tsx", contents: "#!/usr/bin/env smithers\n/** @jsxImportSource smithers-orchestrator */\nimport { execFileSync } from \"node:child_process\"\nimport { existsSync, mkdirSync, readFileSync, readdirSync } from \"node:fs\"\nimport { dirname, join, resolve } from \"node:path\"\nimport { z } from \"zod\"\nimport { createSmithers, Sequence, PiAgent, CodexAgent, ClaudeCodeAgent } from \"smithers-orchestrator\"\n\ntype Spec = {\n  id: string\n  title: string\n  goals: string[]\n  nonGoals: string[]\n  req: { api: string[]; behavior: string[]; obs: string[] }\n  accept: string[]\n  assume: string[]\n}\n\nconst env = process.env\nconst specPath = resolve(env.SMITHERS_SPEC_PATH ?? env.SPEC_PATH ?? \"specs/000-base.json\")\nconst reportDir = resolve(env.SMITHERS_REPORT_DIR ?? env.REPORT_DIR ?? \"reports\")\nconst reviewPromptPath = env.SMITHERS_REVIEW_PROMPT_PATH\nconst execCwd = env.SMITHERS_CWD ? resolve(env.SMITHERS_CWD) : process.cwd()\nconst agentKind = (env.SMITHERS_AGENT ?? env.RALPH_AGENT ?? \"pi\").toLowerCase()\nconst modelOverride = env.SMITHERS_MODEL ?? env.MODEL\nconst providerOverride = env.SMITHERS_PROVIDER ?? env.PI_PROVIDER\nconst sourceDbPath = env.SMITHERS_SOURCE_DB_PATH ? resolve(env.SMITHERS_SOURCE_DB_PATH) : undefined\n\nconst spec = JSON.parse(readFileSync(specPath, \"utf8\")) as Spec\n\nconst dbPath = resolve(env.SMITHERS_DB_PATH ?? join(\".smithers\", `${spec.id}.review.db`))\nif (!existsSync(dirname(dbPath))) {\n  mkdirSync(dirname(dbPath), { recursive: true })\n}\nif (!existsSync(reportDir)) {\n  mkdirSync(reportDir, { recursive: true })\n}\n\nconst reviewSchema = z.object({\n  v: z.number(),\n  status: z.enum([\"approved\", \"changes_requested\"]),\n  issues: z.array(z.string()),\n  next: z.array(z.string())\n})\n\nconst { Workflow, Task, smithers } = createSmithers({ reviewSummary: reviewSchema }, { dbPath })\n\nconst systemPrompt = [\n  `Spec ID: ${spec.id}`,\n  `Title: ${spec.title}`,\n  \"\",\n  \"Goals:\",\n  ...spec.goals.map((g) => `- ${g}`),\n  \"\",\n  \"Non-goals:\",\n  ...spec.nonGoals.map((g) => `- ${g}`),\n  \"\",\n  \"API requirements:\",\n  ...spec.req.api.map((r) => `- ${r}`),\n  \"\",\n  \"Behavior requirements:\",\n  ...spec.req.behavior.map((r) => `- ${r}`),\n  \"\",\n  \"Observability requirements:\",\n  ...spec.req.obs.map((r) => `- ${r}`),\n  \"\",\n  \"Acceptance criteria:\",\n  ...spec.accept.map((a) => `- ${a}`),\n  \"\",\n  \"Assumptions:\",\n  ...spec.assume.map((a) => `- ${a}`)\n].join(\"\\n\")\n\nconst loadPrompt = (path?: string): string => {\n  if (!path) return \"\"\n  try {\n    if (!existsSync(path)) return \"\"\n    return readFileSync(path, \"utf8\").trim()\n  } catch {\n    return \"\"\n  }\n}\n\nconst reviewerPrompt = loadPrompt(reviewPromptPath)\n\nconst reviewSchemaExample = JSON.stringify(\n  {\n    v: 1,\n    status: \"approved | changes_requested\",\n    issues: [\"...\"],\n    next: [\"...\"]\n  },\n  null,\n  2\n)\n\nconst makeAgent = (model?: string) => {\n  const resolvedModel = model ?? modelOverride\n  if (agentKind === \"claude\") {\n    return new ClaudeCodeAgent({\n      model: resolvedModel ?? \"opus\",\n      dangerouslySkipPermissions: true,\n      cwd: execCwd\n    })\n  }\n  if (agentKind === \"codex\") {\n    return new CodexAgent({\n      model: resolvedModel ?? \"gpt-5.2-codex\",\n      sandbox: \"danger-full-access\",\n      dangerouslyBypassApprovalsAndSandbox: true,\n      skipGitRepoCheck: true,\n      cd: execCwd,\n      cwd: execCwd\n    })\n  }\n  return new PiAgent({\n    model: resolvedModel ?? undefined,\n    provider: providerOverride ?? undefined,\n    mode: \"text\",\n    print: true,\n    cwd: execCwd\n  })\n}\n\nconst reviewAgent = makeAgent(modelOverride)\n\nconst readReportSummary = () => {\n  if (sourceDbPath && existsSync(sourceDbPath)) {\n    try {\n      const runId = env.SMITHERS_RUN_ID ?? \"\"\n      const script = `\nimport json, os, sqlite3\npath = \"${sourceDbPath}\"\nrun_id = \"${runId}\"\nif not os.path.exists(path):\n  print(\"No reports found.\")\n  raise SystemExit(0)\nconn = sqlite3.connect(path)\ntry:\n  if run_id:\n    cur = conn.execute(\"SELECT task_id, status, issues, next FROM task_report WHERE run_id = ? ORDER BY node_id\", (run_id,))\n  else:\n    cur = conn.execute(\"SELECT task_id, status, issues, next FROM task_report ORDER BY node_id\")\n  rows = cur.fetchall()\n  if not rows:\n    print(\"No reports found.\")\n  else:\n    for row in rows:\n      print(json.dumps({\"taskId\": row[0], \"status\": row[1], \"issues\": row[2], \"next\": row[3]}, indent=2))\nexcept Exception:\n  print(\"No reports found.\")\nfinally:\n  conn.close()\n`\n      const output = execFileSync(\"python3\", [\"-\"], { input: script, encoding: \"utf8\" }).trim()\n      return output || \"No reports found.\"\n    } catch {\n      return \"No reports found.\"\n    }\n  }\n\n  try {\n    const files = existsSync(reportDir) ? readdirSync(reportDir) : []\n    const reportFiles = files.filter((f) => f.endsWith(\".report.json\"))\n    const summaries = reportFiles.slice(0, 30).map((f) => {\n      const raw = readFileSync(join(reportDir, f), \"utf8\")\n      return `${f}:\\n${raw}`\n    })\n    return summaries.length > 0 ? summaries.join(\"\\n\\n\") : \"No reports found.\"\n  } catch {\n    return \"No reports found.\"\n  }\n}\n\nexport default smithers(() => {\n  const reportSummary = readReportSummary()\n\n  return (\n    <Workflow name=\"review-only\">\n      <Sequence>\n        <Task id=\"review\" output=\"reviewSummary\" outputSchema={reviewSchema} agent={reviewAgent}>\n          {[\n            reviewerPrompt,\n            systemPrompt,\n            \"\",\n            \"Review the implementation against the spec, todo, and task reports.\",\n            \"Focus on correctness, tests, security, and strict spec compliance.\",\n            \"Verify changes were pushed (jj git push --change @) if applicable.\",\n            \"\",\n            \"Reports:\",\n            reportSummary,\n            \"\",\n            \"Output:\",\n            \"Return a single JSON object that matches this schema:\",\n            reviewSchemaExample\n          ]\n            .filter((line) => line !== \"\")\n            .join(\"\\n\")}\n        </Task>\n      </Sequence>\n    </Workflow>\n  )\n})\n" },
  { path: "scripts/validate-specs.ts", contents: "import { readdir, readFile, stat } from \"node:fs/promises\"\nimport { join } from \"node:path\"\n\nconst isJson = (name: string) => name.endsWith(\".json\") && !name.endsWith(\".min.json\")\n\nconst isStringArray = (value: unknown): value is string[] =>\n  Array.isArray(value) && value.every((item) => typeof item === \"string\")\n\nconst onlyKeys = (obj: object, keys: string[]) =>\n  Object.keys(obj).every((key) => keys.includes(key))\n\nconst validateSpec = (file: string, obj: Record<string, unknown>, errors: string[]) => {\n  const keys = [\n    \"v\",\n    \"id\",\n    \"title\",\n    \"status\",\n    \"version\",\n    \"lastUpdated\",\n    \"supersedes\",\n    \"dependsOn\",\n    \"goals\",\n    \"nonGoals\",\n    \"req\",\n    \"cfg\",\n    \"accept\",\n    \"assume\"\n  ]\n\n  if (!onlyKeys(obj, keys)) {\n    errors.push(`${file}: unexpected top-level keys`)\n  }\n\n  for (const key of [\"v\", \"id\", \"title\", \"status\", \"version\", \"lastUpdated\", \"goals\", \"nonGoals\", \"req\", \"accept\", \"assume\"]) {\n    if (!(key in obj)) {\n      errors.push(`${file}: missing ${key}`)\n    }\n  }\n\n  if (obj.v !== 1) errors.push(`${file}: v must be 1`)\n  for (const key of [\"id\", \"title\", \"status\", \"version\", \"lastUpdated\"]) {\n    if (typeof obj[key] !== \"string\") errors.push(`${file}: ${key} must be string`)\n  }\n\n  for (const key of [\"supersedes\", \"dependsOn\", \"goals\", \"nonGoals\", \"accept\", \"assume\"]) {\n    const value = obj[key]\n    if (value !== undefined && !isStringArray(value)) {\n      errors.push(`${file}: ${key} must be string[]`)\n    }\n  }\n\n  const req = obj.req\n  if (typeof req !== \"object\" || req === null) {\n    errors.push(`${file}: req must be object`)\n  } else {\n    const reqKeys = [\"api\", \"behavior\", \"obs\"]\n    if (!onlyKeys(req, reqKeys)) errors.push(`${file}: req has unexpected keys`)\n    for (const key of reqKeys) {\n      const value = (req as Record<string, unknown>)[key]\n      if (value === undefined) errors.push(`${file}: req missing ${key}`)\n      else if (!isStringArray(value)) errors.push(`${file}: req.${key} must be string[]`)\n    }\n  }\n\n  const cfg = obj.cfg\n  if (cfg !== undefined) {\n    if (typeof cfg !== \"object\" || cfg === null) {\n      errors.push(`${file}: cfg must be object`)\n    } else {\n      const cfgKeys = [\"env\"]\n      if (!onlyKeys(cfg, cfgKeys)) errors.push(`${file}: cfg has unexpected keys`)\n      const env = (cfg as Record<string, unknown>).env\n      if (env !== undefined && !isStringArray(env)) errors.push(`${file}: cfg.env must be string[]`)\n    }\n  }\n}\n\nconst validateTodo = (file: string, obj: Record<string, unknown>, errors: string[]) => {\n  const keys = [\"v\", \"id\", \"tdd\", \"dod\", \"tasks\"]\n  if (!onlyKeys(obj, keys)) errors.push(`${file}: unexpected top-level keys`)\n  for (const key of keys) {\n    if (!(key in obj)) errors.push(`${file}: missing ${key}`)\n  }\n  if (obj.v !== 1) errors.push(`${file}: v must be 1`)\n  if (typeof obj.id !== \"string\") errors.push(`${file}: id must be string`)\n  if (typeof obj.tdd !== \"boolean\") errors.push(`${file}: tdd must be boolean`)\n  if (!isStringArray(obj.dod)) errors.push(`${file}: dod must be string[]`)\n\n  if (!Array.isArray(obj.tasks)) {\n    errors.push(`${file}: tasks must be array`)\n  } else {\n    for (const [index, task] of obj.tasks.entries()) {\n      if (typeof task !== \"object\" || task === null) {\n        errors.push(`${file}: tasks[${index}] must be object`)\n        continue\n      }\n      const taskKeys = [\"id\", \"do\", \"verify\"]\n      if (!onlyKeys(task, taskKeys)) errors.push(`${file}: tasks[${index}] unexpected keys`)\n      for (const key of taskKeys) {\n        const value = (task as Record<string, unknown>)[key]\n        if (value === undefined) errors.push(`${file}: tasks[${index}] missing ${key}`)\n        else if (typeof value !== \"string\") errors.push(`${file}: tasks[${index}].${key} must be string`)\n      }\n    }\n  }\n}\n\nconst validateDir = async (dir: string) => {\n  const entries = await readdir(dir)\n  const errors: string[] = []\n\n  for (const entry of entries) {\n    const fullPath = join(dir, entry)\n    const info = await stat(fullPath)\n    if (!info.isFile()) continue\n    if (!isJson(entry)) continue\n\n    const raw = await readFile(fullPath, \"utf8\")\n    const json = JSON.parse(raw) as Record<string, unknown>\n    if (entry.endsWith(\".todo.json\")) validateTodo(entry, json, errors)\n    else validateSpec(entry, json, errors)\n  }\n\n  if (errors.length > 0) {\n    console.error(`Schema validation errors:\\n${errors.join(\"\\n\")}`)\n    process.exit(1)\n  }\n\n  console.log(\"All spec/todo JSON files passed schema checks.\")\n}\n\nconst target = process.argv[2] ?? \"specs\"\n\nvalidateDir(target).catch((error) => {\n  console.error(error)\n  process.exit(1)\n})\n" },
  { path: "scripts/minify-specs.ts", contents: "import { readdir, readFile, writeFile, stat } from \"node:fs/promises\"\nimport { join } from \"node:path\"\n\nconst isJson = (name: string) => name.endsWith(\".json\") && !name.endsWith(\".min.json\")\n\nconst minifyFile = async (filePath: string) => {\n  const raw = await readFile(filePath, \"utf8\")\n  const json = JSON.parse(raw)\n  const minPath = filePath.replace(/\\.json$/, \".min.json\")\n  await writeFile(minPath, JSON.stringify(json), \"utf8\")\n}\n\nconst minifyDir = async (dir: string) => {\n  const entries = await readdir(dir)\n  for (const entry of entries) {\n    const fullPath = join(dir, entry)\n    const info = await stat(fullPath)\n    if (!info.isFile()) {\n      continue\n    }\n    if (isJson(entry)) {\n      await minifyFile(fullPath)\n    }\n  }\n}\n\nconst target = process.argv[2] ?? \"specs\"\n\nminifyDir(target)\n  .then(() => {\n    console.log(`Minified JSON in ${target}`)\n  })\n  .catch((error) => {\n    console.error(error)\n    process.exit(1)\n  })\n" },
  { path: "prompts/DEFAULT-IMPLEMENTER.md", contents: "# Default Implementer Prompt\n\nStudy /docs to become familiar with the codebase architecture.\n\nStudy the spec and todo JSON to learn the goal at hand.\n\nLook at recent commits to see what has been done.\n\nPick the most important task from the TODO list for implementation of the spec and implement that. Focus on completion of that task. If you encounter blocking errors, fix them, verify them, commit them, get the task done.\n\nBefore making changes search codebase (don't assume an item is not implemented) using parallel subagents. Think hard.\n\nWrite tests, verify your work builds, run the dev server (you can access the logs) and use chrome dev tools mcp to check the website at the very end, going through the user flow.\n\nImportant: When authoring documentation (ie. ts doc, tests or documentation) capture the why tests and the backing implementation is important.\n\nAfter implementing functionality or resolving problems, run the tests for that unit of code that was improved.\nWhen all tests and verifications pass commit your work. If functionality is missing then it's your job to add it as per the application specifications.\n\nCommit message rules:\n- Use Conventional Commits: type(scope): subject\n- Include spec id, todo id, and run id in the message body or trailer\n- When debugging/fixing root causes, include: cause → reasoning → fix, plus relevant error output\n- If `jj git push --bookmark <branch>` fails with \"Refusing to create new remote bookmark\", run:\n  `jj bookmark track <branch> --remote=origin` then retry push\n- Avoid literal `\\n` in commit messages. Use a proper multi-line body:\n  - Preferred: `jj describe -m \"$(cat <<'EOF'\\n<subject>\\n\\n<trailers>\\nEOF\\n)\"`\n  - Or: `printf '%s\\n\\n%s\\n' \"<subject>\" \"<trailers>\" | jj describe -m -`\n- Example:\n  feat(spec-020-fabrik-v0-2-0): implement dispatch auth\n  \n  todo: git-credentials-vm\n  spec: 020-fabrik-v0-2-0\n  run: 20260203T120945Z\n  cause: GH auth relied on host keychain; VM had no token\n  reasoning: VM needs env-based auth; ralph.env already contains GITHUB_TOKEN\n  fix: source ralph.env and export GH_TOKEN during dispatch\n  error: gh auth status -> \"token in default is invalid\"\n\nUpdate the TODO.md file noting what has been done, attach a screenshot of the UI confirming it's done for frontend changes.\n" },
  { path: "prompts/DEFAULT-REVIEWER.md", contents: "# Default Reviewer Prompt\n\nReview the implementation against the spec and todo. Focus on:\n\n- Correctness and completeness\n- Tests and verification steps\n- Security risks and edge cases\n- Strict spec compliance\n\nConfirm changes were pushed to the single spec branch/bookmark (no `push-*` branches).\nCheck commit messages follow Conventional Commits and include spec/todo/run plus root-cause notes when relevant.\nVerify task reports include rootCause/reasoning/fix/error/commit when applicable.\n\nReport issues clearly and suggest next steps.\n" },
  { path: "prompts/reviewers/SECURITY.md", contents: "# Security Reviewer\n\nReview for security vulnerabilities and best practices.\n\n## Checklist\n\n- [ ] No hardcoded secrets or credentials in code\n- [ ] Input validation at all entry points (prevent injection)\n- [ ] Proper error handling (no information leakage in error messages)\n- [ ] Authentication/authorization checks where applicable\n- [ ] Secure defaults (deny by default, least privilege)\n- [ ] No SQL injection vectors (parameterized queries only)\n- [ ] No XSS vulnerabilities (output encoding where needed)\n- [ ] Dependencies are up to date (no known CVEs)\n- [ ] Sensitive data encrypted at rest and in transit\n- [ ] Audit logging for sensitive operations\n\n## Effect-TS Specific\n\n- [ ] Effect error channels don't leak sensitive internals\n- [ ] Service requirements properly scoped (least privilege)\n- [ ] No direct Promise rejection exposure\n\nFlag any security issue as `changes_requested` with severity:\n- `CRITICAL`: Data breach, auth bypass, injection vulnerability\n- `HIGH`: Potential security risk with clear exploitation path\n- `MEDIUM`: Defense in depth improvement recommended\n" },
  { path: "prompts/reviewers/CODE-QUALITY.md", contents: "# Code Quality Reviewer\n\nReview for general code quality, readability, and maintainability fundamentals.\n\n## Checklist\n\n- [ ] Functions are focused and single-purpose (SRP)\n- [ ] Variable names are descriptive and intent-revealing\n- [ ] No magic numbers or strings (use named constants)\n- [ ] Consistent formatting and style\n- [ ] Comments explain WHY, not WHAT (code should be self-documenting)\n- [ ] No dead code or unused imports\n- [ ] Error handling is comprehensive, not just happy-path\n- [ ] No deeply nested conditionals (prefer early returns)\n- [ ] Async code properly handled (no floating Promises)\n\n## TypeScript Specific\n\n- [ ] Strict typing enabled (no `any`, minimal `unknown` with validation)\n- [ ] Type inference used appropriately (not over-typed)\n- [ ] Generics used correctly (not over-engineered)\n- [ ] Null/undefined handling explicit (Option/Maybe types preferred)\n\n## Effect-TS Specific\n\n- [ ] Effects are composed, not nested\n- [ ] Error channels are explicit and handled\n- [ ] Resource management uses Scope/acquireRelease\n- [ ] No Effect.runPromise in library code\n\nFlag quality issues as `changes_requested` or `approved` with suggestions.\n" },
  { path: "prompts/reviewers/SIMPLICITY.md", contents: "# Minimal Simplicity Reviewer\n\nReview against \"simple is better than complex\" principles. Code should be as simple as possible, but no simpler.\n\n## Tigerstyle Alignment\n\n1. **DENSITY**: Is the code concise without being cryptic?\n   - One idea per line\n   - No unnecessary abstraction layers\n   - Remove boilerplate and ceremony\n\n2. **LOCALITY**: Are related concepts close together?\n   - No jumps across files for understanding\n   - Cohesive functions and modules\n   - Minimize cognitive distance\n\n3. **EXPLICITNESS**: Are all side effects visible?\n   - No hidden control flow\n   - No magic conventions\n   - Dependencies explicitly declared\n\n## Anti-Patterns to Flag\n\n- [ ] Over-engineering: Abstract factories for simple cases\n- [ ] Premature optimization: Complex caching for unclear benefit\n- [ ] Deep inheritance hierarchies (prefer composition)\n- [ ] Unnecessary indirection (interface with single implementation)\n- [ ] \"Enterprise\" patterns applied where functions suffice\n\n## Approval Criteria\n\n- Could a junior developer understand this in 5 minutes?\n- Is there a shorter way to express this intent?\n- Are we solving the problem we have, not might have?\n\nFlag complexity without justification as `changes_requested`.\n" },
  { path: "prompts/reviewers/TEST-COVERAGE.md", contents: "# Test Coverage Reviewer\n\nReview for comprehensive testing strategy and test quality.\n\n## Layer 4 (L4) Requirements\n\n### Unit Tests\n- [ ] Happy path covered for all public functions\n- [ ] Edge cases identified and tested (empty inputs, boundaries)\n- [ ] Error paths tested (Effect failure branches)\n- [ ] No tests that just \"pass through\" without verification\n\n### Property-Based Tests (Critical)\n- [ ] Invariants have `@property` TSDoc comments with names\n- [ ] Property tests for:\n  - **Conservation**: Nothing created/destroyed (e.g., money, tokens)\n  - **Idempotency**: Same input → same output (deterministic)\n  - **Commutativity**: Order doesn't matter for independent ops\n  - **Associativity**: Grouping doesn't affect result\n\n### Integration Tests\n- [ ] End-to-end flows work with real (or test) services\n- [ ] Database constraints actually enforced (test failures)\n- [ ] External API boundaries handled correctly\n\n### Effect-TS Testing\n- [ ] `Effect.TestClock` used for time-dependent logic\n- [ ] `TestContext` provided for all service dependencies\n- [ ] Both success and failure branches in Effect pipelines tested\n\n## T1/T2 Specific\n\nFor T1 (Critical) and T2 (Important) code:\n- [ ] Every invariant named and tested\n- [ ] Database constraints verified (try to violate them, confirm rejection)\n- [ ] Failure scenarios enumerated and covered\n\n## Measurement\n\n- Line coverage ≥ 80% (T3/T4), ≥ 90% (T1/T2)\n- Branch coverage ≥ 70% (T3/T4), ≥ 85% (T1/T2)\n- Invariant coverage: 100% (every @property has a test)\n\nFlag missing test coverage as `changes_requested` for critical paths.\n" },
  { path: "prompts/reviewers/MAINTAINABILITY.md", contents: "# Maintainability Reviewer\n\nReview for long-term code health and team scalability.\n\n## Documentation\n\n- [ ] README or module docs explain the \"why\" and \"how\"\n- [ ] Complex business logic has context comments\n- [ ] API changes documented (breaking vs non-breaking)\n- [ ] Architecture Decision Records (ADRs) for major choices\n\n## Code Organization\n\n- [ ] Clear module boundaries (high cohesion, low coupling)\n- [ ] Public API surface is minimal and intentional\n- [ ] Internal modules marked/separated from public\n- [ ] No circular dependencies\n\n## Observability\n\n- [ ] Structured logging for important operations\n- [ ] Error contexts include actionable information\n- [ ] Metrics/TODOs documented for production (L5 preparation)\n\n## Onboarding\n\n- [ ] New developer could fix a bug in this code within 1 hour\n- [ ] No tribal knowledge required (all context in code/docs)\n- [ ] Examples provided for complex operations\n\n## Effect-TS Specific\n\n- [ ] Service interfaces are stable and well-documented\n- [ ] Error types are actionable (contain debugging context)\n- [ ] Resource lifecycles are clear and documented\n\n## Versioning\n\n- [ ] Breaking changes explicitly identified\n- [ ] Migration path provided for API changes\n\nFlag maintainability issues as `approved` with suggestions (not blocking unless severe).\n" },
  { path: "README.md", contents: "# Local Ralph/Wisp Development Environment\n\n**Humans write specs. Agents ship features.**\n\nRun a workforce of isolated coding agents locally. Write a specification, dispatch it to your Ralph fleet, get notified when it ships. Smithers is required.\n\n## The Vision\n\n```\n┌─────────────────────────────────────────────────────────────────────┐\n│                                                                     │\n│   Human writes spec ──► Ralphs implement ──► Ralphs review ──►     │\n│                                │                  │                 │\n│                                └──── iterate ─────┘                 │\n│                                         │                           │\n│                                         ▼                           │\n│                              \"Feature X shipped\" ──► Human          │\n│                                                                     │\n└─────────────────────────────────────────────────────────────────────┘\n```\n\nYou stay in the loop for:\n- Writing specifications\n- Answering questions when agents get stuck\n- Receiving \"shipped\" notifications\n\nAgents handle:\n- Implementation\n- Code review (agent-to-agent)\n- Iteration on feedback\n- PR creation\n\n## Architecture\n\n```\n┌──────────────────────────────────────────────────────────────────┐\n│  Host Machine                                                    │\n│  ├── LAOS (Grafana/Loki/Tempo/Prometheus/Sentry/PostHog) ◄──     │\n│  │   all agents report here                                     │\n│  ├── Message queue (filesystem) ◄── agents coordinate           │\n│  │                                                               │\n│  ├── ralph-1 (VM) ──── Smithers workflow ── feat/auth           │\n│  ├── ralph-2 (VM) ──── Smithers workflow ── feat/dashboard      │\n│  ├── ralph-3 (VM) ──── Smithers workflow ── fix/api-error       │\n│  │                                                               │\n│  └── ralph-review (VM) ── reviews reports, sends feedback       │\n└──────────────────────────────────────────────────────────────────┘\n```\n\nEach VM has the repo cloned and works on its own branch. For advanced parallel work, use [Jujutsu (jj)](https://github.com/martinvonz/jj) which handles multiple changes natively.\n\n## Quick Start\n\n### 1. Setup infrastructure\n\n```bash\n# Start LAOS (shared host observability stack)\n# Source of truth: https://github.com/dtechvision/laos\nmkdir -p ~/git\nif [[ -d ~/git/laos/.git ]]; then\n  (cd ~/git/laos && git pull)\nelse\n  git clone https://github.com/dtechvision/laos.git ~/git/laos\nfi\ncd ~/git/laos\ndocker compose up -d\n\n# Optional: create a shared env file so LAOS endpoints get copied into VMs\ncd /path/to/local-isolated-ralph\n./scripts/create-ralph-env.sh\n# Edit ~/.config/ralph/ralph.env and set:\n# macOS (Lima):  LAOS_HOST=host.lima.internal\n# Linux (libvirt): LAOS_HOST=192.168.122.1\n\n# Create VMs (4 implementers + 1 reviewer)\nfor i in 1 2 3 4; do ./scripts/create-ralph.sh ralph-$i 2 4 20; done\n./scripts/create-ralph.sh ralph-review 2 4 20\n\n# Setup base image in one VM, then snapshot for cloning\n./scripts/setup-base-vm.sh  # Run inside VM\n```\n\n### 2. Prepare a task (Spec + TODO)\n\n```bash\n# Validate the JSON spec/todo (fabrik auto-minifies on dispatch)\nbun run scripts/validate-specs.ts\n```\n\n### 3. Launch Smithers\n\n```bash\n# Run a Smithers workflow (spec/todo JSON; minified on dispatch)\n./dist/fabrik run --spec specs/010-weekly-summary.json --vm ralph-1\n\n# With local project directory synced to VM\n./dist/fabrik run --spec specs/010-weekly-summary.json --vm ralph-1 --project ~/projects/my-app\n\n# With iteration limit (stops after 20 Smithers iterations)\n./dist/fabrik run --spec specs/010-weekly-summary.json --vm ralph-1 --project ~/projects/my-app --iterations 20\n\n# Or start multiple Ralphs on different specs (fleet)\n./dist/fabrik fleet --specs-dir specs --vm-prefix ralph\n```\n\n### 4. Watch and wait\n\n```bash\n# Grafana for logs/traces\nopen http://localhost:3010\n\n# Or attach to a VM session directly\n# limactl shell <vm> or ssh ralph@<ip>\n\n# Watch for blocked tasks and get desktop notifications\nfabrik runs watch --vm ralph-1\n```\n\nWhen done, Smithers writes task outputs into its SQLite db (`.smithers/<spec>.db`) and exits when all tasks are done.\n\n### Desktop notifications\n\n`fabrik runs watch` will send notifications when blocked tasks appear.\n\nInstall a notifier:\n- macOS: `brew install terminal-notifier`\n- Linux: `sudo apt install libnotify-bin` (provides `notify-send`)\n\n## Workflows\n\n| Pattern | Use Case | Setup |\n|---------|----------|-------|\n| **Single Ralph** | One feature at a time | 1 VM, feature branch |\n| **Multi-Ralph Fleet** | Parallel features | N VMs, each on own branch |\n| **Multi-Ralph per VM** | Resource constrained | 2-4 Ralphs in 1 VM |\n| **Implementer + Reviewer** | Reduce human review | Agents review each other |\n\nSee **[WORKFLOW.md](./WORKFLOW.md)** for detailed patterns.\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| [QUICKSTART.md](./QUICKSTART.md) | End-to-end tutorial |\n| [WORKFLOW.md](./WORKFLOW.md) | Workflow patterns, multi-agent coordination |\n| [OBSERVABILITY.md](./OBSERVABILITY.md) | Telemetry, logging, tracing, and analytics setup |\n| [SETUP-MACOS.md](./SETUP-MACOS.md) | macOS setup with Lima |\n| [SETUP-LINUX.md](./SETUP-LINUX.md) | Linux setup with libvirt/QEMU |\n| [CI-CD.md](./CI-CD.md) | CI/CD setup with self-hosted runners |\n| [dtechvision/laos](https://github.com/dtechvision/laos) | Shared observability stack (external) |\n| [specs/templates/](./specs/templates/) | Spec/TODO JSON templates |\n\n## Scripts\n\n| Script | Purpose |\n|--------|---------|\n| `create-ralph.sh` | Create a new Ralph VM |\n| `setup-base-vm.sh` | Install tools inside VM (run once, snapshot) |\n| `smithers-fleet.sh` | Dispatch multiple Smithers workflows |\n| `smithers-spec-runner.tsx` | Default Smithers workflow for spec/todo |\n| `smithers-reviewer.tsx` | Smithers reviewer workflow template |\n| `cleanup-workdirs.sh` | Cleanup old immutable workdirs |\n| `record-human-feedback.sh` | Record human review decision/notes |\n| `list-ralphs.sh` | Show all VMs and status |\n| `cleanup-ralphs.sh` | Delete VMs |\n\n## CLI (Fabrik)\n\nBuild and run the single binary CLI:\n\n```bash\nbun install\nbun run build\n./dist/fabrik flow\n```\n\n### Standalone binary (embedded assets)\n\nThe `fabrik` binary embeds:\n- default prompts + reviewer prompts\n- default Smithers workflows\n- helper scripts (dispatch/cleanup/fleet)\n- docs (README/WORKFLOW/QUICKSTART/specs README)\n\nIf `LOCAL_RALPH_HOME` (or `~/git/local-isolated-ralph`) is missing, `fabrik` writes embedded assets\nto `~/.cache/fabrik/embedded/<hash>/` and runs from there.\n\nCommon commands:\n\n```bash\n# Validate specs in current repo\nfabrik spec validate\n# Optional: generate minified copies (gitignored)\nfabrik spec minify\n\n# Dispatch a run (from another repo)\nfabrik run --spec specs/feature.json --vm ralph-1\n\n# Run with custom prompts\nfabrik run --spec specs/feature.json --vm ralph-1 \\\n  --prompt ./prompts/PROMPT-implementer.md \\\n  --review-prompt ./prompts/PROMPT-reviewer.md\n\n# Run with custom reviewer models + retry cap\nfabrik run --spec specs/feature.json --vm ralph-1 \\\n  --review-max 3 \\\n  --review-models ./prompts/reviewer-models.json\n\n# Record human feedback\nfabrik feedback --vm ralph-1 --spec specs/feature.json --decision approve --notes \"OK\"\n\n# Fleet\nfabrik fleet --specs-dir specs --vm-prefix ralph\n\n# Docs\nfabrik docs --topic workflow\n\n# Runs\nfabrik runs list --limit 10\nfabrik runs show --id 42  # includes failure_reason when available\nfabrik runs feedback --id 42 --decision approve --notes \"OK\"\n\n# Observability stack (LAOS)\nfabrik laos up\nfabrik laos status\nfabrik laos logs --follow\nfabrik laos down\n\n# Credentials sync\nfabrik credentials sync --vm ralph-1\n\n# Dependency maintenance\nfabrik deps check\nfabrik deps update --bun\nfabrik deps update --smithers\nfabrik deps update --bun --smithers\n```\n\nDependency policy:\n- Direct deps are pinned (no `latest`/range drift).\n- New direct deps require explicit approval.\n- CI enforces policy with `bun run deps:policy`.\n- Install the local pre-commit hook once: `bun run hooks:install`.\n\n`fabrik laos` clones/pulls `https://github.com/dtechvision/laos` with **jj** (or `git` if jj is missing)\ninto `~/.cache/fabrik/laos` and runs `docker compose`.\n\n### Use the CLI from another repo\n\nFrom any repo (e.g. `~/git/<your-repo>`):\n\n```bash\n# Build once (in local-ralph)\ncd ~/git/local-isolated-ralph\nbun install\nbun build src/fabrik/bin.ts --compile --outfile dist/fabrik\n\n# Use from another repo\ncd ~/git/<your-repo>\n~/git/local-isolated-ralph/dist/fabrik spec validate\n~/git/local-isolated-ralph/dist/fabrik spec minify\n~/git/local-isolated-ralph/dist/fabrik run --spec specs/001-foo.json --vm ralph-1\n```\n\n### Binary Releases (GitHub)\n\nThe repo ships prebuilt `fabrik` binaries for:\n- macOS ARM64 (`darwin-arm64`)\n- Linux x64 (`linux-x64`)\n- Linux ARM64 (`linux-arm64`)\n\nRelease process:\n\n```bash\ngit tag v0.1.0\ngit push origin v0.1.0\n```\n\nOr trigger the workflow manually with a tag (GitHub Actions UI).\n\nIf your local-ralph repo lives elsewhere, set:\n\n```bash\nexport LOCAL_RALPH_HOME=/path/to/local-isolated-ralph\n```\n\n### Smithers (Required Orchestration + JJ)\n\nSmithers is required. Fabrik dispatches minified spec/todo JSON for token efficiency and Smithers executes tasks with durable state. It always runs an agent reviewer and writes review outputs to the Smithers SQLite db (`review_report`, `review_summary`) along with a `human_gate` row for human approval. Version control is JJ (colocated Git backend).\n\nDefault models:\n- Claude: `opus`\n- Codex: `gpt-5.2-codex` (reasoning `medium`, sandbox `danger-full-access`)\n\nPROMPT control:\n- Pass `--prompt` to prepend a per-run `PROMPT.md` (implementation instructions).\n- Pass `--review-prompt` to prepend reviewer instructions.\nThese files are prepended before the spec/todo content in Smithers.\nDefaults live in `prompts/DEFAULT-IMPLEMENTER.md` and `prompts/DEFAULT-REVIEWER.md`.\nReview pipeline (default):\n- Security\n- Code Quality\n- Minimal Simplicity\n- Test Coverage\n- Maintainability\n\nReviewer prompts live in `prompts/reviewers/*.md` and are copied into each run.\n\nReviewer model config (optional):\nCreate `reviewer-models.json` to map reviewers to models:\n\n```json\n{\n  \"_default\": \"sonnet\",\n  \"security\": \"sonnet\",\n  \"code-quality\": \"sonnet\",\n  \"simplicity\": \"sonnet\",\n  \"test-coverage\": \"sonnet\",\n  \"maintainability\": \"sonnet\"\n}\n```\n\nBackpressure:\n- If any reviewer requests changes, Smithers generates follow-up review tasks in the workflow and records them in the SQLite db.\n- The review pipeline reruns after review tasks.\n- Only when all reviewers approve does the human gate row appear.\n\nRun context audit:\n- Each run writes `reports/run-context.json` with prompt contents + hashes.\n\n```bash\n# Install in VM if missing\n# bun add -g github:evmts/smithers#ea5ece3b156ebd32990ec9c528f9435c601a0403\n\n# Local workflow (uses scripts/smithers-spec-runner.tsx by default)\n./dist/fabrik run --spec specs/000-base.json --vm ralph-1\n\n# With custom prompts\n./dist/fabrik run --spec specs/000-base.json --vm ralph-1 \\\n  --prompt ./prompts/PROMPT-implementer.md \\\n  --review-prompt ./prompts/PROMPT-reviewer.md\n\n# Custom TODO and workflow\n./dist/fabrik run --spec specs/010-weekly-summary.json --todo specs/010-weekly-summary.todo.json \\\n  --workflow scripts/smithers-spec-runner.tsx --model sonnet --vm ralph-1\n\n# Review runs automatically after tasks; Smithers writes review outputs + human gate into the SQLite db.\n```\n\n### Smithers Workflow Diagram\n\n```\nspec.json + todo.json\n   (minified on dispatch)\n          │\n          ▼\n  Smithers workflow\n  (Ralph loop in React)\n          │\n          ├─ task 1 → task_report row\n          ├─ task 2 → task_report row\n          └─ task N → task_report row\n          │\n          ▼\n     DONE / BLOCKED / FAILED\n```\n\n### Reviewer Template (Standalone)\n\nUse the built-in Smithers reviewer workflow:\n\n```bash\n./dist/fabrik run --spec specs/feature.json --vm ralph-review --workflow scripts/smithers-reviewer.tsx\n```\n\n### JJ Primer (Required VCS)\n\nJJ uses a colocated Git backend. The repo still has `.git`, but you use `jj` commands.\n\n```\nClone:              jj git clone <url> <dir>\nInit in repo:       jj git init\nStart change:       jj new master\nStatus:             jj status\nDiff:               jj diff\nDescribe change:    jj describe\nPush change:        jj git push --change @\n```\n\nSet your JJ identity (recommended):\n```bash\njj config set --user user.name \"Your Name\"\njj config set --user user.email \"you@company.com\"\n```\n\nIf JJ identity is missing, fabrik falls back to git identity (if set) or uses defaults.\n\n### Changesets + JJ\n\nChangesets stays the same; JJ only replaces Git commands locally:\n\n```bash\n# Create a changeset for your PR\nbunx changeset\n\n# Work in a new JJ change\njj new master\n\n# Review + commit\njj status\njj diff\njj describe\n\n# Push the change\njj git push --change @\n```\n\n### fabrik run Options\n\n```bash\n./dist/fabrik run --spec <path> --vm <vm-name> [--todo <path>] \\\n  [--project <dir>] [--repo <url>] [--ref <branch>] [--include-git] \\\n  [--workflow <path>] [--report-dir <path>] [--model <name>] \\\n  [--prompt <path>] [--review-prompt <path>] [--review-models <path>] [--review-max <n>] \\\n  [--iterations <n>] [--follow]\n\n# Example with .git included (enables push from synced project)\nRALPH_AGENT=pi ./dist/fabrik run --include-git --spec specs/000-base.json --vm ralph-1 --project ~/projects/app --iterations 20\n```\n\n- `--include-git` - Include `.git` in sync (otherwise agent must clone from repo URL)\n- `--spec` - Spec JSON (minified on dispatch for Smithers mode)\n- `--todo` - TODO JSON (minified on dispatch for Smithers mode)\n- `--workflow` - Smithers workflow script (default: `scripts/smithers-spec-runner.tsx`)\n- `--report-dir` - Report output directory inside VM (default: workdir/reports)\n- `--model` - Model name for Smithers agent\n- `--prompt` - PROMPT.md prepended to every task prompt\n- `--review-prompt` - Reviewer PROMPT.md prepended to review prompt\n- `--review-max` - Max review reruns before human gate (default: 2)\n- `--review-models` - JSON map of reviewer_id -> model\n- `RALPH_AGENT` - Agent to use: `pi` (default), `claude`, `codex`\n- `MAX_ITERATIONS` - Max loops (default: 100, 0 = unlimited)\n\nEach dispatch creates a timestamped work directory (`/home/ralph/work/<vm>/<project>-<timestamp>/`), enabling parallel dispatches to the same VM.\n\nFailure reporting:\n- `fabrik runs show --id <run-id>` prints `failure_reason` when a run fails (derived from `reports/smithers.log`).\n- Stale or missing heartbeats are marked as `failure_reason: stale_process`.\n\n## Resource Planning\n\n| Host RAM | Recommended Setup |\n|----------|-------------------|\n| 16GB | 4 light VMs (2 CPU, 4GB each) |\n| 32GB | 8 light VMs or 4 medium VMs |\n| 64GB+ | 8+ medium VMs, or density mode |\n\n**Density mode:** Run 2-4 Ralphs per VM when working on separate directories.\n\n## Credentials Setup\n\nAgents need `GITHUB_TOKEN` to push code and create PRs.\n\n1. Create token: https://github.com/settings/tokens/new (scopes: `repo`, `workflow`)\n2. Add to `~/.config/ralph/ralph.env`:\n   ```bash\n   export GITHUB_TOKEN=\"ghp_your_token_here\"\n   ```\n3. Run `./scripts/create-ralph-env.sh` to create the env file, or `./scripts/sync-credentials.sh <vm>` to update existing VMs\n\nThe token is used by both `git push/pull` (credential helper) and `gh` CLI (auto-detects env var).\n\nAgent auth files are synced to VMs when you run `fabrik credentials sync` (or the bash equivalent).\n\nRequired by default (pi):\n- `~/.pi/agent/auth.json` (created by `pi` then `/login`)\n\nOptional (only if using `RALPH_AGENT=codex`):\n- `~/.codex/auth.json` (created by `codex login`)\n\nOptional (only if using `RALPH_AGENT=claude`):\n- `~/.claude` or `~/.claude.json` (created by `claude login` / `claude setup-token`)\n\n## Prerequisites\n\n```bash\n# Docker (for LAOS)\ndocker --version\n\n# SSH key (for VM access)\nls ~/.ssh/id_rsa.pub || ssh-keygen -t rsa -b 4096\n\n# macOS: Colima 0.6+\nbrew install colima docker\n\n# Linux: libvirt + KVM\nsudo apt install qemu-kvm libvirt-daemon-system virtinst\n```\n\n## The Goal\n\n```\nBefore:  Human writes code, human reviews code, human ships\nAfter:   Human writes spec ──────────────────► Human gets \"shipped\" notification\n                           (agents do the rest)\n```\n\n## Disk Usage\n\nDisk usage to watch:\n  - ~/.lima/ - VM disks (20GB+ per VM)\n  - ~/.cache/ralph/ - Downloaded images (~6GB per\n  architecture)\n  - ~/vms/ralph/ - libvirt VM disks on Linux\n\nFor the cloud-hosted version of this, see [Sprites](https://sprites.dev) + [Wisp](https://github.com/thruflo/wisp).\n### Immutable Runs + Local DB\n\nEach Smithers run gets a new workdir. Runs are tracked in a local SQLite DB:\n\n```\n~/.cache/ralph/ralph.db\n```\n\nCleanup old runs:\n\n```bash\n./scripts/cleanup-workdirs.sh ralph-1 --keep 5\n```\n\nRecord human feedback:\n\n```bash\n./scripts/record-human-feedback.sh --vm ralph-1 --spec specs/010-weekly-summary.json \\\n  --decision approve --notes \"Looks good.\"\n```\nSpec is explicit:\n- You choose the spec with `--spec`, not inside the prompt.\n\nContext stack now:\n\n```\n[\n  PROMPT.md (global instructions, if provided),\n  spec.json-derived system prompt,\n  task.do / task.verify,\n  JJ instructions,\n  report schema\n]\n```\n\nReviewer stack:\n\n```\n[\n  REVIEW_PROMPT.md (if provided),\n  reviewer-specific prompt (from prompts/reviewers/*.md),\n  spec.json-derived system prompt,\n  Smithers db task_report rows,\n  review schema\n]\n```\n" },
  { path: "WORKFLOW.md", contents: "# Ralph Workflow Guide\n\nSmithers is required; the legacy bash loop is not used.\n\nHow to run single and multi-Ralph setups efficiently.\n\n## Smithers Full-Orchestration Mode (Required)\n\nSmithers replaces the bash loop inside each VM. The host still handles VM lifecycle and sync, but Smithers runs the plan. The legacy bash loop is no longer used. JJ is the required VCS (colocated Git backend).\n\n## Prompt Control\n\nProvide per-run instructions with `PROMPT.md` and reviewer instructions with `REVIEW_PROMPT.md`. PI models are defined in `~/.pi/agent/models.json` (optional) and selected via `--model <name>` or `SMITHERS_MODEL`.\n\n```bash\n./dist/fabrik run --spec specs/feature.json --vm ralph-1 \\\n  --prompt ./prompts/PROMPT-implementer.md \\\n  --review-prompt ./prompts/PROMPT-reviewer.md\n```\n\n## JJ Primer (Required)\n\n```\nClone:              jj git clone <url> <dir>\nInit in repo:       jj git init\nStart change:       jj new master\nStatus:             jj status\nDiff:               jj diff\nDescribe change:    jj describe\nPush change:        jj git push --bookmark <branch>\n```\n\nCommit message rules:\n- Conventional Commits: type(scope): subject\n- Trailers: spec, todo, run\n- For root-cause fixes, include: cause → reasoning → fix and relevant error output\n\n```\nHost fabrik run\n     │\n     ▼\nVM workdir (spec.json + todo.json, minified on dispatch + workflow.tsx)\n     │\n     ▼\nsmithers workflow.tsx\n  ├─ runs tasks sequentially or in parallel\n  ├─ writes task_report rows in the Smithers db\n  └─ persists state in .smithers/*.db\n```\n\nRecommended when you want durable, inspectable multi-step plans with deterministic replay.\n\n## Git Strategies for Parallel Work\n\n### Single Ralph: Feature Branches\n\nOne Ralph, one branch, simple:\n\n```bash\n# Ralph works on a feature branch\ngit checkout -b feat/user-auth\n# ... Ralph implements ...\ngit push -u origin feat/user-auth\ngh pr create\n```\n\n### Multi-Ralph: Separate VMs, Separate Branches\n\nEach VM clones the repo and works on its own branch:\n\n```bash\n# In ralph-1 VM:\ngit clone git@github.com:org/repo.git\ncd repo\ngit checkout -b feat/auth\n# ... Ralph implements ...\n\n# In ralph-2 VM:\ngit clone git@github.com:org/repo.git\ncd repo\ngit checkout -b feat/dashboard\n# ... Ralph implements ...\n```\n\nEach Ralph pushes to its own branch → creates its own PR. Simple.\n\n### Multi-Ralph: Jujutsu (jj) - Advanced Parallel Work\n\n[Jujutsu](https://github.com/martinvonz/jj) handles parallel changes natively (no worktrees needed):\n\n```bash\n# Initialize or clone\njj git clone git@github.com:org/repo.git\ncd repo\n\n# Create changes for each Ralph (no explicit branches needed)\njj new master -m \"feat: user auth\"      # Creates change A\njj new master -m \"feat: dashboard\"      # Creates change B\njj new master -m \"fix: api error\"       # Creates change C\n\n# Each Ralph works on a different change\n# jj handles rebasing automatically when main updates\n```\n\n**Benefits:**\n- No branch name juggling\n- Automatic rebasing when main updates\n- First-class parallel changes in a single working directory\n- Easier to squash/reorganize before PR\n\n### Multi-Ralph: Same Spec, Different Tasks (jj)\n\nMultiple Ralphs can work on ONE large spec, each picking different tasks:\n\n```bash\n# One spec with multiple tasks\n# specs/big-feature.md:\n#   - Task 1: Add user model\n#   - Task 2: Add auth endpoints\n#   - Task 3: Add tests\n#   - Task 4: Add documentation\n\n# All Ralphs start from main, work on different tasks\njj new master -m \"task-1: user model\"     # Ralph-1 picks this\njj new master -m \"task-2: auth endpoints\" # Ralph-2 picks this\njj new master -m \"task-3: tests\"          # Ralph-3 picks this\njj new master -m \"task-4: docs\"           # Ralph-4 picks this\n\n# jj automatically handles when tasks touch same files\n# Conflicts surface immediately, agents can coordinate\n```\n\n**How it works:**\n1. Orchestrator parses spec, creates jj changes for each task\n2. Each Ralph gets assigned a change to work on\n3. Ralphs commit to their change as they work\n4. jj auto-rebases when main updates or other changes land\n5. When all tasks done, squash or merge as needed\n\n```bash\n# After all Ralphs complete, combine changes\njj rebase -s task-1 -d main\njj rebase -s task-2 -d task-1\njj rebase -s task-3 -d task-2\njj rebase -s task-4 -d task-3\n\n# Or keep parallel and merge all at once\njj git push --all\n# Create PR that includes all changes\n```\n\n**Conflict handling:**\n- jj shows conflicts immediately (even uncommitted)\n- Ralphs can see \"task-2 conflicts with your changes\"\n- Orchestrator can pause one Ralph while another resolves\n- Or let both continue and resolve conflicts at merge time\n\n---\n\n## Shared Spec Workflow (Swarm on One Feature)\n\nMultiple Ralphs work on the same large feature, each owning a task:\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│  specs/big-feature.md                                           │\n│  ├── Task 1: Add user model (Ralph-1)                          │\n│  ├── Task 2: Add auth endpoints (Ralph-2)                       │\n│  ├── Task 3: Add tests (Ralph-3)                                │\n│  └── Task 4: Add documentation (Ralph-4)                        │\n└─────────────────────────────────────────────────────────────────┘\n                             │\n                    jj new master (×4)\n                             │\n         ┌───────────┬───────┴───────┬───────────┐\n         ▼           ▼               ▼           ▼\n    ┌─────────┐ ┌─────────┐    ┌─────────┐ ┌─────────┐\n    │ Ralph-1 │ │ Ralph-2 │    │ Ralph-3 │ │ Ralph-4 │\n    │ task-1  │ │ task-2  │    │ task-3  │ │ task-4  │\n    │ model   │ │ api     │    │ tests   │ │ docs    │\n    └────┬────┘ └────┬────┘    └────┬────┘ └────┬────┘\n         │           │               │           │\n         └───────────┴───────┬───────┴───────────┘\n                             │\n                    jj squash / merge\n                             │\n                             ▼\n                    ┌─────────────────┐\n                    │  Single PR      │\n                    │  \"Big Feature\"  │\n                    └─────────────────┘\n```\n\n### Setup\n\n```bash\n# 1. Write your spec with clear task breakdown\ncat > specs/big-feature.md << 'EOF'\n# Big Feature Spec\n\n## Overview\nAdd complete user authentication system.\n\n## Tasks\n\n### Task 1: User Model\n- Add User entity with email, password hash, created_at\n- Add migration\n- Files: src/models/user.ts, src/db/migrations/\n\n### Task 2: Auth Endpoints\n- POST /auth/register\n- POST /auth/login\n- POST /auth/refresh\n- Files: src/routes/auth.ts, src/services/auth.ts\n\n### Task 3: Tests\n- Unit tests for auth service\n- Integration tests for endpoints\n- Files: tests/\n\n### Task 4: Documentation\n- API docs for auth endpoints\n- README updates\n- Files: docs/, README.md\nEOF\n\n# 2. Create jj changes for each task\ncd ~/projects/myapp\njj new master -m \"task-1: user model\"\njj new master -m \"task-2: auth endpoints\"\njj new master -m \"task-3: tests\"\njj new master -m \"task-4: documentation\"\n\n# 3. Prepare spec/todo JSON for each task\n#    (store in specs/, then validate; fabrik minifies on dispatch)\nbun run scripts/validate-specs.ts\n\n# 4. Launch swarm (fleet)\n./scripts/smithers-fleet.sh specs ralph\n```\n\n### Dependency Handling\n\nTasks often depend on each other. Handle this with jj stacking:\n\n```bash\n# Task 2 depends on Task 1? Stack them:\njj rebase -s task-2 -d task-1\n\n# Now task-2 sees task-1's changes\n# Ralph-2 can continue working\n\n# When task-1 updates, task-2 auto-rebases\n```\n\n### Merging Results\n\n```bash\n# Option A: Linear history (rebase chain)\njj rebase -s task-1 -d main\njj rebase -s task-2 -d task-1\njj rebase -s task-3 -d task-2\njj rebase -s task-4 -d task-3\n\n# Option B: Merge commit (parallel history)\njj new task-1 task-2 task-3 task-4 -m \"feat: big feature complete\"\n\n# Push and create PR\njj git push -c @\ngh pr create --title \"Big Feature\" --body \"Implements auth system\"\n```\n\n---\n\n## Single Ralph Workflow (Smithers Required)\n\n```\n┌──────────────────────────────────────┐\n│  Human writes spec + todo            │\n│  └── specs/feature-x.json/.todo.json │\n└──────────────────┬───────────────────┘\n                   ▼\n┌──────────────────────────────────────┐\n│  Ralph implements                    │\n│  └── Commits to feat/feature-x      │\n│  └── Creates PR when done            │\n└──────────────────┬───────────────────┘\n                   ▼\n┌──────────────────────────────────────┐\n│  Human reviews reports               │\n│  └── Approves or requests changes    │\n└──────────────────┬───────────────────┘\n                   ▼\n┌──────────────────────────────────────┐\n│  Merge & ship                        │\n│  └── Human gets \"shipped\" notice     │\n└──────────────────────────────────────┘\n```\n\n### Setup\n\n```bash\n# Create VM\n./scripts/create-ralph.sh ralph-1\n\n# Prepare spec + todo\ncp specs/templates/spec.json specs/feature-x.json\ncp specs/templates/todo.json specs/feature-x.todo.json\n# Edit both files, then validate\nbun run scripts/validate-specs.ts\n\n# Start Smithers workflow\n./dist/fabrik run --spec specs/feature-x.json --vm ralph-1\n\n# Watch\ntmux attach -t ralph-1\n```\n\n---\n\n## Multi-Ralph Parallel Workflow (Smithers Required)\n\n```\n┌────────────────────────────────────────────────────────────┐\n│  Human writes specs + todos                                │\n│  └── specs/auth.json, specs/dashboard.json, specs/api.json │\n└────────────────────────────┬───────────────────────────────┘\n                             ▼\n┌─────────────┬─────────────┬─────────────┬─────────────────┐\n│  Ralph-1    │  Ralph-2    │  Ralph-3    │  Ralph-4        │\n│  (VM)       │  (VM)       │  (VM)       │  (VM)           │\n│  feat/auth  │  feat/dash  │  fix/api    │  feat/notifs    │\n└──────┬──────┴──────┬──────┴──────┬──────┴────────┬────────┘\n       │             │             │               │\n       ▼             ▼             ▼               ▼\n┌──────────────────────────────────────────────────────────┐\n│  4 PRs created in parallel                               │\n└──────────────────────────────────────────────────────────┘\n```\n\n### Setup\n\n```bash\n# Prepare specs + todos\ncp specs/templates/spec.json specs/auth.json\ncp specs/templates/todo.json specs/auth.todo.json\ncp specs/templates/spec.json specs/dashboard.json\ncp specs/templates/todo.json specs/dashboard.todo.json\ncp specs/templates/spec.json specs/api-fix.json\ncp specs/templates/todo.json specs/api-fix.todo.json\n\n# Edit files, then validate\nbun run scripts/validate-specs.ts\n\n# Create VMs\nfor i in 1 2 3; do\n  ./scripts/create-ralph.sh ralph-$i 2 4 20\ndone\n\n# Start fleet (fleet)\n./scripts/smithers-fleet.sh specs ralph\n\n# Monitor via logs/LAOS or VM tmux if you start a local session\n```\n\n---\n\n## Multi-Agent Coordination (Implementer + Reviewer)\n\nReviewer agents provide code quality, security, and spec-compliance feedback. After review, a human approves before the next spec run.\n\nRuns are immutable: every dispatch creates a new workdir. Track runs in `~/.cache/ralph/ralph.db` and clean old workdirs when needed.\n\n```\n┌─────────────────────────────────────────────────────────────────┐\n│  Human writes spec                                              │\n└───────────────────────────────┬─────────────────────────────────┘\n                                ▼\n┌─────────────────────────────────────────────────────────────────┐\n│  Implementer Smithers                                           │\n│  └── Implements feature                                         │\n│  └── Writes task_report rows in Smithers db                     │\n└───────────────────────────────┬─────────────────────────────────┘\n                                ▼\n                    ┌───────────────────────┐\n                    │  Reports Directory    │\n                    │  .smithers/*.db       │\n                    └───────────┬───────────┘\n                                ▼\n┌─────────────────────────────────────────────────────────────────┐\n│  Reviewer Smithers                                              │\n│  └── Reviews code vs spec + reports                             │\n│  └── Writes review_summary row                                  │\n└───────────────────────────────┬─────────────────────────────────┘\n                                ▼\n                    ┌───────────────────────┐\n                    │  Feedback loops back  │\n                    │  to Implementer       │\n                    └───────────────────────┘\n                                ▼\n┌─────────────────────────────────────────────────────────────────┐\n│  Human                                                         │\n│  └── Reviews review_summary row                                 │\n│  └── Approves or updates spec/todo                              │\n│  └── Starts next spec run                                       │\n└───────────────────────────────┬─────────────────────────────────┘\n                                ▼\n┌─────────────────────────────────────────────────────────────────┐\n│  Human gets notified: \"Feature X shipped\"                       │\n│  └── Only intervenes for spec questions                         │\n└─────────────────────────────────────────────────────────────────┘\n```\n\n### Setup\n\n```bash\n# Create implementer VM\n./scripts/create-ralph.sh ralph-impl 4 6 30\n\n# Create reviewer VM\n./scripts/create-ralph.sh ralph-review 2 4 20\n\n# Start reviewer workflow (Smithers)\n./dist/fabrik run --spec specs/reviewer.json --vm ralph-review --workflow scripts/smithers-reviewer.tsx\n\n# Review runs automatically after tasks in scripts/smithers-spec-runner.tsx.\n```\n\n### Review Output\n\n**Reviewer Output:**\n```json\n// review_summary row\n{\n  \"v\": 1,\n  \"status\": \"approved\",\n  \"issues\": [],\n  \"next\": []\n}\n```\n\n**Human Gate:**\n```json\n// human_gate row\n{\n  \"v\": 1,\n  \"status\": \"blocked\",\n  \"reason\": \"Human review required before next spec run.\"\n}\n```\n\n**Record Human Feedback (host):**\n```bash\n./scripts/record-human-feedback.sh --vm ralph-1 --spec specs/feature-x.json \\\n  --decision approve --notes \"Spec satisfied.\"\n```\n\n---\n\n## Human Touchpoints\n\nWith this setup, humans only need to:\n\n| Action | When |\n|--------|------|\n| **Write specs** | Start of feature |\n| **Answer questions** | When a task report or human gate is `blocked` |\n| **Final merge approval** | After review_summary and human approval |\n| **Receive shipped notification** | Feature complete |\n\nThe goal: **Humans write specs, agents ship features.**\n\n---\n\n## Directory Structure\n\n```\n~/\n├── specs/                        # Spec + TODO JSON (on host)\n│   ├── auth.json\n│   ├── auth.todo.json\n│   └── ...\n│\n└── vms/                          # VM storage (Linux only)\n    └── wisp/\n```\n\nMinified copies are generated inside each run workdir and are gitignored.\n\nInside each VM:\n```\n~/\n├── repo/                         # Cloned repository\n│   └── (working on feature branch)\n├── specs/                        # Copied from host\n├── reports/                      # run logs + context\n└── .smithers/                    # SQLite state\n```\n\n---\n\n## Quick Commands\n\n```bash\n# Single Ralph\n./dist/fabrik run --spec specs/feature.json --vm ralph-1\n\n# Multi-Ralph (fleet)\n./scripts/smithers-fleet.sh specs ralph\n\n# Multi-Ralph in single VM (density mode)\n./dist/fabrik run --spec specs/auth.json --vm ralph-1\n./dist/fabrik run --spec specs/dashboard.json --vm ralph-1\n\n# Runs\n./dist/fabrik runs list --limit 10\n./dist/fabrik runs show --id <run-id>  # includes failure_reason when available\n\n# List all Ralphs\n./scripts/list-ralphs.sh\n\n# Cleanup\n./scripts/cleanup-ralphs.sh --all\n```\n" },
  { path: "OBSERVABILITY.md", contents: "# Observability & Analytics for Coding Agents\n\nRalph uses **LAOS** (Local Analytics and Observability Stack) as the shared telemetry backend. This guide covers setup, querying, and troubleshooting.\n\n**LAOS Repository:** https://github.com/dtechvision/laos\n\n## Quick Start\n\n### 1. Start LAOS on the Host\n\n```bash\nmkdir -p ~/git\nif [[ -d ~/git/laos/.git ]]; then\n  (cd ~/git/laos && git pull)\nelse\n  git clone https://github.com/dtechvision/laos.git ~/git/laos\nfi\ncd ~/git/laos && ./scripts/laos-up.sh\n```\n\n### 2. Configure Ralph Environment\n\n```bash\ncd /path/to/local-isolated-ralph\n./scripts/create-ralph-env.sh\n```\n\nEdit `~/.config/ralph/ralph.env`:\n\n```bash\n# macOS (Lima): export LAOS_HOST=\"host.lima.internal\"\n# Linux (libvirt): export LAOS_HOST=\"192.168.122.1\"\nexport LAOS_HOST=\"<your-host>\"\n\n# Telemetry endpoints\nexport OTEL_EXPORTER_OTLP_ENDPOINT=\"http://${LAOS_HOST}:4317\"\nexport LOKI_URL=\"http://${LAOS_HOST}:3100\"\nexport SENTRY_DSN=\"http://<key>@${LAOS_HOST}:9000/1\"\nexport POSTHOG_HOST=\"http://${LAOS_HOST}:8001\"\nexport POSTHOG_API_KEY=\"phc_xxx\"\nexport PYROSCOPE_SERVER_ADDRESS=\"http://${LAOS_HOST}:4040\"\n```\n\n> **Platform Selection:** Set `LAOS_PLATFORM=linux/arm64` for Apple Silicon or ARM64 Linux. Default is `linux/amd64`.\n\n### 3. Sync to VMs\n\n```bash\n./scripts/sync-credentials.sh ralph-1\n# or: fabrik credentials sync --vm ralph-1\n```\n\n### 4. Access Dashboards\n\n| Service | URL | Credentials |\n|---------|-----|-------------|\n| Grafana | http://localhost:3010 | admin/admin |\n| Sentry | http://localhost:9000 | Create on first run |\n| PostHog | http://localhost:8001 | Setup wizard |\n| Pyroscope | http://localhost:4040 | None |\n| Prometheus | http://localhost:9090 | None |\n\n## Query Reference\n\n### Health Checks\n\n```bash\ncurl http://$LAOS_HOST:3100/ready  # Loki\ncurl http://$LAOS_HOST:3200/ready  # Tempo\ncurl http://$LAOS_HOST:9090/-/ready  # Prometheus\ncurl http://$LAOS_HOST:4040/ready  # Pyroscope\ncurl -I http://localhost:8001  # PostHog (expect 302/200)\n```\n\n### Query Patterns by Tool\n\n| Tool | URL/Endpoint | Example Query | Filters/Labels |\n|------|-------------|---------------|----------------|\n| **Loki** | `:3100` | `{service_name=\"smithers\"} \\|= \"ERROR\"` | `vm`, `trace_id`, `level` |\n| **Tempo** | `:4318` | Search by trace ID or `vm=ralph-1` | `service.name`, `task` |\n| **Prometheus** | `:9090` | `rate(http_requests_total[5m])` | `job`, `status`, `vm` |\n| **Pyroscope** | `:4040` | Flame graph: `process_cpu` | `spec_id`, `vm`, `agent_type` |\n| **Sentry** | `:9000` | Issues → Stack trace + breadcrumbs | `trace_id` → links to Tempo |\n| **PostHog** | `:8001` | Events → Real-time stream | `distinct_id`, `source` |\n\n### Detailed Query Examples\n\n**Loki (Logs):**\n```logql\n# All Smithers logs\n{service_name=\"smithers\"}\n\n# Errors only\n{service_name=\"smithers\"} |= \"ERROR\"\n\n# Specific VM\n{service_name=\"smithers\", vm=\"ralph-1\"}\n\n# Parse JSON\n{service_name=\"smithers\"} | json | line_format \"{{.level}}: {{.message}}\"\n```\n\n**Prometheus (Metrics):**\n```promql\n# Service health\nup{job=\"agent-metrics\"}\n\n# Request rate\nrate(http_requests_total{job=\"smithers\"}[5m])\n\n# Error rate\nrate(http_requests_total{status=~\"5..\"}[5m])\n\n# P95 latency\nhistogram_quantile(0.95, rate(task_duration_seconds_bucket[5m]))\n```\n\n**Pyroscope (Profiles):**\n1. **View:** Select app → profile type (`process_cpu`, `memory`, `wall`)\n2. **Compare:** Select two time ranges → \"Compare\" → diff flame graph\n3. **Correlate:** In Tempo trace, click span → \"View Profile\"\n\n**Sentry (Headless verification):**\n```bash\nEVENT_ID=$(uuidgen | tr -d '-' | tr 'A-Z' 'a-z')\nDSN=\"http://YOUR_KEY@localhost:9000/2\"\nprintf '{\"event_id\":\"%s\"}\\n{\"type\":\"event\"}\\n{\"message\":\"test\",\"level\":\"error\"}\\n' \\\n  \"$EVENT_ID\" > /tmp/envelope.txt\ncurl -X POST \"http://localhost:9000/api/2/envelope/\" \\\n  -H \"Content-Type: application/x-sentry-envelope\" \\\n  --data-binary @/tmp/envelope.txt\n```\n\n## Smithers Integration\n\n### Effect-TS Observability Layer\n\n```typescript\nimport * as Otlp from \"@effect/opentelemetry/Otlp\"\nimport { NodeHttpClient } from \"@effect/platform-node\"\nimport { Config, Effect, Layer } from \"effect\"\n\nexport const OtlpLive = Layer.unwrapEffect(\n  Effect.gen(function* () {\n    const otlpEndpoint = yield* Config.string(\"OTLP_ENDPOINT\").pipe(\n      Config.orElse(() => Config.succeed(\"http://localhost:4318\")),\n    )\n    const serviceName = yield* Config.string(\"SERVICE_NAME\").pipe(\n      Config.orElse(() => Config.succeed(\"ralph-agent\")),\n    )\n    return Otlp.layer({\n      baseUrl: otlpEndpoint,\n      resource: { serviceName, attributes: { \"deployment.environment\": \"development\" } },\n    }).pipe(Layer.provide(NodeHttpClient.layerUndici))\n  }),\n)\n```\n\n### Task Instrumentation\n\n```typescript\nconst instrumentedTask = Effect.gen(function* () {\n  yield* Effect.logInfo(\"Starting task\")\n  const result = yield* processTask()\n  yield* Metric.counter(\"tasks_completed\").pipe(Metric.increment)\n  return result\n}).pipe(Effect.withSpan(\"task-execution\", { attributes: { task_id: \"001\", vm: \"ralph-1\" } }))\n```\n\n### Profiling with Labels\n\n```typescript\nexport const handleSpecRun = (spec: string) =>\n  Effect.gen(function* () {\n    const profiling = yield* Profiling\n    return yield* profiling.withLabels(\n      { spec_id: spec, vm: process.env.VM_NAME || \"unknown\" },\n      Effect.promise(() => runSmithersWorkflow(spec)),\n    )\n  })\n```\n\n## Troubleshooting\n\n### No Telemetry Appearing\n\n```bash\n# 1. Verify LAOS is running\ncd ~/git/laos && docker compose ps\n\n# 2. Check service health\ncurl http://$LAOS_HOST:3100/ready  # Loki, etc.\n\n# 3. Check LAOS_HOST (macOS: host.lima.internal, Linux: 192.168.122.1)\n\n# 4. Sync credentials\n./scripts/sync-credentials.sh ralph-1\n\n# 5. Test from inside VM\nlimactl shell ralph-1\ncurl http://$LAOS_HOST:3100/ready\n```\n\n### Root Cause Analysis Flow\n\n```\nGrafana Dashboard → \"Error rate spike\"\n       ↓\nSentry → \"NullReferenceException in auth.ts:42\"\n       ↓\nTempo Trace → DB call span = 5s\n       ↓\nLoki Logs → \"Connection timeout to postgres\"\n       ↓\nPyroscope → CPU saturated on connection pool\n```\n\nAll signals linked by `trace_id` and `span_id`.\n\n### Common Issues\n\n| Issue | Solution |\n|-------|----------|\n| macOS ARM64 platform errors | `softwareupdate --install-rosetta --agree-to-license` |\n| Port conflicts | `lsof -i :3010 :9000 :8001` |\n| PostHog slow startup | Normal, wait for `curl -I localhost:8001` to return 302 |\n| Reset everything | `docker compose down -v && docker compose up -d` |\n\n## Further Reading\n\n- **LAOS Repository:** https://github.com/dtechvision/laos\n- **LAOS Setup Guide:** `~/git/laos/SETUP-LAOS.md`\n- **Effect + Telemetry:** `~/git/laos/examples/observability-layer.ts`\n- **Profiling:** `~/git/laos/PYROSCOPE.md`\n" },
  { path: "QUICKSTART.md", contents: "# Quickstart: Your First Ralph Agent\n\nThis guide walks you through setting up and running your first autonomous coding agent in about 15 minutes.\n\n## Prerequisites Checklist\n\nBefore starting, ensure you have:\n\n- [ ] **macOS 13+** (Ventura) or **Linux** with KVM support\n- [ ] **Docker** installed and running\n- [ ] **SSH key** generated (`ls ~/.ssh/id_*.pub`)\n- [ ] **pi auth** on host (`pi` then `/login`) — default agent\n- [ ] **Codex auth** if using Codex (`codex login`)\n- [ ] **Claude auth** if using Claude (`claude auth login`)\n\n**macOS specific:**\n```bash\nbrew install colima docker\ncolima version  # Should be 0.6.0+\n```\n\n**Linux specific:**\n```bash\nsudo apt install qemu-kvm libvirt-daemon-system virtinst cloud-image-utils\nvirsh list --all  # Should work without errors\n```\n\n---\n\n## Step 1: Start LAOS (Optional but Recommended)\n\nThe LAOS stack lets you monitor your agent's progress in Grafana, plus Sentry/PostHog.\n\n```bash\n# Source of truth: https://github.com/dtechvision/laos\nmkdir -p ~/git\nif [[ -d ~/git/laos/.git ]]; then\n  (cd ~/git/laos && git pull)\nelse\n  git clone https://github.com/dtechvision/laos.git ~/git/laos\nfi\ncd ~/git/laos\ndocker compose up -d\n\n# Verify it's running\ncurl http://localhost:3010/api/health  # Grafana\n```\n\nOpen http://localhost:3010 (login: admin/admin) to see dashboards.\n\nOptional: create a shared env file so LAOS endpoints get copied into VMs:\n\n```bash\ncd /path/to/local-isolated-ralph\n./scripts/create-ralph-env.sh\n# Edit ~/.config/ralph/ralph.env and set:\n# macOS (Lima):  LAOS_HOST=host.lima.internal\n# Linux (libvirt): LAOS_HOST=192.168.122.1\n```\n\n---\n\n## Step 2: Authenticate Agents on Your Host\n\nIf you haven't already, authenticate pi on your host machine:\n\n```bash\npi\n/login\n```\n\nThis creates `~/.pi/agent/auth.json` which will be copied to your VMs.\n\nOptional (only if using Codex):\n\n```bash\ncodex login\n```\n\nOptional (only if using Claude):\n\n```bash\nclaude auth login\n```\n\n---\n\n## Step 3: Set Up GitHub Token\n\nCreate a token at https://github.com/settings/tokens/new (scopes: `repo`, `workflow`) and add to `~/.config/ralph/ralph.env`:\n\n```bash\n./scripts/create-ralph-env.sh\n# Edit the file and add: export GITHUB_TOKEN=\"ghp_your_token\"\n```\n\n---\n\n## Step 4: Create Your First Ralph VM\n\n```bash\ncd /path/to/local-isolated-ralph\n\n# Create a VM (this takes ~1-2 minutes)\n./scripts/create-ralph.sh ralph-1\n\n# The script will:\n# - Create a VM with 4 CPU, 6GB RAM, 30GB disk\n# - Copy your ~/.claude auth folder to the VM\n# - Install Smithers (required)\n# - Copy ~/.config/ralph/ralph.env (with GITHUB_TOKEN)\n```\n\n---\n\n## Step 5: Set Up the VM\n\nSSH into the VM and run the setup script:\n\n**macOS:**\n```bash\ncolima ssh -p ralph-1\n\n# Inside VM:\ncurl -fsSL https://raw.githubusercontent.com/your-org/local-isolated-ralph/main/scripts/setup-base-vm.sh | bash\n# Or if you have the repo mounted:\n# bash /path/to/scripts/setup-base-vm.sh\n```\n\n**Linux:**\n```bash\n# Get VM IP\nVM_IP=$(virsh domifaddr ralph-1 | grep ipv4 | awk '{print $4}' | cut -d/ -f1)\nssh dev@$VM_IP\n\n# Inside VM:\ncurl -fsSL https://raw.githubusercontent.com/your-org/local-isolated-ralph/main/scripts/setup-base-vm.sh | bash\n```\n\nThe setup script installs Node.js, Claude CLI, GitHub CLI, Playwright, and more.\n\n**Configure git identity:**\n```bash\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your@email.com\"\n```\n\n**Verify Claude auth works:**\n```bash\nclaude --version\n# Should show version without auth errors\n```\n\n**Install Smithers (required):**\n```bash\nbun add -g github:evmts/smithers#ea5ece3b156ebd32990ec9c528f9435c601a0403\n```\n\n**Verify JJ is available (required):**\n```bash\njj --version\n```\n\nExit the VM when done: `exit`\n\nIf you need to re-sync credentials later:\n\n```bash\n./scripts/sync-credentials.sh ralph-1\n# Or via CLI\nfabrik credentials sync --vm ralph-1\n```\n\nTo store a Claude Code token for syncing:\n\n```bash\n./scripts/create-ralph-env.sh\n# Edit ~/.config/ralph/ralph.env and set:\n# export CLAUDE_CODE_OAUTH_TOKEN=\"...\"\n```\n\nNote: Claude CLI auth is stored in `~/.claude.json` on the host. Make sure it exists (or set `ANTHROPIC_API_KEY` in `ralph.env`) before syncing.\n\n---\n\n## Step 6: Write Your First Spec\n\nCreate a JSON spec and TODO (Fabrik will minify on dispatch):\n\n```bash\n# Use templates as a starting point\ncp specs/templates/spec.json specs/001-hello-world.json\ncp specs/templates/todo.json specs/001-hello-world.todo.json\n\n# Edit both files, then validate\nbun run scripts/validate-specs.ts\n```\n\n---\n\n## Step 7: Run Smithers\n\n**Use the Fabrik CLI (runs from host)**\n\n```bash\n# Smithers mode (spec/todo JSON; minified on dispatch)\n./dist/fabrik run --spec specs/001-hello-world.json --vm ralph-1\n\n# Sync a local project directory to the VM\n./dist/fabrik run --spec specs/001-hello-world.json --vm ralph-1 --project ~/projects/my-app\n\n# Limit iterations (stops after 20 Smithers iterations)\n./dist/fabrik run --spec specs/001-hello-world.json --vm ralph-1 --project ~/projects/my-app --iterations 20\n\n# Or use environment variable\nMAX_ITERATIONS=10 ./dist/fabrik run --spec specs/001-hello-world.json --vm ralph-1\n```\n\n**Smithers loop at a glance:**\n```\nspec.json + todo.json (minified on dispatch) → smithers workflow → task_report rows (per task)\n```\n\n---\n\n## Step 8: Watch and Wait\n\nThe workflow will:\n1. Read `spec.json` + `todo.json` (minified on dispatch)\n2. Implement tasks in order\n3. Write `task_report` rows in the Smithers SQLite db\n4. Run an agent reviewer\n5. Write `review_report`, `review_summary`, and `human_gate` rows in the Smithers db\n6. Stop for human review\n\n**Monitor progress:**\n\n- Watch the terminal output directly\n- Or check Grafana at http://localhost:3010 for logs\n- Check iteration status: `cat ~/work/state/status`\n- Or use the CLI watcher: `fabrik runs watch --vm ralph-1`\n- Inspect failures with `fabrik runs show --id <run-id>` (prints `failure_reason` when available)\n\n**Human review gate:**\n\nAfter the reviewer runs, a `human_gate` row is written in the Smithers db with `status: \"blocked\"`.\nHuman approves, then starts the next spec run.\n\n**Custom prompts:**\n\n```bash\n./dist/fabrik run --spec specs/001-hello-world.json --vm ralph-1 \\\n  --prompt ./prompts/PROMPT-implementer.md \\\n  --review-prompt ./prompts/PROMPT-reviewer.md\n```\n\nRecord feedback:\n\n```bash\n./scripts/record-human-feedback.sh --vm ralph-1 --spec specs/001-hello-world.json \\\n  --decision approve --notes \"Matches spec.\"\n```\n\n### Desktop notifications\n\nInstall a notifier to get popups from `fabrik runs watch`:\n\n- macOS: `brew install terminal-notifier`\n- Linux: `sudo apt install libnotify-bin` (provides `notify-send`)\n\n**Immutable runs:**\n\nEach run gets a new workdir and is tracked in `~/.cache/ralph/ralph.db`.\n\n---\n\n## Step 9: Cleanup\n\nWhen done, you can stop or delete the VM:\n\n**macOS:**\n```bash\ncolima stop -p ralph-1     # Stop (preserves state)\ncolima delete -p ralph-1   # Delete completely\n```\n\nCleanup old workdirs:\n\n```bash\n./scripts/cleanup-workdirs.sh ralph-1 --keep 5\n```\n\n**Linux:**\n```bash\nvirsh shutdown ralph-1                              # Stop\nvirsh destroy ralph-1; virsh undefine ralph-1 --remove-all-storage  # Delete\n```\n\n---\n\n## Next Steps\n\n- **Run multiple Ralphs**: See [WORKFLOW.md](./WORKFLOW.md) for fleet patterns\n- **Create a VM template**: Set up once, snapshot, clone quickly\n- **Use Jujutsu (jj)**: For advanced parallel work on the same repo\n- **Set up Implementer + Reviewer**: Agents review each other's code\n\n---\n\n## Quick Reference\n\n| Task | macOS | Linux |\n|------|-------|-------|\n| Create VM | `./scripts/create-ralph.sh ralph-1` | Same |\n| SSH into VM | `colima ssh -p ralph-1` | `ssh dev@<IP>` |\n| Get VM IP | N/A (use colima ssh) | `virsh domifaddr ralph-1` |\n| Stop VM | `colima stop -p ralph-1` | `virsh shutdown ralph-1` |\n| Delete VM | `colima delete -p ralph-1` | `virsh undefine ralph-1 --remove-all-storage` |\n| List VMs | `colima list` | `virsh list --all` |\n\n---\n\n## Troubleshooting\n\n### VM creation fails\n\n**macOS**: Try falling back to QEMU:\n```bash\ncolima start -p ralph-1 --vm-type qemu --cpu 4 --memory 6\n```\n\n**Linux**: Check KVM is enabled:\n```bash\nlscpu | grep Virtualization  # Should show VT-x or AMD-V\n```\n\n### Claude auth not working in VM\n\nRe-copy the auth folder:\n```bash\n# macOS\ntar -C ~ -cf - .claude | colima ssh -p ralph-1 -- tar -C ~ -xf -\n\n# Linux\nscp -r ~/.claude dev@<VM_IP>:~/\n```\n\n### Agent loops forever\n\n- Check `~/work/state/status` for current state\n- The workflow stops when all tasks are done or when a task is blocked/failed\n- Set `MAX_ITERATIONS=10` to limit loops during testing\n\n### Can't reach LAOS from VM\n\n**macOS**: Use `host.lima.internal`\n**Linux**: Use `192.168.122.1` (libvirt default gateway)\n\nTest from inside VM:\n```bash\ncurl http://host.lima.internal:3010/api/health   # macOS\ncurl http://192.168.122.1:3010/api/health        # Linux\n```\n" },
  { path: "specs/README.md", contents: "# Specs Workflow (Human Guide)\n\nThis repo follows a strict, test-driven flow for all features.\n\n## Flow\n1) **PRD → Spec**\n   - Human drafts `PRD.md` using `specs/templates/PRD.template.md`.\n   - Human verifies PRD with `specs/PRD-GUIDE.md`.\n   - Agent drafts `spec.json` from the approved PRD.\n   - Human reviews and edits `spec.json`.\n\n2) **Spec → TODO**\n   - Agent generates `todo.json` from the approved spec.\n\n3) **TODO → Implementation (Smithers)**\n   - Smithers runs tasks in order with tests first.\n   - Write `task_report` rows per task in the Smithers db (includes root-cause fields).\n\n4) **Manual Review Checkpoints**\n   - Review after each spec before proceeding to the next.\n\n## Diagram\n\n```\nPRD.md → spec.json → todo.json → fabrik dispatch (minify) → Smithers workflow → task_report rows\n                               (token-efficient input)    (per task)\n```\n\n## Files\n- Specs (human): `specs/*.json`\n- TODOs (human): `specs/*.todo.json`\n- Minified inputs: generated in the run workdir (gitignored)\n\n## Current Specs\n- `000-base`\n- `020-fabrik-v0-2-0`\n- `021-fabrik-run-persistence`\n- `022-fabrik-doctor`\n\n## Report Format (per task)\n`task_report` rows include:\n- `status`, `work`, `files`, `tests`, `issues`, `next`\n- `rootCause`, `reasoning`, `fix`, `error`, `commit`\n\n## Minified Inputs (Smithers)\n- `fabrik run` minifies spec/todo JSON on dispatch and writes the minified copies into the run workdir.\n- Minified files are **not** tracked in git.\n\n## Testing Requirements\n- TDD is mandatory.\n- Use `@effect/vitest` and Effect DI for external services.\n- Definition of Done: `bun test`, `bun run typecheck`.\n\n## Start Here\n- Read `specs/templates/PRD.template.md` and `specs/PRD-GUIDE.md`.\n- Read `specs/000-base.md`, `specs/000-base.json`, and `specs/000-base.todo.json`.\n- Implement in order, with tests first.\n" }
]
