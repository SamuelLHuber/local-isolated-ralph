// Generated by scripts/embed-assets.ts. Do not edit.
export type EmbeddedAsset = { path: string; contents: string; mode?: number }

export const embeddedAssets: EmbeddedAsset[] = [
  { path: "scripts/smithers-spec-runner.tsx", contents: "#!/usr/bin/env smithers\n/** @jsxImportSource smithers-orchestrator */\nimport { existsSync, mkdirSync, readFileSync, readdirSync } from \"node:fs\"\nimport { dirname, join, resolve } from \"node:path\"\nimport { z } from \"zod\"\nimport {\n  createSmithers,\n  Sequence,\n  Parallel,\n  Ralph,\n  PiAgent,\n  CodexAgent,\n  ClaudeCodeAgent\n} from \"smithers-orchestrator\"\n\ntype Spec = {\n  id: string\n  title: string\n  goals: string[]\n  nonGoals: string[]\n  req: {\n    api: string[]\n    behavior: string[]\n    obs: string[]\n  }\n  accept: string[]\n  assume: string[]\n}\n\ntype TodoTask = { id: string; do: string; verify: string }\ntype Todo = { id: string; tdd: boolean; dod: string[]; tasks: TodoTask[] }\n\ntype Review = {\n  v: number\n  reviewer: string\n  status: \"approved\" | \"changes_requested\"\n  issues: string[]\n  next: string[]\n}\n\ntype ReviewSummary = {\n  v: number\n  status: \"approved\" | \"changes_requested\"\n  issues: string[]\n  next: string[]\n}\n\ntype Report = {\n  v: number\n  taskId: string\n  status: \"done\" | \"blocked\" | \"failed\"\n  work: string[]\n  files: string[]\n  tests: string[]\n  issues: string[]\n  next: string[]\n}\n\ntype HumanGate = {\n  v: number\n  status: \"blocked\"\n  reason: string\n}\n\nconst env = process.env\nconst specPath = resolve(env.SMITHERS_SPEC_PATH ?? env.SPEC_PATH ?? \"specs/000-base.json\")\nconst todoPath = resolve(env.SMITHERS_TODO_PATH ?? env.TODO_PATH ?? \"specs/000-base.todo.json\")\nconst reportDir = resolve(env.SMITHERS_REPORT_DIR ?? env.REPORT_DIR ?? \"reports\")\nconst promptPath = env.SMITHERS_PROMPT_PATH\nconst reviewPromptPath = env.SMITHERS_REVIEW_PROMPT_PATH\nconst reviewersDir = env.SMITHERS_REVIEWERS_DIR ?? \"prompts/reviewers\"\nconst reviewModelsPath = env.SMITHERS_REVIEW_MODELS_FILE\nconst execCwd = env.SMITHERS_CWD ? resolve(env.SMITHERS_CWD) : process.cwd()\nconst agentKind = (env.SMITHERS_AGENT ?? env.RALPH_AGENT ?? \"pi\").toLowerCase()\nconst modelOverride = env.SMITHERS_MODEL ?? env.MODEL\nconst providerOverride = env.SMITHERS_PROVIDER ?? env.PI_PROVIDER\nconst reviewMax = Number(env.SMITHERS_REVIEW_MAX ?? 2)\n\nconst spec = JSON.parse(readFileSync(specPath, \"utf8\")) as Spec\nconst todo = JSON.parse(readFileSync(todoPath, \"utf8\")) as Todo\n\nconst dbPath = resolve(env.SMITHERS_DB_PATH ?? join(\".smithers\", `${spec.id}.db`))\nif (!existsSync(dirname(dbPath))) {\n  mkdirSync(dirname(dbPath), { recursive: true })\n}\nif (!existsSync(reportDir)) {\n  mkdirSync(reportDir, { recursive: true })\n}\n\nconst reportSchema = z.object({\n  v: z.number(),\n  taskId: z.string(),\n  status: z.enum([\"done\", \"blocked\", \"failed\"]),\n  work: z.array(z.string()),\n  files: z.array(z.string()),\n  tests: z.array(z.string()),\n  issues: z.array(z.string()),\n  next: z.array(z.string())\n})\n\nconst reviewSchema = z.object({\n  v: z.number(),\n  reviewer: z.string(),\n  status: z.enum([\"approved\", \"changes_requested\"]),\n  issues: z.array(z.string()),\n  next: z.array(z.string())\n})\n\nconst reviewSummarySchema = z.object({\n  v: z.number(),\n  status: z.enum([\"approved\", \"changes_requested\"]),\n  issues: z.array(z.string()),\n  next: z.array(z.string())\n})\n\nconst humanGateSchema = z.object({\n  v: z.number(),\n  status: z.literal(\"blocked\"),\n  reason: z.string()\n})\n\nconst { Workflow, Task, smithers } = createSmithers(\n  {\n    taskReport: reportSchema,\n    reviewReport: reviewSchema,\n    reviewSummary: reviewSummarySchema,\n    humanGate: humanGateSchema\n  },\n  { dbPath }\n)\n\nconst systemPrompt = [\n  `Spec ID: ${spec.id}`,\n  `Title: ${spec.title}`,\n  \"\",\n  \"Goals:\",\n  ...spec.goals.map((g) => `- ${g}`),\n  \"\",\n  \"Non-goals:\",\n  ...spec.nonGoals.map((g) => `- ${g}`),\n  \"\",\n  \"API requirements:\",\n  ...spec.req.api.map((r) => `- ${r}`),\n  \"\",\n  \"Behavior requirements:\",\n  ...spec.req.behavior.map((r) => `- ${r}`),\n  \"\",\n  \"Observability requirements:\",\n  ...spec.req.obs.map((r) => `- ${r}`),\n  \"\",\n  \"Acceptance criteria:\",\n  ...spec.accept.map((a) => `- ${a}`),\n  \"\",\n  \"Assumptions:\",\n  ...spec.assume.map((a) => `- ${a}`),\n  \"\",\n  `TDD required: ${todo.tdd ? \"yes\" : \"no\"}`,\n  \"Definition of done:\",\n  ...todo.dod.map((d) => `- ${d}`)\n].join(\"\\n\")\n\nconst loadPrompt = (path?: string): string => {\n  if (!path) return \"\"\n  try {\n    if (!existsSync(path)) return \"\"\n    return readFileSync(path, \"utf8\").trim()\n  } catch {\n    return \"\"\n  }\n}\n\nconst globalPrompt = loadPrompt(promptPath)\nconst reviewerPrompt = loadPrompt(reviewPromptPath)\n\ntype Reviewer = {\n  id: string\n  title: string\n  prompt: string\n}\n\n// Fallback reviewers if prompts/reviewers/ directory doesn't exist or files missing.\n// These are loaded from prompts/reviewers/*.md when available.\n// File naming: prompts/reviewers/{REVIEWER-ID}.md (uppercase with hyphens)\nconst defaultReviewers: Reviewer[] = [\n  { id: \"security\", title: \"Security\", prompt: \"\" },\n  { id: \"code-quality\", title: \"Code Quality\", prompt: \"\" },\n  { id: \"simplicity\", title: \"Minimal Simplicity\", prompt: \"\" },\n  { id: \"test-coverage\", title: \"Test Coverage\", prompt: \"\" },\n  { id: \"maintainability\", title: \"Maintainability\", prompt: \"\" },\n  { id: \"tigerstyle\", title: \"Tigerstyle Audit\", prompt: \"\" },\n  { id: \"nasa-10-rules\", title: \"NASA Engineering Principles\", prompt: \"\" },\n  { id: \"correctness-guarantees\", title: \"Correctness & Invariant Validation\", prompt: \"\" }\n]\n\nconst loadReviewers = (): Reviewer[] => {\n  if (!reviewersDir || !existsSync(reviewersDir)) return defaultReviewers\n  const files = readdirSync(reviewersDir).filter((f) => f.toLowerCase().endsWith(\".md\"))\n  if (files.length === 0) return defaultReviewers\n  return files.map((file) => {\n    const id = file.replace(/\\.md$/i, \"\").toLowerCase()\n    const title = file.replace(/\\.md$/i, \"\").replace(/[-_]/g, \" \")\n    const prompt = loadPrompt(join(reviewersDir, file))\n    return { id, title, prompt }\n  })\n}\n\nconst reviewers = loadReviewers()\n\nconst loadReviewModels = (): Record<string, string> => {\n  if (!reviewModelsPath) return {}\n  try {\n    if (!existsSync(reviewModelsPath)) return {}\n    const raw = readFileSync(reviewModelsPath, \"utf8\")\n    const parsed = JSON.parse(raw)\n    if (!parsed || typeof parsed !== \"object\") return {}\n    const map: Record<string, string> = {}\n    for (const [key, value] of Object.entries(parsed)) {\n      if (typeof value === \"string\") map[key.toLowerCase()] = value\n    }\n    return map\n  } catch {\n    return {}\n  }\n}\n\nconst reviewModels = loadReviewModels()\nconst reviewDefaultModel = reviewModels._default ?? reviewModels.default ?? reviewModels[\"*\"] ?? modelOverride\n\nconst taskSchemaExample = JSON.stringify(\n  {\n    v: 1,\n    taskId: \"task-id\",\n    status: \"done | blocked | failed\",\n    work: [\"...\"],\n    files: [\"...\"],\n    tests: [\"...\"],\n    issues: [\"...\"],\n    next: [\"...\"]\n  },\n  null,\n  2\n)\n\nconst reviewSchemaExample = JSON.stringify(\n  {\n    v: 1,\n    reviewer: \"security\",\n    status: \"approved | changes_requested\",\n    issues: [\"...\"],\n    next: [\"...\"]\n  },\n  null,\n  2\n)\n\nconst makeAgent = (model?: string) => {\n  const resolvedModel = model ?? modelOverride\n  if (agentKind === \"claude\") {\n    return new ClaudeCodeAgent({\n      model: resolvedModel ?? \"opus\",\n      dangerouslySkipPermissions: true,\n      cwd: execCwd\n    })\n  }\n  if (agentKind === \"codex\") {\n    return new CodexAgent({\n      model: resolvedModel ?? \"gpt-5.2-codex\",\n      sandbox: \"danger-full-access\",\n      dangerouslyBypassApprovalsAndSandbox: true,\n      skipGitRepoCheck: true,\n      cd: execCwd,\n      cwd: execCwd\n    })\n  }\n  return new PiAgent({\n    model: resolvedModel ?? undefined,\n    provider: providerOverride ?? undefined,\n    mode: \"text\",\n    print: true,\n    cwd: execCwd\n  })\n}\n\nconst taskAgent = makeAgent(modelOverride)\n\nconst taskNodes = todo.tasks.map((task) => ({\n  nodeId: `task-${task.id}`,\n  task\n}))\n\nconst hasBlockingTask = (ctx: { outputMaybe: (table: string, key: { nodeId: string }) => Report | undefined }) => {\n  return taskNodes.some(({ nodeId }) => {\n    const report = ctx.outputMaybe(\"taskReport\", { nodeId }) as Report | undefined\n    return report ? report.status !== \"done\" : false\n  })\n}\n\nconst shouldSkipTask = (\n  ctx: { outputMaybe: (table: string, key: { nodeId: string }) => Report | undefined },\n  index: number\n) => {\n  if (index === 0) return false\n  return taskNodes.slice(0, index).some(({ nodeId }) => {\n    const report = ctx.outputMaybe(\"taskReport\", { nodeId }) as Report | undefined\n    return report ? report.status !== \"done\" : false\n  })\n}\n\nconst buildReviewTasks = (ctx: { latest: (table: string, nodeId: string) => Review | undefined }) => {\n  const tasks: Array<{ id: string; reviewer: Reviewer; text: string }> = []\n  for (const reviewer of reviewers) {\n    const nodeId = `review-${reviewer.id}`\n    const review = ctx.latest(\"reviewReport\", nodeId) as Review | undefined\n    if (!review) continue\n    const items = [...(review.issues ?? []), ...(review.next ?? [])].filter(Boolean)\n    items.forEach((item, index) => {\n      tasks.push({\n        id: `review-task-${reviewer.id}-${index + 1}`,\n        reviewer,\n        text: `[${reviewer.title}] ${item}`\n      })\n    })\n  }\n  return tasks\n}\n\nconst combineReviews = (ctx: { outputMaybe: (table: string, key: { nodeId: string; iteration?: number }) => Review | undefined; iteration: number }) => {\n  const reviews = reviewers\n    .map((reviewer) => ctx.outputMaybe(\"reviewReport\", { nodeId: `review-${reviewer.id}`, iteration: ctx.iteration }) as Review | undefined)\n    .filter(Boolean) as Review[]\n  const issues = reviews.flatMap((r) => r.issues ?? [])\n  const next = reviews.flatMap((r) => r.next ?? [])\n  const status = reviews.length > 0 && reviews.every((r) => r.status === \"approved\") ? \"approved\" : \"changes_requested\"\n  return { v: 1, status, issues, next } satisfies ReviewSummary\n}\n\nexport default smithers((ctx) => {\n  const blocking = hasBlockingTask(ctx)\n  const latestSummary = ctx.latest(\"reviewSummary\", \"review-summary\") as ReviewSummary | undefined\n  const reviewApproved = latestSummary?.status === \"approved\"\n  const reviewIterations = ctx.iterationCount(\"reviewSummary\", \"review-summary\")\n  const reviewMaxIterations = Math.max(1, reviewMax + 1)\n  const maxReviewReached = reviewIterations >= reviewMaxIterations && !reviewApproved\n\n  const gateReason = reviewApproved\n    ? \"Human review required before next spec run.\"\n    : maxReviewReached\n      ? \"Reviewers requested changes. Max retries reached; human decision required.\"\n      : \"Reviewers requested changes. Human decision required.\"\n\n  const reviewTasks = buildReviewTasks(ctx)\n  const needsReviewTasks = latestSummary?.status === \"changes_requested\"\n\n  return (\n    <Workflow name=\"spec-workflow\">\n      <Sequence>\n        {taskNodes.map(({ nodeId, task }, index) => (\n          <Task\n            key={nodeId}\n            id={nodeId}\n            output=\"taskReport\"\n            outputSchema={reportSchema}\n            skipIf={shouldSkipTask(ctx, index)}\n            agent={taskAgent}\n          >\n            {[\n              globalPrompt,\n              systemPrompt,\n              \"\",\n              `Task ${index + 1}/${taskNodes.length}: ${task.id}`,\n              \"\",\n              \"Do:\",\n              task.do,\n              \"\",\n              \"Verify:\",\n              task.verify,\n              \"\",\n              \"Engineering Standards (MUST comply - NASA/Tigerstyle):\",\n              \"\",\n              \"1. Classify Criticality Tier (T1-T4):\",\n              \"   - T1 (Critical/Money/Auth): Needs ALL 6 layers (L1-L5 + Simulation)\",\n              \"   - T2 (Important/State): Needs L1-L5, Simulation optional\",\n              \"   - T3-T4 (Standard/Low): Needs L1-L4\",\n              \"\",\n              \"2. Implement Guarantee Layers (Defense in Depth):\",\n              \"   * L1 (Types): Branded types for domain values (UserId, not string). Phantom types for state machines.\",\n              \"   * L2 (Runtime): Effect.assert for preconditions/postconditions. Fail fast on violations.\",\n              \"   * L3 (Persistence): DB constraints (UNIQUE for idempotency, CHECK for valid values).\",\n              \"   * L4 (Tests): @property TSDoc naming each invariant. Property-based tests for correctness.\",\n              \"   * L5 (Monitoring): TODOs/alerts for production (e.g., 'detected double X').\",\n              \"   * L6 (Simulation): T1 only - seed-based 24/7 simulation plan.\",\n              \"\",\n              \"3. Tigerstyle Principles:\",\n              \"   - No primitive obsession (branded types > raw primitives)\",\n              \"   - Immutable data structures (const > let, avoid mutation)\",\n              \"   - Explicit dependencies (Effect requirements, not hidden globals)\",\n              \"   - Fail fast with guard clauses (assert early, assert often)\",\n              \"\",\n              \"4. NASA Power of Ten:\",\n              \"   - Bounded loops (no infinite recursion, fixed upper limits)\",\n              \"   - Short functions (<60 lines, single responsibility)\",\n              \"   - Check all return values (Effect error channels handled)\",\n              \"   - Explicit assertions (pre/postconditions verified)\",\n              \"\",\n              \"Version control (GitHub-compatible):\",\n              \"- Use jj. GitHub requires named branches for PRs; never use anonymous changes.\",\n              `- Create branch: \\`jj new main && jj bookmark create ${spec.id}-${task.id}\\`.`,\n              \"- Work normally (jj auto-snapshots files).\",\n\n              `- Describe: \\`jj describe -m \"...\"\\` (required before push).`,\n              `- Push to GitHub: \\`jj git push --branch ${spec.id}-${task.id}\\`.`,\n              \"  (This creates/updates the branch on origin for PR creation).\",\n              \"- If push fails (conflict), rebase: `jj rebase -d main` then force-push.\",\n              \"- If still failing, set status=failed with details.\",\n              \"\",\n              \"Output:\",\n              \"Return a single JSON object that matches this schema:\",\n              taskSchemaExample\n            ]\n              .filter((line) => line !== \"\")\n              .join(\"\\n\")}\n          </Task>\n        ))}\n\n        <Ralph\n          id=\"review-loop\"\n          until={reviewApproved}\n          maxIterations={reviewMaxIterations}\n          onMaxReached=\"return-last\"\n          skipIf={blocking}\n        >\n          <Sequence>\n            {needsReviewTasks && reviewTasks.length > 0 ? (\n              <Sequence>\n                {reviewTasks.map((task, index) => (\n                  <Task\n                    key={task.id}\n                    id={task.id}\n                    output=\"taskReport\"\n                    outputSchema={reportSchema}\n                    agent={taskAgent}\n                  >\n                    {[\n                      globalPrompt,\n                      systemPrompt,\n                      \"\",\n                      `Review Task ${index + 1}/${reviewTasks.length}: ${task.id}`,\n                      \"\",\n                      \"Do:\",\n                      task.text,\n                      \"\",\n                      \"Verify:\",\n                      \"Update code/tests and verify relevant tests pass.\",\n                      \"\",\n                      \"Engineering Standards (MUST comply - NASA/Tigerstyle):\",\n                      \"\",\n                      \"1. Classify Criticality Tier (T1-T4):\",\n                      \"   - T1 (Critical/Money/Auth): Needs ALL 6 layers (L1-L5 + Simulation)\",\n                      \"   - T2 (Important/State): Needs L1-L5, Simulation optional\",\n                      \"   - T3-T4 (Standard/Low): Needs L1-L4\",\n                      \"\",\n                      \"2. Implement Guarantee Layers (Defense in Depth):\",\n                      \"   * L1 (Types): Branded types for domain values (UserId, not string). Phantom types for state machines.\",\n                      \"   * L2 (Runtime): Effect.assert for preconditions/postconditions. Fail fast on violations.\",\n                      \"   * L3 (Persistence): DB constraints (UNIQUE for idempotency, CHECK for valid values).\",\n                      \"   * L4 (Tests): @property TSDoc naming each invariant. Property-based tests for correctness.\",\n                      \"   * L5 (Monitoring): TODOs/alerts for production (e.g., 'detected double X').\",\n                      \"   * L6 (Simulation): T1 only - seed-based 24/7 simulation plan.\",\n                      \"\",\n                      \"3. Tigerstyle Principles:\",\n                      \"   - No primitive obsession (branded types > raw primitives)\",\n                      \"   - Immutable data structures (const > let, avoid mutation)\",\n                      \"   - Explicit dependencies (Effect requirements, not hidden globals)\",\n                      \"   - Fail fast with guard clauses (assert early, assert often)\",\n                      \"\",\n                      \"4. NASA Power of Ten:\",\n                      \"   - Bounded loops (no infinite recursion, fixed upper limits)\",\n                      \"   - Short functions (<60 lines, single responsibility)\",\n                      \"   - Check all return values (Effect error channels handled)\",\n                      \"   - Explicit assertions (pre/postconditions verified)\",\n                      \"\",\n                      \"Version control (GitHub-compatible):\",\n                      \"- Use jj. GitHub requires named branches for PRs; never use anonymous changes.\",\n                      `- Create branch: \\`jj new main && jj bookmark create ${spec.id}-${task.id}\\`.`,\n                      \"- Work normally (jj auto-snapshots files).\",\n\n                      `- Describe: \\`jj describe -m \"...\"\\` (required before push).`,\n                      `- Push to GitHub: \\`jj git push --branch ${spec.id}-${task.id}\\`.`,\n                      \"  (This creates/updates the branch on origin for PR creation).\",\n                      \"- If push fails (conflict), rebase: `jj rebase -d main` then force-push.\",\n                      \"- If still failing, set status=failed with details.\",\n                      \"\",\n                      \"Output:\",\n                      \"Return a single JSON object that matches this schema:\",\n                      taskSchemaExample\n                    ]\n                      .filter((line) => line !== \"\")\n                      .join(\"\\n\")}\n                  </Task>\n                ))}\n              </Sequence>\n            ) : null}\n\n            <Parallel>\n              {reviewers.map((reviewer) => {\n                const modelOverride = reviewModels[reviewer.id.toLowerCase()] ?? reviewDefaultModel\n                const reviewerAgent = makeAgent(modelOverride)\n                return (\n                  <Task\n                    key={reviewer.id}\n                    id={`review-${reviewer.id}`}\n                    output=\"reviewReport\"\n                    outputSchema={reviewSchema}\n                    agent={reviewerAgent}\n                  >\n                    {[\n                      reviewerPrompt,\n                      reviewer.prompt,\n                      systemPrompt,\n                      \"\",\n                      `Reviewer: ${reviewer.title}`,\n                      `Set reviewer to \"${reviewer.id}\" in the JSON output.`,\n                      \"Review the implementation against the spec, todo, and task reports.\",\n                      \"Focus on correctness, tests, security, and strict spec compliance.\",\n                      \"Verify changes were pushed (jj git push --change @) if applicable.\",\n                      \"\",\n                      \"Output:\",\n                      \"Return a single JSON object that matches this schema:\",\n                      reviewSchemaExample\n                    ]\n                      .filter((line) => line !== \"\")\n                      .join(\"\\n\")}\n                  </Task>\n                )\n              })}\n            </Parallel>\n\n            <Task id=\"review-summary\" output=\"reviewSummary\" outputSchema={reviewSummarySchema}>\n              {combineReviews(ctx)}\n            </Task>\n          </Sequence>\n        </Ralph>\n\n        <Task\n          id=\"human-gate\"\n          output=\"humanGate\"\n          outputSchema={humanGateSchema}\n          skipIf={blocking || !latestSummary}\n        >\n          {{ v: 1, status: \"blocked\", reason: gateReason }}\n        </Task>\n      </Sequence>\n    </Workflow>\n  )\n})\n" },
  { path: "scripts/smithers-reviewer.tsx", contents: "#!/usr/bin/env smithers\n/** @jsxImportSource smithers-orchestrator */\nimport { execFileSync } from \"node:child_process\"\nimport { existsSync, mkdirSync, readFileSync, readdirSync } from \"node:fs\"\nimport { dirname, join, resolve } from \"node:path\"\nimport { z } from \"zod\"\nimport { createSmithers, Sequence, PiAgent, CodexAgent, ClaudeCodeAgent } from \"smithers-orchestrator\"\n\ntype Spec = {\n  id: string\n  title: string\n  goals: string[]\n  nonGoals: string[]\n  req: { api: string[]; behavior: string[]; obs: string[] }\n  accept: string[]\n  assume: string[]\n}\n\nconst env = process.env\nconst specPath = resolve(env.SMITHERS_SPEC_PATH ?? env.SPEC_PATH ?? \"specs/000-base.json\")\nconst reportDir = resolve(env.SMITHERS_REPORT_DIR ?? env.REPORT_DIR ?? \"reports\")\nconst reviewPromptPath = env.SMITHERS_REVIEW_PROMPT_PATH\nconst execCwd = env.SMITHERS_CWD ? resolve(env.SMITHERS_CWD) : process.cwd()\nconst agentKind = (env.SMITHERS_AGENT ?? env.RALPH_AGENT ?? \"pi\").toLowerCase()\nconst modelOverride = env.SMITHERS_MODEL ?? env.MODEL\nconst providerOverride = env.SMITHERS_PROVIDER ?? env.PI_PROVIDER\nconst sourceDbPath = env.SMITHERS_SOURCE_DB_PATH ? resolve(env.SMITHERS_SOURCE_DB_PATH) : undefined\n\nconst spec = JSON.parse(readFileSync(specPath, \"utf8\")) as Spec\n\nconst dbPath = resolve(env.SMITHERS_DB_PATH ?? join(\".smithers\", `${spec.id}.review.db`))\nif (!existsSync(dirname(dbPath))) {\n  mkdirSync(dirname(dbPath), { recursive: true })\n}\nif (!existsSync(reportDir)) {\n  mkdirSync(reportDir, { recursive: true })\n}\n\nconst reviewSchema = z.object({\n  v: z.number(),\n  status: z.enum([\"approved\", \"changes_requested\"]),\n  issues: z.array(z.string()),\n  next: z.array(z.string())\n})\n\nconst { Workflow, Task, smithers } = createSmithers({ reviewSummary: reviewSchema }, { dbPath })\n\nconst systemPrompt = [\n  `Spec ID: ${spec.id}`,\n  `Title: ${spec.title}`,\n  \"\",\n  \"Goals:\",\n  ...spec.goals.map((g) => `- ${g}`),\n  \"\",\n  \"Non-goals:\",\n  ...spec.nonGoals.map((g) => `- ${g}`),\n  \"\",\n  \"API requirements:\",\n  ...spec.req.api.map((r) => `- ${r}`),\n  \"\",\n  \"Behavior requirements:\",\n  ...spec.req.behavior.map((r) => `- ${r}`),\n  \"\",\n  \"Observability requirements:\",\n  ...spec.req.obs.map((r) => `- ${r}`),\n  \"\",\n  \"Acceptance criteria:\",\n  ...spec.accept.map((a) => `- ${a}`),\n  \"\",\n  \"Assumptions:\",\n  ...spec.assume.map((a) => `- ${a}`)\n].join(\"\\n\")\n\nconst loadPrompt = (path?: string): string => {\n  if (!path) return \"\"\n  try {\n    if (!existsSync(path)) return \"\"\n    return readFileSync(path, \"utf8\").trim()\n  } catch {\n    return \"\"\n  }\n}\n\nconst reviewerPrompt = loadPrompt(reviewPromptPath)\n\nconst reviewSchemaExample = JSON.stringify(\n  {\n    v: 1,\n    status: \"approved | changes_requested\",\n    issues: [\"...\"],\n    next: [\"...\"]\n  },\n  null,\n  2\n)\n\nconst makeAgent = (model?: string) => {\n  const resolvedModel = model ?? modelOverride\n  if (agentKind === \"claude\") {\n    return new ClaudeCodeAgent({\n      model: resolvedModel ?? \"opus\",\n      dangerouslySkipPermissions: true,\n      cwd: execCwd\n    })\n  }\n  if (agentKind === \"codex\") {\n    return new CodexAgent({\n      model: resolvedModel ?? \"gpt-5.2-codex\",\n      sandbox: \"danger-full-access\",\n      dangerouslyBypassApprovalsAndSandbox: true,\n      skipGitRepoCheck: true,\n      cd: execCwd,\n      cwd: execCwd\n    })\n  }\n  return new PiAgent({\n    model: resolvedModel ?? undefined,\n    provider: providerOverride ?? undefined,\n    mode: \"text\",\n    print: true,\n    cwd: execCwd\n  })\n}\n\nconst reviewAgent = makeAgent(modelOverride)\n\nconst readReportSummary = () => {\n  if (sourceDbPath && existsSync(sourceDbPath)) {\n    try {\n      const runId = env.SMITHERS_RUN_ID ?? \"\"\n      const script = `\nimport json, os, sqlite3\npath = \"${sourceDbPath}\"\nrun_id = \"${runId}\"\nif not os.path.exists(path):\n  print(\"No reports found.\")\n  raise SystemExit(0)\nconn = sqlite3.connect(path)\ntry:\n  if run_id:\n    cur = conn.execute(\"SELECT task_id, status, issues, next FROM task_report WHERE run_id = ? ORDER BY node_id\", (run_id,))\n  else:\n    cur = conn.execute(\"SELECT task_id, status, issues, next FROM task_report ORDER BY node_id\")\n  rows = cur.fetchall()\n  if not rows:\n    print(\"No reports found.\")\n  else:\n    for row in rows:\n      print(json.dumps({\"taskId\": row[0], \"status\": row[1], \"issues\": row[2], \"next\": row[3]}, indent=2))\nexcept Exception:\n  print(\"No reports found.\")\nfinally:\n  conn.close()\n`\n      const output = execFileSync(\"python3\", [\"-\"], { input: script, encoding: \"utf8\" }).trim()\n      return output || \"No reports found.\"\n    } catch {\n      return \"No reports found.\"\n    }\n  }\n\n  try {\n    const files = existsSync(reportDir) ? readdirSync(reportDir) : []\n    const reportFiles = files.filter((f) => f.endsWith(\".report.json\"))\n    const summaries = reportFiles.slice(0, 30).map((f) => {\n      const raw = readFileSync(join(reportDir, f), \"utf8\")\n      return `${f}:\\n${raw}`\n    })\n    return summaries.length > 0 ? summaries.join(\"\\n\\n\") : \"No reports found.\"\n  } catch {\n    return \"No reports found.\"\n  }\n}\n\nexport default smithers(() => {\n  const reportSummary = readReportSummary()\n\n  return (\n    <Workflow name=\"review-only\">\n      <Sequence>\n        <Task id=\"review\" output=\"reviewSummary\" outputSchema={reviewSchema} agent={reviewAgent}>\n          {[\n            reviewerPrompt,\n            systemPrompt,\n            \"\",\n            \"Review the implementation against the spec, todo, and task reports.\",\n            \"Focus on correctness, tests, security, and strict spec compliance.\",\n            \"Verify changes were pushed (jj git push --change @) if applicable.\",\n            \"\",\n            \"Reports:\",\n            reportSummary,\n            \"\",\n            \"Output:\",\n            \"Return a single JSON object that matches this schema:\",\n            reviewSchemaExample\n          ]\n            .filter((line) => line !== \"\")\n            .join(\"\\n\")}\n        </Task>\n      </Sequence>\n    </Workflow>\n  )\n})\n" },
  { path: "scripts/validate-specs.ts", contents: "import { readdir, readFile, stat } from \"node:fs/promises\"\nimport { join } from \"node:path\"\n\nconst isJson = (name: string) => name.endsWith(\".json\") && !name.endsWith(\".min.json\")\n\nconst isStringArray = (value: unknown): value is string[] =>\n  Array.isArray(value) && value.every((item) => typeof item === \"string\")\n\nconst onlyKeys = (obj: object, keys: string[]) =>\n  Object.keys(obj).every((key) => keys.includes(key))\n\nconst validateSpec = (file: string, obj: Record<string, unknown>, errors: string[]) => {\n  const keys = [\n    \"v\",\n    \"id\",\n    \"title\",\n    \"status\",\n    \"version\",\n    \"lastUpdated\",\n    \"supersedes\",\n    \"dependsOn\",\n    \"goals\",\n    \"nonGoals\",\n    \"req\",\n    \"cfg\",\n    \"accept\",\n    \"assume\"\n  ]\n\n  if (!onlyKeys(obj, keys)) {\n    errors.push(`${file}: unexpected top-level keys`)\n  }\n\n  for (const key of [\"v\", \"id\", \"title\", \"status\", \"version\", \"lastUpdated\", \"goals\", \"nonGoals\", \"req\", \"accept\", \"assume\"]) {\n    if (!(key in obj)) {\n      errors.push(`${file}: missing ${key}`)\n    }\n  }\n\n  if (obj.v !== 1) errors.push(`${file}: v must be 1`)\n  for (const key of [\"id\", \"title\", \"status\", \"version\", \"lastUpdated\"]) {\n    if (typeof obj[key] !== \"string\") errors.push(`${file}: ${key} must be string`)\n  }\n\n  for (const key of [\"supersedes\", \"dependsOn\", \"goals\", \"nonGoals\", \"accept\", \"assume\"]) {\n    const value = obj[key]\n    if (value !== undefined && !isStringArray(value)) {\n      errors.push(`${file}: ${key} must be string[]`)\n    }\n  }\n\n  const req = obj.req\n  if (typeof req !== \"object\" || req === null) {\n    errors.push(`${file}: req must be object`)\n  } else {\n    const reqKeys = [\"api\", \"behavior\", \"obs\"]\n    if (!onlyKeys(req, reqKeys)) errors.push(`${file}: req has unexpected keys`)\n    for (const key of reqKeys) {\n      const value = (req as Record<string, unknown>)[key]\n      if (value === undefined) errors.push(`${file}: req missing ${key}`)\n      else if (!isStringArray(value)) errors.push(`${file}: req.${key} must be string[]`)\n    }\n  }\n\n  const cfg = obj.cfg\n  if (cfg !== undefined) {\n    if (typeof cfg !== \"object\" || cfg === null) {\n      errors.push(`${file}: cfg must be object`)\n    } else {\n      const cfgKeys = [\"env\"]\n      if (!onlyKeys(cfg, cfgKeys)) errors.push(`${file}: cfg has unexpected keys`)\n      const env = (cfg as Record<string, unknown>).env\n      if (env !== undefined && !isStringArray(env)) errors.push(`${file}: cfg.env must be string[]`)\n    }\n  }\n}\n\nconst validateTodo = (file: string, obj: Record<string, unknown>, errors: string[]) => {\n  const keys = [\"v\", \"id\", \"tdd\", \"dod\", \"tasks\"]\n  if (!onlyKeys(obj, keys)) errors.push(`${file}: unexpected top-level keys`)\n  for (const key of keys) {\n    if (!(key in obj)) errors.push(`${file}: missing ${key}`)\n  }\n  if (obj.v !== 1) errors.push(`${file}: v must be 1`)\n  if (typeof obj.id !== \"string\") errors.push(`${file}: id must be string`)\n  if (typeof obj.tdd !== \"boolean\") errors.push(`${file}: tdd must be boolean`)\n  if (!isStringArray(obj.dod)) errors.push(`${file}: dod must be string[]`)\n\n  if (!Array.isArray(obj.tasks)) {\n    errors.push(`${file}: tasks must be array`)\n  } else {\n    for (const [index, task] of obj.tasks.entries()) {\n      if (typeof task !== \"object\" || task === null) {\n        errors.push(`${file}: tasks[${index}] must be object`)\n        continue\n      }\n      const taskKeys = [\"id\", \"do\", \"verify\"]\n      if (!onlyKeys(task, taskKeys)) errors.push(`${file}: tasks[${index}] unexpected keys`)\n      for (const key of taskKeys) {\n        const value = (task as Record<string, unknown>)[key]\n        if (value === undefined) errors.push(`${file}: tasks[${index}] missing ${key}`)\n        else if (typeof value !== \"string\") errors.push(`${file}: tasks[${index}].${key} must be string`)\n      }\n    }\n  }\n}\n\nconst validateDir = async (dir: string) => {\n  const entries = await readdir(dir)\n  const errors: string[] = []\n\n  for (const entry of entries) {\n    const fullPath = join(dir, entry)\n    const info = await stat(fullPath)\n    if (!info.isFile()) continue\n    if (!isJson(entry)) continue\n\n    const raw = await readFile(fullPath, \"utf8\")\n    const json = JSON.parse(raw) as Record<string, unknown>\n    if (entry.endsWith(\".todo.json\")) validateTodo(entry, json, errors)\n    else validateSpec(entry, json, errors)\n  }\n\n  if (errors.length > 0) {\n    console.error(`Schema validation errors:\\n${errors.join(\"\\n\")}`)\n    process.exit(1)\n  }\n\n  console.log(\"All spec/todo JSON files passed schema checks.\")\n}\n\nconst target = process.argv[2] ?? \"specs\"\n\nvalidateDir(target).catch((error) => {\n  console.error(error)\n  process.exit(1)\n})\n" },
  { path: "scripts/minify-specs.ts", contents: "import { readdir, readFile, writeFile, stat } from \"node:fs/promises\"\nimport { join } from \"node:path\"\n\nconst isJson = (name: string) => name.endsWith(\".json\") && !name.endsWith(\".min.json\")\n\nconst minifyFile = async (filePath: string) => {\n  const raw = await readFile(filePath, \"utf8\")\n  const json = JSON.parse(raw)\n  const minPath = filePath.replace(/\\.json$/, \".min.json\")\n  await writeFile(minPath, JSON.stringify(json), \"utf8\")\n}\n\nconst minifyDir = async (dir: string) => {\n  const entries = await readdir(dir)\n  for (const entry of entries) {\n    const fullPath = join(dir, entry)\n    const info = await stat(fullPath)\n    if (!info.isFile()) {\n      continue\n    }\n    if (isJson(entry)) {\n      await minifyFile(fullPath)\n    }\n  }\n}\n\nconst target = process.argv[2] ?? \"specs\"\n\nminifyDir(target)\n  .then(() => {\n    console.log(`Minified JSON in ${target}`)\n  })\n  .catch((error) => {\n    console.error(error)\n    process.exit(1)\n  })\n" },
  { path: "prompts/DEFAULT-IMPLEMENTER.md", contents: "# Default Implementer Prompt\n\nStudy /docs to become familiar with the codebase architecture.\n\nStudy the spec and todo JSON to learn the goal at hand.\n\nLook at recent commits to see what has been done.\n\nPick the most important task from the TODO list for implementation of the spec and implement that. Focus on completion of that task. If you encounter blocking errors, fix them, verify them, commit them, get the task done.\n\nBefore making changes search codebase (don't assume an item is not implemented) using parallel subagents. Think hard.\n\nWrite tests, verify your work builds, run the dev server (you can access the logs) and use chrome dev tools mcp to check the website at the very end, going through the user flow.\n\nImportant: When authoring documentation (ie. ts doc, tests or documentation) capture the why tests and the backing implementation is important.\n\nAfter implementing functionality or resolving problems, run the tests for that unit of code that was improved.\nWhen all tests and verifications pass commit your work. If functionality is missing then it's your job to add it as per the application specifications.\n\nCommit message rules:\n- Use Conventional Commits: type(scope): subject\n- Include spec id, todo id, and run id in the message body or trailer\n- When debugging/fixing root causes, include: cause → reasoning → fix, plus relevant error output\n- If `jj git push --bookmark <branch>` fails with \"Refusing to create new remote bookmark\", run:\n  `jj bookmark track <branch> --remote=origin` then retry push\n- Avoid literal `\\n` in commit messages. Use a proper multi-line body:\n  - Preferred: `jj describe -m \"$(cat <<'EOF'\\n<subject>\\n\\n<trailers>\\nEOF\\n)\"`\n  - Or: `printf '%s\\n\\n%s\\n' \"<subject>\" \"<trailers>\" | jj describe -m -`\n- Example:\n  feat(spec-020-fabrik-v0-2-0): implement dispatch auth\n  \n  todo: git-credentials-vm\n  spec: 020-fabrik-v0-2-0\n  run: 20260203T120945Z\n  cause: GH auth relied on host keychain; VM had no token\n  reasoning: VM needs env-based auth; ralph.env already contains GITHUB_TOKEN\n  fix: source ralph.env and export GH_TOKEN during dispatch\n  error: gh auth status -> \"token in default is invalid\"\n\nUpdate the TODO.md file noting what has been done, attach a screenshot of the UI confirming it's done for frontend changes.\n" },
  { path: "prompts/DEFAULT-REVIEWER.md", contents: "# Default Reviewer Prompt\n\nReview the implementation against the spec and todo. Focus on:\n\n- Correctness and completeness\n- Tests and verification steps\n- Security risks and edge cases\n- Strict spec compliance\n\nConfirm changes were pushed to the single spec branch/bookmark (no `push-*` branches).\nCheck commit messages follow Conventional Commits and include spec/todo/run plus root-cause notes when relevant.\nVerify task reports include rootCause/reasoning/fix/error/commit when applicable.\n\nReport issues clearly and suggest next steps.\n" },
  { path: "prompts/reviewers/SECURITY.md", contents: "# Security Reviewer\n\nReview for security vulnerabilities and best practices.\n\n## Checklist\n\n- [ ] No hardcoded secrets or credentials in code\n- [ ] Input validation at all entry points (prevent injection)\n- [ ] Proper error handling (no information leakage in error messages)\n- [ ] Authentication/authorization checks where applicable\n- [ ] Secure defaults (deny by default, least privilege)\n- [ ] No SQL injection vectors (parameterized queries only)\n- [ ] No XSS vulnerabilities (output encoding where needed)\n- [ ] Dependencies are up to date (no known CVEs)\n- [ ] Sensitive data encrypted at rest and in transit\n- [ ] Audit logging for sensitive operations\n\n## Effect-TS Specific\n\n- [ ] Effect error channels don't leak sensitive internals\n- [ ] Service requirements properly scoped (least privilege)\n- [ ] No direct Promise rejection exposure\n\nFlag any security issue as `changes_requested` with severity:\n- `CRITICAL`: Data breach, auth bypass, injection vulnerability\n- `HIGH`: Potential security risk with clear exploitation path\n- `MEDIUM`: Defense in depth improvement recommended\n" },
  { path: "prompts/reviewers/CODE-QUALITY.md", contents: "# Code Quality Reviewer\n\nReview for general code quality, readability, and maintainability fundamentals.\n\n## Checklist\n\n- [ ] Functions are focused and single-purpose (SRP)\n- [ ] Variable names are descriptive and intent-revealing\n- [ ] No magic numbers or strings (use named constants)\n- [ ] Consistent formatting and style\n- [ ] Comments explain WHY, not WHAT (code should be self-documenting)\n- [ ] No dead code or unused imports\n- [ ] Error handling is comprehensive, not just happy-path\n- [ ] No deeply nested conditionals (prefer early returns)\n- [ ] Async code properly handled (no floating Promises)\n\n## TypeScript Specific\n\n- [ ] Strict typing enabled (no `any`, minimal `unknown` with validation)\n- [ ] Type inference used appropriately (not over-typed)\n- [ ] Generics used correctly (not over-engineered)\n- [ ] Null/undefined handling explicit (Option/Maybe types preferred)\n\n## Effect-TS Specific\n\n- [ ] Effects are composed, not nested\n- [ ] Error channels are explicit and handled\n- [ ] Resource management uses Scope/acquireRelease\n- [ ] No Effect.runPromise in library code\n\nFlag quality issues as `changes_requested` or `approved` with suggestions.\n" },
  { path: "prompts/reviewers/SIMPLICITY.md", contents: "# Minimal Simplicity Reviewer\n\nReview against \"simple is better than complex\" principles. Code should be as simple as possible, but no simpler.\n\n## Tigerstyle Alignment\n\n1. **DENSITY**: Is the code concise without being cryptic?\n   - One idea per line\n   - No unnecessary abstraction layers\n   - Remove boilerplate and ceremony\n\n2. **LOCALITY**: Are related concepts close together?\n   - No jumps across files for understanding\n   - Cohesive functions and modules\n   - Minimize cognitive distance\n\n3. **EXPLICITNESS**: Are all side effects visible?\n   - No hidden control flow\n   - No magic conventions\n   - Dependencies explicitly declared\n\n## Anti-Patterns to Flag\n\n- [ ] Over-engineering: Abstract factories for simple cases\n- [ ] Premature optimization: Complex caching for unclear benefit\n- [ ] Deep inheritance hierarchies (prefer composition)\n- [ ] Unnecessary indirection (interface with single implementation)\n- [ ] \"Enterprise\" patterns applied where functions suffice\n\n## Approval Criteria\n\n- Could a junior developer understand this in 5 minutes?\n- Is there a shorter way to express this intent?\n- Are we solving the problem we have, not might have?\n\nFlag complexity without justification as `changes_requested`.\n" },
  { path: "prompts/reviewers/TEST-COVERAGE.md", contents: "# Test Coverage Reviewer\n\nReview for comprehensive testing strategy and test quality.\n\n## Layer 4 (L4) Requirements\n\n### Unit Tests\n- [ ] Happy path covered for all public functions\n- [ ] Edge cases identified and tested (empty inputs, boundaries)\n- [ ] Error paths tested (Effect failure branches)\n- [ ] No tests that just \"pass through\" without verification\n\n### Property-Based Tests (Critical)\n- [ ] Invariants have `@property` TSDoc comments with names\n- [ ] Property tests for:\n  - **Conservation**: Nothing created/destroyed (e.g., money, tokens)\n  - **Idempotency**: Same input → same output (deterministic)\n  - **Commutativity**: Order doesn't matter for independent ops\n  - **Associativity**: Grouping doesn't affect result\n\n### Integration Tests\n- [ ] End-to-end flows work with real (or test) services\n- [ ] Database constraints actually enforced (test failures)\n- [ ] External API boundaries handled correctly\n\n### Effect-TS Testing\n- [ ] `Effect.TestClock` used for time-dependent logic\n- [ ] `TestContext` provided for all service dependencies\n- [ ] Both success and failure branches in Effect pipelines tested\n\n## T1/T2 Specific\n\nFor T1 (Critical) and T2 (Important) code:\n- [ ] Every invariant named and tested\n- [ ] Database constraints verified (try to violate them, confirm rejection)\n- [ ] Failure scenarios enumerated and covered\n\n## Measurement\n\n- Line coverage ≥ 80% (T3/T4), ≥ 90% (T1/T2)\n- Branch coverage ≥ 70% (T3/T4), ≥ 85% (T1/T2)\n- Invariant coverage: 100% (every @property has a test)\n\nFlag missing test coverage as `changes_requested` for critical paths.\n" },
  { path: "prompts/reviewers/MAINTAINABILITY.md", contents: "# Maintainability Reviewer\n\nReview for long-term code health and team scalability.\n\n## Documentation\n\n- [ ] README or module docs explain the \"why\" and \"how\"\n- [ ] Complex business logic has context comments\n- [ ] API changes documented (breaking vs non-breaking)\n- [ ] Architecture Decision Records (ADRs) for major choices\n\n## Code Organization\n\n- [ ] Clear module boundaries (high cohesion, low coupling)\n- [ ] Public API surface is minimal and intentional\n- [ ] Internal modules marked/separated from public\n- [ ] No circular dependencies\n\n## Observability\n\n- [ ] Structured logging for important operations\n- [ ] Error contexts include actionable information\n- [ ] Metrics/TODOs documented for production (L5 preparation)\n\n## Onboarding\n\n- [ ] New developer could fix a bug in this code within 1 hour\n- [ ] No tribal knowledge required (all context in code/docs)\n- [ ] Examples provided for complex operations\n\n## Effect-TS Specific\n\n- [ ] Service interfaces are stable and well-documented\n- [ ] Error types are actionable (contain debugging context)\n- [ ] Resource lifecycles are clear and documented\n\n## Versioning\n\n- [ ] Breaking changes explicitly identified\n- [ ] Migration path provided for API changes\n\nFlag maintainability issues as `approved` with suggestions (not blocking unless severe).\n" },
  { path: "README.md", contents: "# Local Ralph/Wisp Development Environment\n\n**Humans write specs. Agents ship features.**\n\nRun a workforce of isolated coding agents locally. Write a specification, dispatch it to your Ralph fleet, get notified when it ships. Smithers is required.\n\n## The Vision\n\n```\n┌─────────────────────────────────────────────────────────────────────┐\n│                                                                     │\n│   Human writes spec ──► Ralphs implement ──► Ralphs review ──►     │\n│                                │                  │                 │\n│                                └──── iterate ─────┘                 │\n│                                         │                           │\n│                                         ▼                           │\n│                              \"Feature X shipped\" ──► Human          │\n│                                                                     │\n└─────────────────────────────────────────────────────────────────────┘\n```\n\nYou stay in the loop for:\n- Writing specifications\n- Answering questions when agents get stuck\n- Receiving \"shipped\" notifications\n\nAgents handle:\n- Implementation\n- Code review (agent-to-agent)\n- Iteration on feedback\n- PR creation\n\n## Architecture\n\n```\n┌──────────────────────────────────────────────────────────────────┐\n│  Host Machine                                                    │\n│  ├── LAOS (Grafana/Loki/Tempo/Prometheus/Sentry/PostHog) ◄──     │\n│  │   all agents report here                                     │\n│  ├── Message queue (filesystem) ◄── agents coordinate           │\n│  │                                                               │\n│  ├── ralph-1 (VM) ──── Smithers workflow ── feat/auth           │\n│  ├── ralph-2 (VM) ──── Smithers workflow ── feat/dashboard      │\n│  ├── ralph-3 (VM) ──── Smithers workflow ── fix/api-error       │\n│  │                                                               │\n│  └── ralph-review (VM) ── reviews reports, sends feedback       │\n└──────────────────────────────────────────────────────────────────┘\n```\n\nEach VM has the repo cloned and works on its own branch. For advanced parallel work, use [Jujutsu (jj)](https://github.com/martinvonz/jj) which handles multiple changes natively.\n\n## Quick Start\n\n### 1. Setup infrastructure\n\n```bash\n# Start LAOS (shared host observability stack)\n# Source of truth: https://github.com/dtechvision/laos\nmkdir -p ~/git\nif [[ -d ~/git/laos/.git ]]; then\n  (cd ~/git/laos && git pull)\nelse\n  git clone https://github.com/dtechvision/laos.git ~/git/laos\nfi\ncd ~/git/laos\ndocker compose up -d\n\n# Optional: create a shared env file so LAOS endpoints get copied into VMs\ncd /path/to/local-isolated-ralph\n./scripts/create-ralph-env.sh\n# Edit ~/.config/ralph/ralph.env and set:\n# macOS (Lima):  LAOS_HOST=host.lima.internal\n# Linux (libvirt): LAOS_HOST=192.168.122.1\n\n# Create VMs (4 implementers + 1 reviewer)\nfor i in 1 2 3 4; do ./scripts/create-ralph.sh ralph-$i 2 4 20; done\n./scripts/create-ralph.sh ralph-review 2 4 20\n\n# Setup base image in one VM, then snapshot for cloning\n./scripts/setup-base-vm.sh  # Run inside VM\n```\n\n### 2. Compound Engineering: Spec → Todo → Run\n\n**Principle**: 80% Planning, 20% Execution. Each cycle compounds quality.\n\n#### Step 1: Spec erstellen (40%)\n\n```bash\n# Interview-Guide ausgeben (self-contained, kein externes File nötig)\n./dist/fabrik spec interview | tee /tmp/spec-interview.txt\n\n# Mit Agent durchführen → Output: specs/feature.json\ncat /tmp/spec-interview.txt | claude-code\n\n# Validieren\n./dist/fabrik spec validate\n```\n\n#### Step 2: Todo generieren (40%)\n\n```bash\n# Todo-Guide ausgeben\n./dist/fabrik todo generate | tee /tmp/todo-guide.txt\n\n# Mit Agent durchführen → Output: specs/feature.todo.json\ncat /tmp/todo-guide.txt | claude-code\n\n# Validieren\n./dist/fabrik spec validate\n```\n\n#### Step 3: Workflow starten (20%)\n\n```bash\n# Run dispatch\n./dist/fabrik run \\\n  --spec specs/feature.json \\\n  --todo specs/feature.todo.json \\\n  --vm ralph-1 \\\n  --project ~/projects/my-app     # Optional: Ziel-Repo\n```\n\n**Implicit Assumption**: Ohne `--project` arbeitet der Agent in einem frischen Clone innerhalb der VM.\n\n### 3. Launch Smithers\n\n```bash\n# Run a Smithers workflow (spec/todo JSON; minified on dispatch)\n./dist/fabrik run --spec specs/010-weekly-summary.json --vm ralph-1\n\n# With local project directory synced to VM\n./dist/fabrik run --spec specs/010-weekly-summary.json --vm ralph-1 --project ~/projects/my-app\n\n# With iteration limit (stops after 20 Smithers iterations)\n./dist/fabrik run --spec specs/010-weekly-summary.json --vm ralph-1 --project ~/projects/my-app --iterations 20\n\n# Or start multiple Ralphs on different specs (fleet)\n./dist/fabrik fleet --specs-dir specs --vm-prefix ralph\n```\n\n### 4. Watch and wait\n\n```bash\n# Grafana for logs/traces\nopen http://localhost:3010\n\n# Or attach to a VM session directly\n# limactl shell <vm> or ssh ralph@<ip>\n\n# Watch for blocked tasks and get desktop notifications\nfabrik runs watch --vm ralph-1\n```\n\nWhen done, Smithers writes task outputs into its SQLite db (`.smithers/<spec>.db`) and exits when all tasks are done.\n\n### Desktop notifications\n\n`fabrik runs watch` will send notifications when blocked tasks appear.\n\nInstall a notifier:\n- macOS: `brew install terminal-notifier`\n- Linux: `sudo apt install libnotify-bin` (provides `notify-send`)\n\n## Workflows\n\n| Pattern | Use Case | Setup | Time |\n|---------|----------|-------|------|\n| **Compound Engineering** | 80/20 Planning/Execution | `fabrik spec interview` → `fabrik todo generate` → `fabrik run` | 40/40/20% |\n| **Single Ralph** | One feature at a time | 1 VM, feature branch | Sequential |\n| **Multi-Ralph Fleet** | Parallel features | N VMs, fleet dispatch | Parallel |\n| **Multi-Ralph per VM** | Resource constrained | 2-4 Ralphs in 1 VM | Density |\n\n**Compound Effect**: Each cycle makes the next faster (compound interest on quality).\n\nSee **[WORKFLOW.md](./WORKFLOW.md)** for detailed patterns.\n\n## Documentation\n\n| Document | Description | Self-Contained |\n|----------|-------------|----------------|\n| [QUICKSTART.md](./QUICKSTART.md) | End-to-end tutorial | ❌ (needs Repo) |\n| [WORKFLOW.md](./WORKFLOW.md) | Workflow patterns, 80/20 Rule | ❌ (needs Repo) |\n| [specs/INTERVIEW.md](./specs/INTERVIEW.md) | 10-Question Interview Guide | ✅ (via `fabrik spec interview`) |\n| [prompts/COMPOUND-ENGINEERING.md](./prompts/COMPOUND-ENGINEERING.md) | Todo Generation | ✅ (via `fabrik todo generate`) |\n| [prompts/reviewers/](./prompts/reviewers/) | 8 Reviewer Prompts | ⚠️ (if available) |\n| [OBSERVABILITY.md](./OBSERVABILITY.md) | Telemetry, LAOS Setup | ❌ (needs Repo) |\n| [SETUP-MACOS.md](./SETUP-MACOS.md) | macOS setup with Lima | ❌ (needs Repo) |\n| [SETUP-LINUX.md](./SETUP-LINUX.md) | Linux setup with libvirt | ❌ (needs Repo) |\n| [CI-CD.md](./CI-CD.md) | CI/CD with self-hosted runners | ❌ (needs Repo) |\n| [dtechvision/laos](https://github.com/dtechvision/laos) | LAOS Observability (external) | N/A |\n\n## Scripts\n\n| Script | Purpose |\n|--------|---------|\n| `create-ralph.sh` | Create a new Ralph VM |\n| `setup-base-vm.sh` | Install tools inside VM (run once, snapshot) |\n| `smithers-fleet.sh` | Dispatch multiple Smithers workflows |\n| `smithers-spec-runner.tsx` | Default Smithers workflow for spec/todo |\n| `smithers-reviewer.tsx` | Smithers reviewer workflow template |\n| `cleanup-workdirs.sh` | Cleanup old immutable workdirs |\n| `record-human-feedback.sh` | Record human review decision/notes |\n| `list-ralphs.sh` | Show all VMs and status |\n| `cleanup-ralphs.sh` | Delete VMs |\n\n## CLI (Fabrik)\n\nBuild and run the single binary CLI:\n\n```bash\nbun install\nbun run build\n./dist/fabrik flow\n```\n\n### Standalone binary (embedded assets)\n\nThe `fabrik` binary embeds:\n- default prompts + reviewer prompts\n- default Smithers workflows\n- helper scripts (dispatch/cleanup/fleet)\n- docs (README/WORKFLOW/QUICKSTART/specs README)\n\nIf `LOCAL_RALPH_HOME` (or `~/git/local-isolated-ralph`) is missing, `fabrik` writes embedded assets\nto `~/.cache/fabrik/embedded/<hash>/` and runs from there.\n\nCommon commands:\n\n```bash\n# === COMPOUND ENGINEERING: PLANNING (80%) ===\n\n# Spec Interview: 10-Fragen Guide (self-contained)\nfabrik spec interview | tee /tmp/spec-prompt.txt\ncat /tmp/spec-prompt.txt | claude-code  # Output: specs/feature.json\n\n# Todo Generation: Task-Decomposition Guide (self-contained)  \nfabrik todo generate | tee /tmp/todo-prompt.txt\ncat /tmp/todo-prompt.txt | claude-code   # Output: specs/feature.todo.json\n\n# Validate JSON Schema\nfabrik spec validate\nfabrik spec minify   # Optional: .min.json für Dispatch\n\n# === COMPOUND ENGINEERING: EXECUTION (20%) ===\n\n# Single Run\nfabrik run --spec specs/feature.json --todo specs/feature.todo.json --vm ralph-1\n\n# Mit Ziel-Repo außerhalb VM\nfabrik run ... --project ~/projects/my-app\n\n# Mit Custom Reviewern\nfabrik run ... --review-max 3 --review-models ./reviewer-models.json\n\n# Fleet (Multi-VM)\nfabrik fleet --specs-dir specs --vm-prefix ralph\n\n# === MONITORING & REVIEW ===\n\n# Desktop Notifications bei Blockierung\nfabrik runs watch --vm ralph-1\n\n# Run Details\nfabrik runs list --limit 10\nfabrik runs show --id 42  # Mit failure_reason wenn verfügbar\n\n# Human Gate (bindend, kein Timeout)\nfabrik feedback --vm ralph-1 --spec specs/feature.json \\\n  --decision approve --notes \"Implementation correct\"\n\n# === INFRASTRUKTUR ===\n\n# LAOS (Observability)\nfabrik laos up\nfabrik laos status\nfabrik laos logs --follow\nfabrik laos down\n\n# Credentials sync\nfabrik credentials sync --vm ralph-1\n\n# Dependency maintenance\nfabrik deps check\nfabrik deps update --bun\nfabrik deps update --smithers\nfabrik deps update --bun\nfabrik deps update --smithers\nfabrik deps update --bun --smithers\n```\n\nDependency policy:\n- Direct deps are pinned (no `latest`/range drift).\n- New direct deps require explicit approval.\n- CI enforces policy with `bun run deps:policy`.\n- Install the local pre-commit hook once: `bun run hooks:install`.\n\n`fabrik laos` clones/pulls `https://github.com/dtechvision/laos` with **jj** (or `git` if jj is missing)\ninto `~/.cache/fabrik/laos` and runs `docker compose`.\n\n### Use the CLI from another repo\n\nFrom any repo (e.g. `~/git/<your-repo>`):\n\n```bash\n# Build once (in local-ralph)\ncd ~/git/local-isolated-ralph\nbun install\nbun build src/fabrik/bin.ts --compile --outfile dist/fabrik\n\n# Use from another repo\ncd ~/git/<your-repo>\n~/git/local-isolated-ralph/dist/fabrik spec validate\n~/git/local-isolated-ralph/dist/fabrik spec minify\n~/git/local-isolated-ralph/dist/fabrik run --spec specs/001-foo.json --vm ralph-1\n```\n\n### Binary Releases (GitHub)\n\nThe repo ships prebuilt `fabrik` binaries for:\n- macOS ARM64 (`darwin-arm64`)\n- Linux x64 (`linux-x64`)\n- Linux ARM64 (`linux-arm64`)\n\nRelease process:\n\n```bash\ngit tag v0.1.0\ngit push origin v0.1.0\n```\n\nOr trigger the workflow manually with a tag (GitHub Actions UI).\n\nIf your local-ralph repo lives elsewhere, set:\n\n```bash\nexport LOCAL_RALPH_HOME=/path/to/local-isolated-ralph\n```\n\n### Smithers (Required Orchestration + JJ)\n\nSmithers is required. Fabrik dispatches minified spec/todo JSON for token efficiency and Smithers executes tasks with durable state. It always runs an agent reviewer and writes review outputs to the Smithers SQLite db (`review_report`, `review_summary`) along with a `human_gate` row for human approval. Version control is JJ (colocated Git backend).\n\nDefault models:\n- Claude: `opus`\n- Codex: `gpt-5.2-codex` (reasoning `medium`, sandbox `danger-full-access`)\n\nPROMPT control:\n- Pass `--prompt` to prepend a per-run `PROMPT.md` (implementation instructions).\n- Pass `--review-prompt` to prepend reviewer instructions.\nThese files are prepended before the spec/todo content in Smithers.\nDefaults live in `prompts/DEFAULT-IMPLEMENTER.md` and `prompts/DEFAULT-REVIEWER.md`.\nReview pipeline (default):\n- Security\n- Code Quality\n- Minimal Simplicity\n- Test Coverage\n- Maintainability\n\nReviewer prompts live in `prompts/reviewers/*.md` and are copied into each run.\n\nReviewer model config (optional):\nCreate `reviewer-models.json` to map reviewers to models:\n\n```json\n{\n  \"_default\": \"sonnet\",\n  \"security\": \"sonnet\",\n  \"code-quality\": \"sonnet\",\n  \"simplicity\": \"sonnet\",\n  \"test-coverage\": \"sonnet\",\n  \"maintainability\": \"sonnet\"\n}\n```\n\nBackpressure:\n- If any reviewer requests changes, Smithers generates follow-up review tasks in the workflow and records them in the SQLite db.\n- The review pipeline reruns after review tasks.\n- Only when all reviewers approve does the human gate row appear.\n\nRun context audit:\n- Each run writes `reports/run-context.json` with prompt contents + hashes.\n\n```bash\n# Install in VM if missing\n# bun add -g github:evmts/smithers#ea5ece3b156ebd32990ec9c528f9435c601a0403\n\n# Local workflow (uses scripts/smithers-spec-runner.tsx by default)\n./dist/fabrik run --spec specs/000-base.json --vm ralph-1\n\n# With custom prompts\n./dist/fabrik run --spec specs/000-base.json --vm ralph-1 \\\n  --prompt ./prompts/PROMPT-implementer.md \\\n  --review-prompt ./prompts/PROMPT-reviewer.md\n\n# Custom TODO and workflow\n./dist/fabrik run --spec specs/010-weekly-summary.json --todo specs/010-weekly-summary.todo.json \\\n  --workflow scripts/smithers-spec-runner.tsx --model sonnet --vm ralph-1\n\n# Review runs automatically after tasks; Smithers writes review outputs + human gate into the SQLite db.\n```\n\n### Smithers Workflow Diagram\n\n```\nspec.json + todo.json\n   (minified on dispatch)\n          │\n          ▼\n  Smithers workflow\n  (Ralph loop in React)\n          │\n          ├─ task 1 → task_report row\n          ├─ task 2 → task_report row\n          └─ task N → task_report row\n          │\n          ▼\n     DONE / BLOCKED / FAILED\n```\n\n### Reviewer Template (Standalone)\n\nUse the built-in Smithers reviewer workflow:\n\n```bash\n./dist/fabrik run --spec specs/feature.json --vm ralph-review --workflow scripts/smithers-reviewer.tsx\n```\n\n### JJ Primer (Required VCS)\n\nJJ uses a colocated Git backend. The repo still has `.git`, but you use `jj` commands.\n\n```\nClone:              jj git clone <url> <dir>\nInit in repo:       jj git init\nStart change:       jj new master\nStatus:             jj status\nDiff:               jj diff\nDescribe change:    jj describe\nPush change:        jj git push --change @\n```\n\nSet your JJ identity (recommended):\n```bash\njj config set --user user.name \"Your Name\"\njj config set --user user.email \"you@company.com\"\n```\n\nIf JJ identity is missing, fabrik falls back to git identity (if set) or uses defaults.\n\n### Changesets + JJ\n\nChangesets stays the same; JJ only replaces Git commands locally:\n\n```bash\n# Create a changeset for your PR\nbunx changeset\n\n# Work in a new JJ change\njj new master\n\n# Review + commit\njj status\njj diff\njj describe\n\n# Push the change\njj git push --change @\n```\n\n### fabrik run Options\n\n```bash\n./dist/fabrik run --spec <path> --vm <vm-name> [--todo <path>] \\\n  [--project <dir>] [--repo <url>] [--ref <branch>] [--include-git] \\\n  [--workflow <path>] [--report-dir <path>] [--model <name>] \\\n  [--prompt <path>] [--review-prompt <path>] [--review-models <path>] [--review-max <n>] \\\n  [--iterations <n>] [--follow]\n\n# Example with .git included (enables push from synced project)\nRALPH_AGENT=pi ./dist/fabrik run --include-git --spec specs/000-base.json --vm ralph-1 --project ~/projects/app --iterations 20\n```\n\n- `--include-git` - Include `.git` in sync (otherwise agent must clone from repo URL)\n- `--spec` - Spec JSON (minified on dispatch for Smithers mode)\n- `--todo` - TODO JSON (minified on dispatch for Smithers mode)\n- `--workflow` - Smithers workflow script (default: `scripts/smithers-spec-runner.tsx`)\n- `--report-dir` - Report output directory inside VM (default: workdir/reports)\n- `--model` - Model name for Smithers agent\n- `--prompt` - PROMPT.md prepended to every task prompt\n- `--review-prompt` - Reviewer PROMPT.md prepended to review prompt\n- `--review-max` - Max review reruns before human gate (default: 2)\n- `--review-models` - JSON map of reviewer_id -> model\n- `RALPH_AGENT` - Agent to use: `pi` (default), `claude`, `codex`\n- `MAX_ITERATIONS` - Max loops (default: 100, 0 = unlimited)\n\nEach dispatch creates a timestamped work directory (`/home/ralph/work/<vm>/<project>-<timestamp>/`), enabling parallel dispatches to the same VM.\n\nFailure reporting:\n- `fabrik runs show --id <run-id>` prints `failure_reason` when a run fails (derived from `reports/smithers.log`).\n- Stale or missing heartbeats are marked as `failure_reason: stale_process`.\n\n## Resource Planning\n\n| Host RAM | Recommended Setup |\n|----------|-------------------|\n| 16GB | 4 light VMs (2 CPU, 4GB each) |\n| 32GB | 8 light VMs or 4 medium VMs |\n| 64GB+ | 8+ medium VMs, or density mode |\n\n**Density mode:** Run 2-4 Ralphs per VM when working on separate directories.\n\n## Credentials Setup\n\nAgents need `GITHUB_TOKEN` to push code and create PRs.\n\n1. Create token: https://github.com/settings/tokens/new (scopes: `repo`, `workflow`)\n2. Add to `~/.config/ralph/ralph.env`:\n   ```bash\n   export GITHUB_TOKEN=\"ghp_your_token_here\"\n   ```\n3. Run `./scripts/create-ralph-env.sh` to create the env file, or `./scripts/sync-credentials.sh <vm>` to update existing VMs\n\nThe token is used by both `git push/pull` (credential helper) and `gh` CLI (auto-detects env var).\n\nAgent auth files are synced to VMs when you run `fabrik credentials sync` (or the bash equivalent).\n\nRequired by default (pi):\n- `~/.pi/agent/auth.json` (created by `pi` then `/login`)\n\nOptional (only if using `RALPH_AGENT=codex`):\n- `~/.codex/auth.json` (created by `codex login`)\n\nOptional (only if using `RALPH_AGENT=claude`):\n- `~/.claude` or `~/.claude.json` (created by `claude login` / `claude setup-token`)\n\n## Prerequisites\n\n```bash\n# Docker (for LAOS)\ndocker --version\n\n# SSH key (for VM access)\nls ~/.ssh/id_rsa.pub || ssh-keygen -t rsa -b 4096\n\n# macOS: Colima 0.6+\nbrew install colima docker\n\n# Linux: libvirt + KVM\nsudo apt install qemu-kvm libvirt-daemon-system virtinst\n```\n\n## The Goal\n\n```\nBefore:  Human writes code, human reviews code, human ships\nAfter:   Human writes spec ──────────────────► Human gets \"shipped\" notification\n                           (agents do the rest)\n```\n\n## Disk Usage\n\nDisk usage to watch:\n  - ~/.lima/ - VM disks (20GB+ per VM)\n  - ~/.cache/ralph/ - Downloaded images (~6GB per\n  architecture)\n  - ~/vms/ralph/ - libvirt VM disks on Linux\n\nFor the cloud-hosted version of this, see [Sprites](https://sprites.dev) + [Wisp](https://github.com/thruflo/wisp).\n### Immutable Runs + Local DB\n\nEach Smithers run gets a new workdir. Runs are tracked in a local SQLite DB:\n\n```\n~/.cache/ralph/ralph.db\n```\n\nCleanup old runs:\n\n```bash\n./scripts/cleanup-workdirs.sh ralph-1 --keep 5\n```\n\nRecord human feedback:\n\n```bash\n./scripts/record-human-feedback.sh --vm ralph-1 --spec specs/010-weekly-summary.json \\\n  --decision approve --notes \"Looks good.\"\n```\nSpec is explicit:\n- You choose the spec with `--spec`, not inside the prompt.\n\nContext stack now:\n\n```\n[\n  PROMPT.md (global instructions, if provided),\n  spec.json-derived system prompt,\n  task.do / task.verify,\n  JJ instructions,\n  report schema\n]\n```\n\nReviewer stack:\n\n```\n[\n  REVIEW_PROMPT.md (if provided),\n  reviewer-specific prompt (from prompts/reviewers/*.md),\n  spec.json-derived system prompt,\n  Smithers db task_report rows,\n  review schema\n]\n```\n" },
  { path: "WORKFLOW.md", contents: "# Workflow Guide: Compound Engineering with Fabrik\n\n**Scope**: Complete workflow from Spec creation to Human Gate.\n\n**Implicit Assumption**: Reader has completed QUICKSTART.md and understands the 80/20 rule (80% Planning, 20% Execution).\n\n---\n\n## 1. Compound Engineering: The 4 Principles\n\n### 1.1 Plan thoroughly before writing code\n- Spec is the contract. Changes cost 10x.\n- No implementation without completed interview.\n\n### 1.2 Review to catch issues and capture learnings\n- 8 Reviewers (automatic, parallel).\n- Every finding becomes a reusable pattern.\n\n### 1.3 Codify knowledge so it's reusable\n- `@property` TSDoc names invariants explicitly.\n- Branded Types prevent primitive obsession.\n- Todo templates documented in `prompts/reviewers/`.\n\n### 1.4 Keep quality high so future changes are easy\n- 6 Guarantee Layers (L1-L6).\n- Higher quality = faster next cycle.\n\n---\n\n## 2. The Workflow (Step-by-Step)\n\n### Phase 1: Spec Creation (40% of time)\n\n```bash\n# Step 1: Output interview guide\n./dist/fabrik spec interview | tee /tmp/spec-interview.txt\n\n# Step 2: Run with agent\n# Input: Conversation with agent about the 10 questions\n# Output: specs/{id}.json\ncat /tmp/spec-interview.txt | claude-code\n\n# Step 3: Validate\n./dist/fabrik spec validate\n```\n\n**The 10 Questions** (implicit in `fabrik spec interview`):\n1. IDENTITY: Kebab-case ID\n2. TITLE: One sentence, active voice, NO implementation\n3. STATUS: draft | ready | in-progress | review | done | superseded\n4. GOALS: 3-7 outcomes, MUST accomplish, NO implementation details\n5. NON-GOALS: Explicitly out of scope (prevents creep)\n6. API: Interfaces, signatures, branded types, error channels\n7. BEHAVIOR: Business rules, state transitions, edge cases\n8. OBSERVABILITY: Metrics, logs, alerts, health checks\n9. ACCEPTANCE: Testable criteria, performance thresholds\n10. ASSUMPTIONS: What could change (deps, platform, volume)\n\n**Critical**: Spec must have `status: \"ready\"` before next step.\n\n---\n\n### Phase 2: Todo Generation (40% of time)\n\n```bash\n# Step 1: Output todo guide\n./dist/fabrik todo generate | tee /tmp/todo-guide.txt\n\n# Step 2: Run with agent\n# Input: specs/{id}.json\n# Output: specs/{id}.todo.json\ncat /tmp/todo-guide.txt | claude-code\n\n# Step 3: Validate\n./dist/fabrik spec validate\n```\n\n**Criticality Tier** (determines DoD):\n\n| Tier | Examples | Layers |\n|------|----------|--------|\n| T1 | Money, Auth, Signing, irreversible State | ALL 6 (L1-L5 + Simulation) |\n| T2 | User data, Business logic, State machines | L1-L5 |\n| T3 | Features, UI state, Caching | L1-L4 |\n| T4 | Analytics, Logging, Metrics | L1, L4 |\n\n**T1 DoD** (all must be checked):\n- [ ] L1: Branded types\n- [ ] L2: Effect.assert for pre/postconditions\n- [ ] L3: DB UNIQUE/CHECK constraints\n- [ ] L4: @property TSDoc on every invariant test\n- [ ] L4: Property-based tests (conservation, idempotency)\n- [ ] L4: 90%+ line coverage, 85%+ branch coverage\n- [ ] L5: TODOs for production alerts\n- [ ] L6: Seed-based simulation plan\n- [ ] Review: All 8 reviewers approved\n- [ ] VCS: Pushed to GitHub, CI passed\n- [ ] Human: Gate cleared\n\n---\n\n### Phase 3: Execution (20% of time)\n\n```bash\n# Single-VM Workflow\n./dist/fabrik run \\\n  --spec specs/feature.json \\\n  --todo specs/feature.todo.json \\\n  --vm ralph-1 \\\n  --project /path/to/target/repo        # Optional: target repo outside VM\n```\n\n**Internal Flow**:\n\n```\nspec.json + todo.json (minified)\n           │\n           ▼\n    smithers-spec-runner.tsx\n           │\n           ├─ Sequential Tasks (with skipIf on error)\n           ├─ JJ: jj new main && jj bookmark create feature-1\n           ├─ Work → jj describe → jj git push --branch feature-1\n           │\n           ▼\n    Review Loop (Ralph until maxIterations)\n           ├─ 8 Reviewers parallel\n           ├─ On \"changes_requested\": Generate review tasks\n           └─ Resubmit until \"approved\" or max reached\n           │\n           ▼\n    Human Gate (blocked)\n           └─ Waits for: fabrik feedback --decision approve\n```\n\n---\n\n## 3. VCS Strategies (JJ)\n\n### 3.1 Single-Ralph: Feature Branch\n\n```bash\n# In VM (automatic by agent)\njj new main\njj bookmark create feature-1\n# ... work ...\njj describe -m \"feat(feature-1): implement X\"\njj git push --branch feature-1\n```\n\n**Implicit Assumption**: Agent works in `/home/ralph/work/...` directory, not on host.\n\n### 3.2 Multi-Ralph: Separate VMs\n\n```bash\n# Host: Start multiple runs\n./dist/fabrik run --spec specs/auth.json --vm ralph-1 &\n./dist/fabrik run --spec specs/dashboard.json --vm ralph-2 &\n./dist/fabrik run --spec specs/api-fix.json --vm ralph-3 &\n\n# Monitor\n./dist/fabrik runs watch --vm ralph-1 &\n./dist/fabrik runs watch --vm ralph-2 &\n./dist/fabrik runs watch --vm ralph-3 &\n```\n\n**Implicit Assumption**: Each VM has own workdir. No collisions possible.\n\n### 3.3 Multi-Ralph: Fleet Mode\n\n```bash\n./dist/fabrik fleet \\\n  --specs-dir specs \\\n  --vm-prefix ralph \\\n  --project /path/to/repo\n```\n\n**Implicit Assumption**: Fleet matches specs/*.json to available VMs (ralph-1, ralph-2, ...).\n\n---\n\n## 4. Review Pipeline (8 Reviewers)\n\n**Parallel Execution**:\n\n```\nParallel:\n  ├─ security\n  ├─ code-quality\n  ├─ simplicity\n  ├─ test-coverage\n  ├─ maintainability\n  ├─ tigerstyle\n  ├─ nasa-10-rules\n  └─ correctness-guarantees\n```\n\n**Reviewer Prompts**: `prompts/reviewers/{id}.md`\n\n**Custom Models** (optional):\n```json\n// reviewer-models.json\n{\n  \"_default\": \"sonnet\",\n  \"security\": \"opus\",\n  \"correctness-guarantees\": \"opus\"\n}\n```\n\n```bash\n./dist/fabrik run ... --review-models ./reviewer-models.json --review-max 3\n```\n\n---\n\n## 5. Human Gate\n\n**State**: After review loop, `human_gate` row written:\n\n```json\n{\n  \"v\": 1,\n  \"status\": \"blocked\",\n  \"reason\": \"Human review required before next spec run.\"\n}\n```\n\n**Actions**:\n\n```bash\n# Approve\n./dist/fabrik feedback \\\n  --vm ralph-1 \\\n  --spec specs/feature.json \\\n  --decision approve \\\n  --notes \"Implementation correct. Tests pass.\"\n\n# Reject (with reason for re-run)\n./dist/fabrik feedback \\\n  --vm ralph-1 \\\n  --spec specs/feature.json \\\n  --decision reject \\\n  --notes \"Security issue in auth flow. Fix and re-run.\"\n```\n\n**Implicit Assumption**: No automatic transition from \"blocked\". Human decision is binding.\n\n---\n\n## 6. Monitoring & Debugging\n\n### 6.1 Live Monitoring\n\n```bash\n# Terminal 1: Desktop notifications\n./dist/fabrik runs watch --vm ralph-1\n\n# Terminal 2: Stream logs\n./dist/fabrik laos logs --follow\n\n# Browser: Grafana\nopen http://localhost:3010/explore\n```\n\n### 6.2 Post-Mortem\n\n```bash\n# Run details\n./dist/fabrik runs show --id <run-id>\n\n# Output includes:\n# - failure_reason (if failed)\n# - blocked_task (if blocked)\n# - reports/run-context.json (prompt hashes)\n# - .smithers/*.db (SQLite with all reports)\n\n# Inspect SQLite\nsqlite3 .smithers/feature.db \"SELECT * FROM taskReport;\"\nsqlite3 .smithers/feature.db \"SELECT * FROM reviewReport;\"\nsqlite3 .smithers/feature.db \"SELECT * FROM humanGate;\"\n```\n\n---\n\n## 7. Compound Effect: The Flywheel\n\n**Month 1**: Slower than \"just coding\" (planning overhead)\n**Month 3**: Same speed, fewer bugs\n**Month 6**: Faster than traditional (patterns established)\n**Month 12**: 2-3x Velocity (compound interest on quality)\n\n**Mechanism**:\n1. Spec → Reusable requirement patterns\n2. Todo → Reusable task templates\n3. Reviewers → Reusable checklists\n4. L1-L6 → Each change safer than previous\n\n---\n\n## 8. Command Reference\n\n| Command | Purpose | Output |\n|---------|---------|--------|\n| `fabrik spec interview` | 10-question guide | Terminal (pipe to agent) |\n| `fabrik todo generate` | Todo guide | Terminal (pipe to agent) |\n| `fabrik spec validate` | JSON Schema check | Exit code 0/1 |\n| `fabrik spec minify` | Generate .min.json | Filesystem |\n| `fabrik run ...` | Workflow dispatch | SQLite + Reports |\n| `fabrik runs list` | Overview all runs | Table |\n| `fabrik runs show --id X` | Single run detail | JSON |\n| `fabrik runs watch` | Desktop notifications | Desktop popup |\n| `fabrik feedback ...` | Human Gate decision | SQLite update |\n| `fabrik fleet ...` | Multi-VM dispatch | SQLite + Reports |\n\n---\n\n## 9. Implicit Assumptions (Critical)\n\n1. **VCS**: JJ installed and configured (`jj --version`)\n2. **Auth**: `~/.pi/agent/auth.json` exists (or codex/claude equivalent)\n3. **Token**: `GITHUB_TOKEN` set and valid (scope: `repo`, `workflow`)\n4. **LAOS**: Running on localhost:3010 (for logs/metrics)\n5. **VMs**: Exist and reachable (`fabrik laos status` shows healthy)\n6. **Network**: VMs can reach GitHub (firewall/egress allowed)\n7. **Disk**: VMs have >10GB free for repos + dependencies\n8. **Order**: Spec → Todo → Run (binding, not skippable)\n9. **Human Gate**: Requires explicit feedback (no timeout)\n10. **Review**: 8 reviewers run parallel (network/bandwidth required)\n" },
  { path: "OBSERVABILITY.md", contents: "# Observability & Analytics for Coding Agents\n\nRalph uses **LAOS** (Local Analytics and Observability Stack) as the shared telemetry backend. This guide covers setup, querying, and troubleshooting.\n\n**LAOS Repository:** https://github.com/dtechvision/laos\n\n## Quick Start\n\n### 1. Start LAOS on the Host\n\n```bash\nmkdir -p ~/git\nif [[ -d ~/git/laos/.git ]]; then\n  (cd ~/git/laos && git pull)\nelse\n  git clone https://github.com/dtechvision/laos.git ~/git/laos\nfi\ncd ~/git/laos && ./scripts/laos-up.sh\n```\n\n### 2. Configure Ralph Environment\n\n```bash\ncd /path/to/local-isolated-ralph\n./scripts/create-ralph-env.sh\n```\n\nEdit `~/.config/ralph/ralph.env`:\n\n```bash\n# macOS (Lima): export LAOS_HOST=\"host.lima.internal\"\n# Linux (libvirt): export LAOS_HOST=\"192.168.122.1\"\nexport LAOS_HOST=\"<your-host>\"\n\n# Telemetry endpoints\nexport OTEL_EXPORTER_OTLP_ENDPOINT=\"http://${LAOS_HOST}:4317\"\nexport LOKI_URL=\"http://${LAOS_HOST}:3100\"\nexport SENTRY_DSN=\"http://<key>@${LAOS_HOST}:9000/1\"\nexport POSTHOG_HOST=\"http://${LAOS_HOST}:8001\"\nexport POSTHOG_API_KEY=\"phc_xxx\"\nexport PYROSCOPE_SERVER_ADDRESS=\"http://${LAOS_HOST}:4040\"\n```\n\n> **Platform Selection:** Set `LAOS_PLATFORM=linux/arm64` for Apple Silicon or ARM64 Linux. Default is `linux/amd64`.\n\n### 3. Sync to VMs\n\n```bash\n./scripts/sync-credentials.sh ralph-1\n# or: fabrik credentials sync --vm ralph-1\n```\n\n### 4. Access Dashboards\n\n| Service | URL | Credentials |\n|---------|-----|-------------|\n| Grafana | http://localhost:3010 | admin/admin |\n| Sentry | http://localhost:9000 | Create on first run |\n| PostHog | http://localhost:8001 | Setup wizard |\n| Pyroscope | http://localhost:4040 | None |\n| Prometheus | http://localhost:9090 | None |\n\n## Query Reference\n\n### Health Checks\n\n```bash\ncurl http://$LAOS_HOST:3100/ready  # Loki\ncurl http://$LAOS_HOST:3200/ready  # Tempo\ncurl http://$LAOS_HOST:9090/-/ready  # Prometheus\ncurl http://$LAOS_HOST:4040/ready  # Pyroscope\ncurl -I http://localhost:8001  # PostHog (expect 302/200)\n```\n\n### Query Patterns by Tool\n\n| Tool | URL/Endpoint | Example Query | Filters/Labels |\n|------|-------------|---------------|----------------|\n| **Loki** | `:3100` | `{service_name=\"smithers\"} \\|= \"ERROR\"` | `vm`, `trace_id`, `level` |\n| **Tempo** | `:4318` | Search by trace ID or `vm=ralph-1` | `service.name`, `task` |\n| **Prometheus** | `:9090` | `rate(http_requests_total[5m])` | `job`, `status`, `vm` |\n| **Pyroscope** | `:4040` | Flame graph: `process_cpu` | `spec_id`, `vm`, `agent_type` |\n| **Sentry** | `:9000` | Issues → Stack trace + breadcrumbs | `trace_id` → links to Tempo |\n| **PostHog** | `:8001` | Events → Real-time stream | `distinct_id`, `source` |\n\n### Detailed Query Examples\n\n**Loki (Logs):**\n```logql\n# All Smithers logs\n{service_name=\"smithers\"}\n\n# Errors only\n{service_name=\"smithers\"} |= \"ERROR\"\n\n# Specific VM\n{service_name=\"smithers\", vm=\"ralph-1\"}\n\n# Parse JSON\n{service_name=\"smithers\"} | json | line_format \"{{.level}}: {{.message}}\"\n```\n\n**Prometheus (Metrics):**\n```promql\n# Service health\nup{job=\"agent-metrics\"}\n\n# Request rate\nrate(http_requests_total{job=\"smithers\"}[5m])\n\n# Error rate\nrate(http_requests_total{status=~\"5..\"}[5m])\n\n# P95 latency\nhistogram_quantile(0.95, rate(task_duration_seconds_bucket[5m]))\n```\n\n**Pyroscope (Profiles):**\n1. **View:** Select app → profile type (`process_cpu`, `memory`, `wall`)\n2. **Compare:** Select two time ranges → \"Compare\" → diff flame graph\n3. **Correlate:** In Tempo trace, click span → \"View Profile\"\n\n**Sentry (Headless verification):**\n```bash\nEVENT_ID=$(uuidgen | tr -d '-' | tr 'A-Z' 'a-z')\nDSN=\"http://YOUR_KEY@localhost:9000/2\"\nprintf '{\"event_id\":\"%s\"}\\n{\"type\":\"event\"}\\n{\"message\":\"test\",\"level\":\"error\"}\\n' \\\n  \"$EVENT_ID\" > /tmp/envelope.txt\ncurl -X POST \"http://localhost:9000/api/2/envelope/\" \\\n  -H \"Content-Type: application/x-sentry-envelope\" \\\n  --data-binary @/tmp/envelope.txt\n```\n\n## Smithers Integration\n\n### Effect-TS Observability Layer\n\n```typescript\nimport * as Otlp from \"@effect/opentelemetry/Otlp\"\nimport { NodeHttpClient } from \"@effect/platform-node\"\nimport { Config, Effect, Layer } from \"effect\"\n\nexport const OtlpLive = Layer.unwrapEffect(\n  Effect.gen(function* () {\n    const otlpEndpoint = yield* Config.string(\"OTLP_ENDPOINT\").pipe(\n      Config.orElse(() => Config.succeed(\"http://localhost:4318\")),\n    )\n    const serviceName = yield* Config.string(\"SERVICE_NAME\").pipe(\n      Config.orElse(() => Config.succeed(\"ralph-agent\")),\n    )\n    return Otlp.layer({\n      baseUrl: otlpEndpoint,\n      resource: { serviceName, attributes: { \"deployment.environment\": \"development\" } },\n    }).pipe(Layer.provide(NodeHttpClient.layerUndici))\n  }),\n)\n```\n\n### Task Instrumentation\n\n```typescript\nconst instrumentedTask = Effect.gen(function* () {\n  yield* Effect.logInfo(\"Starting task\")\n  const result = yield* processTask()\n  yield* Metric.counter(\"tasks_completed\").pipe(Metric.increment)\n  return result\n}).pipe(Effect.withSpan(\"task-execution\", { attributes: { task_id: \"001\", vm: \"ralph-1\" } }))\n```\n\n### Profiling with Labels\n\n```typescript\nexport const handleSpecRun = (spec: string) =>\n  Effect.gen(function* () {\n    const profiling = yield* Profiling\n    return yield* profiling.withLabels(\n      { spec_id: spec, vm: process.env.VM_NAME || \"unknown\" },\n      Effect.promise(() => runSmithersWorkflow(spec)),\n    )\n  })\n```\n\n## Troubleshooting\n\n### No Telemetry Appearing\n\n```bash\n# 1. Verify LAOS is running\ncd ~/git/laos && docker compose ps\n\n# 2. Check service health\ncurl http://$LAOS_HOST:3100/ready  # Loki, etc.\n\n# 3. Check LAOS_HOST (macOS: host.lima.internal, Linux: 192.168.122.1)\n\n# 4. Sync credentials\n./scripts/sync-credentials.sh ralph-1\n\n# 5. Test from inside VM\nlimactl shell ralph-1\ncurl http://$LAOS_HOST:3100/ready\n```\n\n### Root Cause Analysis Flow\n\n```\nGrafana Dashboard → \"Error rate spike\"\n       ↓\nSentry → \"NullReferenceException in auth.ts:42\"\n       ↓\nTempo Trace → DB call span = 5s\n       ↓\nLoki Logs → \"Connection timeout to postgres\"\n       ↓\nPyroscope → CPU saturated on connection pool\n```\n\nAll signals linked by `trace_id` and `span_id`.\n\n### Common Issues\n\n| Issue | Solution |\n|-------|----------|\n| macOS ARM64 platform errors | `softwareupdate --install-rosetta --agree-to-license` |\n| Port conflicts | `lsof -i :3010 :9000 :8001` |\n| PostHog slow startup | Normal, wait for `curl -I localhost:8001` to return 302 |\n| Reset everything | `docker compose down -v && docker compose up -d` |\n\n## Further Reading\n\n- **LAOS Repository:** https://github.com/dtechvision/laos\n- **LAOS Setup Guide:** `~/git/laos/SETUP-LAOS.md`\n- **Effect + Telemetry:** `~/git/laos/examples/observability-layer.ts`\n- **Profiling:** `~/git/laos/PYROSCOPE.md`\n" },
  { path: "QUICKSTART.md", contents: "# Compound Engineering: Quickstart\n\n**Prerequisite**: Complete platform-specific setup first (SETUP-MACOS.md or SETUP-LINUX.md).\n\n**Implicit Assumption**: All commands run from `local-isolated-ralph` directory unless specified otherwise.\n\n---\n\n## 1. Pre-flight Check\n\n```bash\n# Agent authentication\npi --version        # Must be installed\npi /login           # Run once, creates ~/.pi/agent/auth.json\n\n# GitHub Token (for push/PR)\nexport GITHUB_TOKEN=\"ghp_...\"   # Or in ~/.config/ralph/ralph.env\n\n# Optional: Alternative agents\n# codex login        # Only if RALPH_AGENT=codex\n# claude auth login  # Only if RALPH_AGENT=claude\n```\n\n**Implicit Assumption**: Without `GITHUB_TOKEN`, the agent cannot push branches. Workflow will block.\n\n---\n\n## 2. Start LAOS (Observability)\n\n```bash\nfabrik laos up\nfabrik laos status   # Must show \"healthy\"\n```\n\n**Implicit Assumption**: LAOS runs on localhost:3010 (Grafana). Agent sends logs there.\n\n---\n\n## 3. Create VM\n\n```bash\nfabrik laos up                              # 1. Observability\n./scripts/create-ralph.sh ralph-1 4 8 30    # 2. VM (4 CPU, 8GB RAM, 30GB disk)\n./scripts/setup-base-vm.sh                  # 3. Setup (run INSIDE the VM)\n```\n\n**Implicit Assumption**: `setup-base-vm.sh` must run INSIDE the VM, not on the host.\n\n**macOS**: `colima ssh -p ralph-1`\n**Linux**: `ssh ralph@$(virsh domifaddr ralph-1 | grep ipv4 | awk '{print $4}' | cut -d/ -f1)`\n\n---\n\n## 4. Compound Engineering Workflow\n\n**Principle**: 80% Planning, 20% Execution\n\n### Phase 1: Create Spec (40%)\n\n```bash\n# Output interview guide (self-contained, no external files needed)\n./dist/fabrik spec interview | tee /tmp/interview-prompt.txt\n\n# Run with agent, Output: specs/feature.json\ncat /tmp/interview-prompt.txt | claude-code\n\n# Validate\n./dist/fabrik spec validate\n```\n\n**Critical**: Spec must exist before Todo. Order is binding.\n\n### Phase 2: Generate Todo (40%)\n\n```bash\n# Output todo guide\n./dist/fabrik todo generate | tee /tmp/todo-prompt.txt\n\n# Run with agent, Input: specs/feature.json, Output: specs/feature.todo.json\ncat /tmp/todo-prompt.txt | claude-code\n\n# Validate\n./dist/fabrik spec validate\n```\n\n**Implicit Assumption**: Todo without Spec is invalid. Link via identical `id`.\n\n### Phase 3: Dispatch Workflow (20%)\n\n```bash\n# Single run\n./dist/fabrik run \\\n  --spec specs/feature.json \\\n  --todo specs/feature.todo.json \\\n  --vm ralph-1 \\\n  --project /path/to/target/repo    # Optional: target repo outside VM\n```\n\n**Implicit Assumption**: `--project` copies repo into VM. Agent works there, not on host.\n\n---\n\n## 5. Monitoring\n\n```bash\n# Terminal 1: Watch\n./dist/fabrik runs watch --vm ralph-1\n\n# Browser: Grafana\nopen http://localhost:3010\n\n# Check status\n./dist/fabrik runs list --vm ralph-1\n./dist/fabrik runs show --id <run-id>\n```\n\n**Implicit Assumption**: `runs watch` requires `terminal-notifier` (macOS) or `libnotify-bin` (Linux) for desktop notifications.\n\n---\n\n## 6. Human Gate (Review)\n\nAfter 8 reviewers (automatic) → Human Gate:\n\n```bash\n# Approve or reject\n./dist/fabrik feedback \\\n  --vm ralph-1 \\\n  --spec specs/feature.json \\\n  --decision approve \\\n  --notes \"Implementation correct, tests pass\"\n```\n\n**Implicit Assumption**: Without explicit feedback, run stays `blocked`. No automatic timeout.\n\n---\n\n## Summary: The Compound Cycle\n\n```\n┌────────────────────────────────────────────────────────────────┐\n│  80% PLANNING                                                  │\n│  ├── fabrik spec interview  → specs/feature.json              │\n│  └── fabrik todo generate     → specs/feature.todo.json       │\n├────────────────────────────────────────────────────────────────┤\n│  20% EXECUTION                                                 │\n│  └── fabrik run --spec ... --todo ... --vm ralph-1             │\n│      └── 8 Reviewers → Human Gate → Done                       │\n└────────────────────────────────────────────────────────────────┘\n```\n\n**Compound Effect**: Each completed cycle makes the next faster (reusable patterns, established reviewers).\n\n---\n\n## Troubleshooting\n\n| Symptom | Cause | Solution |\n|---------|-------|----------|\n| \"token in default is invalid\" | GITHUB_TOKEN missing/invalid | `export GITHUB_TOKEN=...` or in `ralph.env` |\n| \"blocked\" forever | Human Gate waiting | `fabrik feedback --decision approve ...` |\n| \"stale_process\" | VM heartbeat timeout | Check VM: `fabrik runs show --id <id>` |\n| Reviewers find nothing | Prompt missing | Check reviewer prompts in `prompts/reviewers/` |\n\n---\n\n## Command Reference\n\n| Command | Purpose |\n|---------|---------|\n| `fabrik spec interview` | 10-question interview guide (self-contained) |\n| `fabrik todo generate` | Todo generation guide (self-contained) |\n| `fabrik spec validate` | Validate Spec/Todo JSON |\n| `fabrik run --spec X --todo Y --vm Z` | Workflow dispatch |\n| `fabrik runs watch --vm Z` | Desktop notifications on block |\n| `fabrik feedback --vm Z --spec X --decision approve` | Release Human Gate |\n| `fabrik laos up/status/down` | Observability stack |\n\n---\n\n## Implicit Assumptions (Critical)\n\n1. **Agent-Auth**: `~/.pi/agent/auth.json` exists (created via `pi /login`)\n2. **GitHub Token**: `GITHUB_TOKEN` is set (for push/PR)\n3. **LAOS**: Running on localhost:3010 (logs/metrics)\n4. **VM**: `ralph-1` exists and is reachable\n5. **Network**: VMs can reach GitHub (for clone/push)\n6. **Disk**: VM has sufficient space for repo + dependencies\n7. **Order**: Spec → Todo → Run (binding)\n8. **Human Gate**: Must explicitly confirm (no auto-approve)\n" },
  { path: "specs/README.md", contents: "# Specs Workflow (Human Guide)\n\nThis repo follows a strict, test-driven flow for all features.\n\n## Flow\n1) **PRD → Spec**\n   - Human drafts `PRD.md` using `specs/templates/PRD.template.md`.\n   - Human verifies PRD with `specs/PRD-GUIDE.md`.\n   - Agent drafts `spec.json` from the approved PRD.\n   - Human reviews and edits `spec.json`.\n\n2) **Spec → TODO**\n   - Agent generates `todo.json` from the approved spec.\n\n3) **TODO → Implementation (Smithers)**\n   - Smithers runs tasks in order with tests first.\n   - Write `task_report` rows per task in the Smithers db (includes root-cause fields).\n\n4) **Manual Review Checkpoints**\n   - Review after each spec before proceeding to the next.\n\n## Diagram\n\n```\nPRD.md → spec.json → todo.json → fabrik dispatch (minify) → Smithers workflow → task_report rows\n                               (token-efficient input)    (per task)\n```\n\n## Files\n- Specs (human): `specs/*.json`\n- TODOs (human): `specs/*.todo.json`\n- Minified inputs: generated in the run workdir (gitignored)\n\n## Current Specs\n- `000-base`\n- `020-fabrik-v0-2-0`\n- `021-fabrik-run-persistence`\n- `022-fabrik-doctor`\n\n## Report Format (per task)\n`task_report` rows include:\n- `status`, `work`, `files`, `tests`, `issues`, `next`\n- `rootCause`, `reasoning`, `fix`, `error`, `commit`\n\n## Minified Inputs (Smithers)\n- `fabrik run` minifies spec/todo JSON on dispatch and writes the minified copies into the run workdir.\n- Minified files are **not** tracked in git.\n\n## Testing Requirements\n- TDD is mandatory.\n- Use `@effect/vitest` and Effect DI for external services.\n- Definition of Done: `bun test`, `bun run typecheck`.\n\n## Start Here\n- Read `specs/templates/PRD.template.md` and `specs/PRD-GUIDE.md`.\n- Read `specs/000-base.md`, `specs/000-base.json`, and `specs/000-base.todo.json`.\n- Implement in order, with tests first.\n" }
]
