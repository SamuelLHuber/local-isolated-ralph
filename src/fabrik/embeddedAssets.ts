// Generated by scripts/embed-assets.ts. Do not edit.
export type EmbeddedAsset = { path: string; contents: string; mode?: number }

export const embeddedAssets: EmbeddedAsset[] = [
  { path: "scripts/dispatch.sh", contents: "#!/usr/bin/env bash\n#\n# Dispatch a task to a Ralph VM and run the Smithers workflow\n# Usage: ./dispatch.sh [options] <vm-name> <spec-file> [project-dir] [max-iterations]\n#\n# Options:\n#   --include-git    Include .git directory in sync (enables commit/push from VM)\n#   --spec <path>    Spec JSON (minified recommended) for Smithers mode\n#   --todo <path>    TODO JSON (minified recommended) for Smithers mode\n#   --workflow <path> Smithers workflow script (default: scripts/smithers-spec-runner.tsx)\n#   --report-dir <path> Report output directory inside VM (default: <workdir>/reports)\n#   --model <name>   Model name for Smithers agent\n#   --prompt <path>  Global PROMPT.md prepended to task prompt\n#   --review-prompt <path> Reviewer PROMPT.md prepended to review prompt\n#   --review-max <n> Max review reruns before human gate (default: 2)\n#   --review-models <path> JSON map of reviewer_id -> model (optional)\n#\n# Examples:\n#   ./dispatch.sh --spec specs/010-weekly-summary.min.json ralph-1 specs/010-weekly-summary.min.json\n#   ./dispatch.sh --spec specs/010-weekly-summary.min.json ralph-2 specs/010-weekly-summary.min.json ~/projects/my-app\n#\n# Environment variables:\n#   MAX_ITERATIONS - Max loops before stopping (default: 100, 0 = unlimited)\n#   RALPH_AGENT    - Which agent to use: claude, codex, opencode (default: codex)\n\nset -euo pipefail\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\n\n# Parse options\nINCLUDE_GIT=false\nRESUME=false\nSMITHERS_SPEC_PATH=\"\"\nSMITHERS_TODO_PATH=\"\"\nSMITHERS_WORKFLOW=\"\"\nSMITHERS_REPORT_DIR=\"\"\nSMITHERS_MODEL=\"\"\nSMITHERS_PROMPT_PATH=\"\"\nSMITHERS_REVIEW_PROMPT_PATH=\"\"\nSMITHERS_REVIEWERS_DIR_SRC=\"\"\nSMITHERS_REVIEW_MAX=\"\"\nSMITHERS_REVIEW_MODELS_FILE=\"\"\nwhile [[ $# -gt 0 && \"$1\" == --* ]]; do\n  case \"$1\" in\n    --include-git)\n      INCLUDE_GIT=true\n      shift\n      ;;\n    --spec)\n      SMITHERS_SPEC_PATH=\"${2:-}\"\n      shift 2\n      ;;\n    --todo)\n      SMITHERS_TODO_PATH=\"${2:-}\"\n      shift 2\n      ;;\n    --workflow)\n      SMITHERS_WORKFLOW=\"${2:-}\"\n      shift 2\n      ;;\n    --report-dir)\n      SMITHERS_REPORT_DIR=\"${2:-}\"\n      shift 2\n      ;;\n    --model)\n      SMITHERS_MODEL=\"${2:-}\"\n      shift 2\n      ;;\n    --prompt)\n      SMITHERS_PROMPT_PATH=\"${2:-}\"\n      shift 2\n      ;;\n    --review-prompt)\n      SMITHERS_REVIEW_PROMPT_PATH=\"${2:-}\"\n      shift 2\n      ;;\n    --review-max)\n      SMITHERS_REVIEW_MAX=\"${2:-}\"\n      shift 2\n      ;;\n    --review-models)\n      SMITHERS_REVIEW_MODELS_FILE=\"${2:-}\"\n      shift 2\n      ;;\n    --resume)\n      RESUME=true\n      shift\n      ;;\n    *)\n      echo \"Unknown option: $1\"\n      exit 1\n      ;;\n  esac\ndone\n\nVM_NAME=\"${1:?Usage: $0 [--include-git] <vm-name> <spec-file> [project-dir] [max-iterations]}\"\nPROMPT_FILE=\"${2:?Usage: $0 [--include-git] <vm-name> <spec-file> [project-dir] [max-iterations]}\"\nPROJECT_DIR=\"${3:-}\"\nMAX_ITERATIONS=\"${4:-${MAX_ITERATIONS:-100}}\"\nRALPH_AGENT=\"${RALPH_AGENT:-codex}\"\n\n# Set the agent command based on RALPH_AGENT\ncase \"$RALPH_AGENT\" in\n  claude)\n    AGENT_CMD=\"claude --dangerously-skip-permissions\"\n    ;;\n  codex)\n    AGENT_CMD=\"codex exec --dangerously-bypass-approvals-and-sandbox\"\n    ;;\n  opencode)\n    AGENT_CMD=\"opencode\"\n    ;;\n  *)\n    echo \"Error: Unknown agent '$RALPH_AGENT'. Use: claude, codex, or opencode\"\n    exit 1\n    ;;\nesac\n\nPROMPT_FILE=$(realpath \"$PROMPT_FILE\")\n\nif [[ -z \"$SMITHERS_SPEC_PATH\" ]]; then\n  SMITHERS_SPEC_PATH=\"$PROMPT_FILE\"\nfi\nif [[ -z \"$SMITHERS_TODO_PATH\" ]]; then\n  if [[ \"$SMITHERS_SPEC_PATH\" == *.todo.min.json ]]; then\n    SMITHERS_TODO_PATH=\"$SMITHERS_SPEC_PATH\"\n  else\n    SMITHERS_TODO_PATH=\"${SMITHERS_SPEC_PATH%.min.json}.todo.min.json\"\n    if [[ \"$SMITHERS_TODO_PATH\" == \"$SMITHERS_SPEC_PATH\" ]]; then\n      SMITHERS_TODO_PATH=\"${SMITHERS_SPEC_PATH%.json}.todo.json\"\n    fi\n  fi\nfi\n\nSMITHERS_SPEC_PATH=$(realpath \"$SMITHERS_SPEC_PATH\")\nSMITHERS_TODO_PATH=$(realpath \"$SMITHERS_TODO_PATH\")\n\nif [[ ! -f \"$SMITHERS_SPEC_PATH\" ]]; then\n  echo \"Error: Spec file not found: $SMITHERS_SPEC_PATH\"\n  exit 1\nfi\nif [[ ! -f \"$SMITHERS_TODO_PATH\" ]]; then\n  echo \"Error: TODO file not found: $SMITHERS_TODO_PATH\"\n  exit 1\nfi\n\nif [[ -z \"$SMITHERS_WORKFLOW\" ]]; then\n  SMITHERS_WORKFLOW=\"$SCRIPT_DIR/smithers-spec-runner.tsx\"\nfi\nif [[ \"$SMITHERS_WORKFLOW\" != /* && \"$SMITHERS_WORKFLOW\" != ~* ]]; then\n  if [[ -f \"$SMITHERS_WORKFLOW\" ]]; then\n    SMITHERS_WORKFLOW=$(realpath \"$SMITHERS_WORKFLOW\")\n  elif [[ -f \"$SCRIPT_DIR/$SMITHERS_WORKFLOW\" ]]; then\n    SMITHERS_WORKFLOW=$(realpath \"$SCRIPT_DIR/$SMITHERS_WORKFLOW\")\n  elif [[ -f \"$SCRIPT_DIR/../$SMITHERS_WORKFLOW\" ]]; then\n    SMITHERS_WORKFLOW=$(realpath \"$SCRIPT_DIR/../$SMITHERS_WORKFLOW\")\n  else\n    SMITHERS_WORKFLOW=$(realpath \"$SMITHERS_WORKFLOW\")\n  fi\nelse\n  SMITHERS_WORKFLOW=$(realpath \"$SMITHERS_WORKFLOW\")\nfi\nif [[ ! -f \"$SMITHERS_WORKFLOW\" ]]; then\n  echo \"Error: Smithers workflow not found: $SMITHERS_WORKFLOW\"\n  exit 1\nfi\n\nif [[ -z \"$SMITHERS_PROMPT_PATH\" && -f \"$SCRIPT_DIR/../prompts/DEFAULT-IMPLEMENTER.md\" ]]; then\n  SMITHERS_PROMPT_PATH=\"$SCRIPT_DIR/../prompts/DEFAULT-IMPLEMENTER.md\"\nfi\nif [[ -n \"$SMITHERS_PROMPT_PATH\" ]]; then\n  SMITHERS_PROMPT_PATH=$(realpath \"$SMITHERS_PROMPT_PATH\")\n  if [[ ! -f \"$SMITHERS_PROMPT_PATH\" ]]; then\n    echo \"Error: Prompt file not found: $SMITHERS_PROMPT_PATH\"\n    exit 1\n  fi\nfi\n\nif [[ -z \"$SMITHERS_REVIEW_PROMPT_PATH\" && -f \"$SCRIPT_DIR/../prompts/DEFAULT-REVIEWER.md\" ]]; then\n  SMITHERS_REVIEW_PROMPT_PATH=\"$SCRIPT_DIR/../prompts/DEFAULT-REVIEWER.md\"\nfi\nif [[ -n \"$SMITHERS_REVIEW_PROMPT_PATH\" ]]; then\n  SMITHERS_REVIEW_PROMPT_PATH=$(realpath \"$SMITHERS_REVIEW_PROMPT_PATH\")\n  if [[ ! -f \"$SMITHERS_REVIEW_PROMPT_PATH\" ]]; then\n    echo \"Error: Review prompt file not found: $SMITHERS_REVIEW_PROMPT_PATH\"\n    exit 1\n  fi\nfi\n\nif [[ -n \"$SMITHERS_REVIEW_MODELS_FILE\" ]]; then\n  SMITHERS_REVIEW_MODELS_FILE=$(realpath \"$SMITHERS_REVIEW_MODELS_FILE\")\n  if [[ ! -f \"$SMITHERS_REVIEW_MODELS_FILE\" ]]; then\n    echo \"Error: Review models file not found: $SMITHERS_REVIEW_MODELS_FILE\"\n    exit 1\n  fi\nfi\n\nif [[ -d \"$SCRIPT_DIR/../prompts/reviewers\" ]]; then\n  SMITHERS_REVIEWERS_DIR_SRC=\"$SCRIPT_DIR/../prompts/reviewers\"\nfi\n\ncase \"$(uname -s)\" in\n  Darwin) OS=\"macos\" ;;\n  Linux)  OS=\"linux\" ;;\n  *)\n    echo \"Unsupported OS\"\n    exit 1\n    ;;\nesac\n\n# Generate unique work directory with timestamp\nTIMESTAMP=$(date +%Y%m%d-%H%M%S)\nif [[ -n \"$PROJECT_DIR\" ]]; then\n  PROJECT_BASENAME=$(basename \"$PROJECT_DIR\")\nelse\n  PROJECT_BASENAME=\"task\"\nfi\nWORK_SUBDIR=\"${PROJECT_BASENAME}-${TIMESTAMP}\"\n\nDB_DIR=\"$HOME/.cache/ralph\"\nDB_PATH=\"${RALPH_DB_PATH:-$DB_DIR/ralph.db}\"\nmkdir -p \"$DB_DIR\"\nchmod 700 \"$DB_DIR\" 2>/dev/null || true\nif [[ -e \"$DB_PATH\" ]]; then\n  chmod 600 \"$DB_PATH\" 2>/dev/null || true\nfi\nif [[ -e \"$DB_PATH\" && ! -w \"$DB_PATH\" ]]; then\n  echo \"[WARN] DB not writable: $DB_PATH\"\n  DB_PATH=\"\"\nfi\nif [[ -z \"$DB_PATH\" && ! -w \"$DB_DIR\" ]]; then\n  TMP_DB_DIR=\"${TMPDIR:-/tmp}/ralph\"\n  mkdir -p \"$TMP_DB_DIR\"\n  DB_PATH=\"$TMP_DB_DIR/ralph.db\"\n  echo \"[WARN] Falling back to writable DB path: $DB_PATH\"\nelif [[ -z \"$DB_PATH\" ]]; then\n  DB_PATH=\"$DB_DIR/ralph.db\"\nfi\n\necho \"[$VM_NAME] Dispatching spec: $SMITHERS_SPEC_PATH\"\necho \"[$VM_NAME] Agent: $RALPH_AGENT ($AGENT_CMD)\"\necho \"[$VM_NAME] Include .git: $INCLUDE_GIT\"\necho \"[$VM_NAME] Work dir: /home/ralph/work/${VM_NAME}/${WORK_SUBDIR}\"\necho \"[$VM_NAME] Orchestrator: Smithers\"\necho \"[$VM_NAME] Spec: $SMITHERS_SPEC_PATH\"\necho \"[$VM_NAME] TODO: $SMITHERS_TODO_PATH\"\necho \"[$VM_NAME] Workflow: $SMITHERS_WORKFLOW\"\n\nRUN_ID=$(\n  python3 - \"$DB_PATH\" \"$VM_NAME\" \"/home/ralph/work/${VM_NAME}/${WORK_SUBDIR}\" \"$SMITHERS_SPEC_PATH\" \"$SMITHERS_TODO_PATH\" <<'PY'\nimport sqlite3\nimport sys\nfrom datetime import datetime, timezone\n\ndb_path, vm, workdir, spec, todo = sys.argv[1:6]\nconn = sqlite3.connect(db_path)\nconn.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS runs (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  vm_name TEXT NOT NULL,\n  workdir TEXT NOT NULL,\n  spec_path TEXT NOT NULL,\n  todo_path TEXT NOT NULL,\n  started_at TEXT NOT NULL,\n  status TEXT NOT NULL,\n  exit_code INTEGER\n)\n\"\"\")\nconn.execute(\"CREATE INDEX IF NOT EXISTS runs_vm_started ON runs(vm_name, started_at)\")\nstarted_at = datetime.now(timezone.utc).isoformat()\ncur = conn.execute(\n  \"INSERT INTO runs (vm_name, workdir, spec_path, todo_path, started_at, status) VALUES (?, ?, ?, ?, ?, ?)\",\n  (vm, workdir, spec, todo, started_at, \"running\")\n)\nconn.commit()\nprint(cur.lastrowid)\nconn.close()\nPY\n)\n\nif [[ \"$OS\" == \"macos\" ]]; then\n  if ! limactl list --format '{{.Name}} {{.Status}}' 2>/dev/null | grep -q \"^$VM_NAME Running\"; then\n    echo \"[$VM_NAME] Starting VM...\"\n    limactl start \"$VM_NAME\"\n  fi\n\n  VM_WORK_DIR=\"/home/ralph/work/${VM_NAME}/${WORK_SUBDIR}\"\n  limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph mkdir -p \"$VM_WORK_DIR\"\n\n  cat \"$PROMPT_FILE\" | limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph tee \"${VM_WORK_DIR}/SPEC.md\" > /dev/null\n  limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph mkdir -p \"${VM_WORK_DIR}/specs\" \"${VM_WORK_DIR}/reports\"\n  cat \"$SMITHERS_SPEC_PATH\" | limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph tee \"${VM_WORK_DIR}/specs/spec.min.json\" > /dev/null\n  cat \"$SMITHERS_TODO_PATH\" | limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph tee \"${VM_WORK_DIR}/specs/todo.min.json\" > /dev/null\n  cat \"$SMITHERS_WORKFLOW\" | limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph tee \"${VM_WORK_DIR}/smithers-workflow.tsx\" > /dev/null\n  if [[ -n \"$SMITHERS_PROMPT_PATH\" ]]; then\n    cat \"$SMITHERS_PROMPT_PATH\" | limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph tee \"${VM_WORK_DIR}/PROMPT.md\" > /dev/null\n  fi\n  if [[ -n \"$SMITHERS_REVIEW_PROMPT_PATH\" ]]; then\n    cat \"$SMITHERS_REVIEW_PROMPT_PATH\" | limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph tee \"${VM_WORK_DIR}/REVIEW_PROMPT.md\" > /dev/null\n  fi\n  if [[ -n \"$SMITHERS_REVIEW_MODELS_FILE\" ]]; then\n    cat \"$SMITHERS_REVIEW_MODELS_FILE\" | limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph tee \"${VM_WORK_DIR}/reviewer-models.json\" > /dev/null\n  fi\n  if [[ -n \"$SMITHERS_REVIEWERS_DIR_SRC\" ]]; then\n    limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph mkdir -p \"${VM_WORK_DIR}/reviewers\"\n    tar -C \"$SMITHERS_REVIEWERS_DIR_SRC\" -cf - . | limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph tar -C \"${VM_WORK_DIR}/reviewers\" -xf -\n  fi\n\n  # Record run context (prompts + hashes) for audit\n  python3 - \"$SMITHERS_SPEC_PATH\" \"$SMITHERS_TODO_PATH\" \"$SMITHERS_PROMPT_PATH\" \"$SMITHERS_REVIEW_PROMPT_PATH\" \"$SMITHERS_REVIEWERS_DIR_SRC\" \"$SMITHERS_REVIEW_MODELS_FILE\" \"$VM_NAME\" \"$RUN_ID\" <<'PY' \\\n    | limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph tee \"${VM_WORK_DIR}/reports/run-context.json\" > /dev/null\nimport hashlib\nimport json\nimport os\nimport sys\nfrom datetime import datetime, timezone\n\ndef read_text(path: str) -> str:\n    if not path:\n        return \"\"\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            return f.read()\n    except Exception:\n        return \"\"\n\ndef sha256(path: str) -> str:\n    if not path or not os.path.exists(path):\n        return \"\"\n    h = hashlib.sha256()\n    with open(path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(8192), b\"\"):\n            h.update(chunk)\n    return h.hexdigest()\n\nspec_path, todo_path, prompt_path, review_prompt_path, reviewers_dir, review_models_path, vm, run_id = sys.argv[1:9]\n\nreviewers = []\nif reviewers_dir and os.path.isdir(reviewers_dir):\n    for name in sorted(os.listdir(reviewers_dir)):\n        if not name.lower().endswith(\".md\"):\n            continue\n        path = os.path.join(reviewers_dir, name)\n        reviewers.append({\n            \"file\": name,\n            \"path\": path,\n            \"sha256\": sha256(path)\n        })\npayload = {\n    \"v\": 1,\n    \"run_id\": int(run_id),\n    \"vm\": vm,\n    \"created_at\": datetime.now(timezone.utc).isoformat(),\n    \"spec_path\": spec_path,\n    \"todo_path\": todo_path,\n    \"prompt_path\": prompt_path or None,\n    \"review_prompt_path\": review_prompt_path or None,\n    \"spec_sha256\": sha256(spec_path),\n    \"todo_sha256\": sha256(todo_path),\n    \"prompt_sha256\": sha256(prompt_path),\n    \"review_prompt_sha256\": sha256(review_prompt_path),\n    \"review_models_path\": review_models_path or None,\n    \"review_models_sha256\": sha256(review_models_path),\n    \"prompt_text\": read_text(prompt_path).strip(),\n    \"review_prompt_text\": read_text(review_prompt_path).strip(),\n    \"review_models_text\": read_text(review_models_path).strip(),\n    \"reviewers\": reviewers\n}\nprint(json.dumps(payload, indent=2))\nPY\n\n  if [[ -n \"$PROJECT_DIR\" ]]; then\n    echo \"[$VM_NAME] Syncing project directory...\"\n\n    # Build tar exclude options (exclude node_modules and macOS extended attribute files)\n    TAR_EXCLUDES=\"--exclude='node_modules' --exclude='._*' --exclude='.DS_Store'\"\n    if [[ \"$INCLUDE_GIT\" == \"false\" ]]; then\n      TAR_EXCLUDES=\"$TAR_EXCLUDES --exclude='.git'\"\n    fi\n\n    COPYFILE_DISABLE=1 eval \"tar -C '$PROJECT_DIR' --no-xattrs $TAR_EXCLUDES -cf - .\" | limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph tar -C \"${VM_WORK_DIR}\" -xf -\n    VM_PROJECT_DIR=\"${VM_WORK_DIR}\"\n\n    # If .git was included, verify git remote works and init jj\n    if [[ \"$INCLUDE_GIT\" == \"true\" && -d \"$PROJECT_DIR/.git\" ]]; then\n      echo \"[$VM_NAME] Verifying git remote access and initializing jj...\"\n      limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph bash -c \"\n        cd '${VM_PROJECT_DIR}'\n\n        # Source ralph.env for GITHUB_TOKEN\n        if [[ -f ~/.config/ralph/ralph.env ]]; then\n          set -a\n          source ~/.config/ralph/ralph.env\n          set +a\n        fi\n\n        # Configure git to use GITHUB_TOKEN for GitHub HTTPS URLs\n        if [[ -n \\\"\\${GITHUB_TOKEN:-}\\\" ]]; then\n          git config --global url.\\\"https://oauth:\\${GITHUB_TOKEN}@github.com/\\\".insteadOf \\\"https://github.com/\\\"\n        fi\n\n        # Show current remote (redact tokens)\n        REMOTE_URL=\\$(git remote get-url origin 2>/dev/null || echo 'none')\n        REMOTE_URL_SAFE=\\$(echo \\\"\\$REMOTE_URL\\\" | sed -E 's|://[^:]+:[^@]+@|://***@|')\n        echo '[$VM_NAME] Git remote: '\\$REMOTE_URL_SAFE\n\n        # Configure git user if not set\n        git config user.email >/dev/null 2>&1 || git config user.email 'ralph@local'\n        git config user.name >/dev/null 2>&1 || git config user.name 'Ralph Agent'\n\n        # Test that we can fetch (verifies credentials work)\n        if git ls-remote --exit-code origin HEAD >/dev/null 2>&1; then\n          echo '[$VM_NAME] Git remote access: OK'\n        else\n          echo '[$VM_NAME] WARNING: Cannot access git remote. Push may fail.'\n          echo '[$VM_NAME] Ensure GITHUB_TOKEN is set in ~/.config/ralph/ralph.env'\n        fi\n\n        # Initialize jj (colocated) if needed\n        if [[ ! -d .jj ]]; then\n          jj git init >/dev/null 2>&1 || true\n        fi\n        echo '[$VM_NAME] JJ: '\\$(jj status -s 2>/dev/null | head -1 || echo 'ready')\n      \"\n    fi\n\n    # Install dependencies if package.json exists\n    if [[ -f \"$PROJECT_DIR/package.json\" ]]; then\n      echo \"[$VM_NAME] Installing dependencies (bun install)...\"\n      limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph bash -c \"cd '${VM_PROJECT_DIR}' \\\n        && export PATH=\\\"\\$HOME/.bun/bin:\\$PATH\\\" \\\n        && export BUN_INSTALL_IGNORE_SCRIPTS=0 \\\n        && export npm_config_ignore_scripts=false \\\n        && BUN_CHECK_OUTPUT=\\$(bun --version 2>&1 || true) \\\n        && if echo \\\"\\$BUN_CHECK_OUTPUT\\\" | grep -q 'postinstall script was not run'; then \\\n             echo '[$VM_NAME] Fixing bun postinstall...'; \\\n             if command -v node >/dev/null 2>&1 && [[ -f \\\"\\$HOME/.bun/install/global/node_modules/bun/install.js\\\" ]]; then \\\n               node \\\"\\$HOME/.bun/install/global/node_modules/bun/install.js\\\"; \\\n             fi; \\\n           fi \\\n        && bun install\" 2>&1 | tail -5\n    fi\n  else\n    VM_PROJECT_DIR=\"$VM_WORK_DIR\"\n  fi\n\n  echo \"[$VM_NAME] Starting Smithers workflow (max iterations: $MAX_ITERATIONS)...\"\n  limactl shell --workdir /home/ralph \"$VM_NAME\" sudo -u ralph bash <<EOF\n    cd \"${VM_PROJECT_DIR}\"\n    echo \"[$VM_NAME] Working in: \\$(pwd)\"\n    echo \"[$VM_NAME] Starting loop...\"\n    export PATH=\"\\$HOME/.bun/bin:\\$PATH\"\n    export MAX_ITERATIONS=${MAX_ITERATIONS}\n    export RALPH_AGENT=${RALPH_AGENT}\n\n    export SMITHERS_SPEC_PATH=\"${VM_WORK_DIR}/specs/spec.min.json\"\n    export SMITHERS_TODO_PATH=\"${VM_WORK_DIR}/specs/todo.min.json\"\n    export SMITHERS_REPORT_DIR=\"${SMITHERS_REPORT_DIR:-${VM_WORK_DIR}/reports}\"\n    export SMITHERS_AGENT=\"${RALPH_AGENT}\"\n    if [[ -n \"${SMITHERS_MODEL}\" ]]; then\n      export SMITHERS_MODEL=\"${SMITHERS_MODEL}\"\n    fi\n    if [[ -d \"${VM_WORK_DIR}/reviewers\" ]]; then\n      export SMITHERS_REVIEWERS_DIR=\"${VM_WORK_DIR}/reviewers\"\n    fi\n    if [[ -f \"${VM_WORK_DIR}/PROMPT.md\" ]]; then\n      export SMITHERS_PROMPT_PATH=\"${VM_WORK_DIR}/PROMPT.md\"\n    fi\n    if [[ -f \"${VM_WORK_DIR}/REVIEW_PROMPT.md\" ]]; then\n      export SMITHERS_REVIEW_PROMPT_PATH=\"${VM_WORK_DIR}/REVIEW_PROMPT.md\"\n    fi\n    if [[ -n \"${SMITHERS_REVIEW_MAX}\" ]]; then\n      export SMITHERS_REVIEW_MAX=\"${SMITHERS_REVIEW_MAX}\"\n    fi\n    if [[ -f \"${VM_WORK_DIR}/reviewer-models.json\" ]]; then\n      export SMITHERS_REVIEW_MODELS_FILE=\"${VM_WORK_DIR}/reviewer-models.json\"\n    fi\n    export SMITHERS_MAX_ITERATIONS=\"${MAX_ITERATIONS}\"\n    smithers \"${VM_WORK_DIR}/smithers-workflow.tsx\"\n    exit \\$?\nEOF\n  EXIT_CODE=$?\n  python3 - \"$DB_PATH\" \"$RUN_ID\" \"$EXIT_CODE\" <<'PY'\nimport sqlite3\nimport sys\n\ndb_path, run_id, exit_code = sys.argv[1:4]\nstatus = \"success\" if exit_code == \"0\" else \"failed\"\nconn = sqlite3.connect(db_path)\nconn.execute(\"UPDATE runs SET status = ?, exit_code = ? WHERE id = ?\", (status, int(exit_code), int(run_id)))\nconn.commit()\nconn.close()\nPY\n\nelse\n  VM_IP=$(virsh domifaddr \"$VM_NAME\" 2>/dev/null | grep ipv4 | awk '{print $4}' | cut -d/ -f1)\n\n  if [[ -z \"$VM_IP\" ]]; then\n    echo \"[$VM_NAME] VM not running or no IP. Starting...\"\n    virsh start \"$VM_NAME\" 2>/dev/null || true\n    sleep 10\n    VM_IP=$(virsh domifaddr \"$VM_NAME\" | grep ipv4 | awk '{print $4}' | cut -d/ -f1)\n  fi\n\n  if [[ -z \"$VM_IP\" ]]; then\n    echo \"[$VM_NAME] Error: Could not get VM IP\"\n    exit 1\n  fi\n\n  echo \"[$VM_NAME] VM IP: $VM_IP\"\n\n  VM_WORK_DIR=\"/home/ralph/work/${VM_NAME}/${WORK_SUBDIR}\"\n  ssh \"ralph@${VM_IP}\" \"mkdir -p '$VM_WORK_DIR'\"\n  scp \"$PROMPT_FILE\" \"ralph@${VM_IP}:${VM_WORK_DIR}/SPEC.md\"\n  ssh \"ralph@${VM_IP}\" \"mkdir -p '${VM_WORK_DIR}/specs' '${VM_WORK_DIR}/reports'\"\n  scp \"$SMITHERS_SPEC_PATH\" \"ralph@${VM_IP}:${VM_WORK_DIR}/specs/spec.min.json\"\n  scp \"$SMITHERS_TODO_PATH\" \"ralph@${VM_IP}:${VM_WORK_DIR}/specs/todo.min.json\"\n  scp \"$SMITHERS_WORKFLOW\" \"ralph@${VM_IP}:${VM_WORK_DIR}/smithers-workflow.tsx\"\n  if [[ -n \"$SMITHERS_PROMPT_PATH\" ]]; then\n    scp \"$SMITHERS_PROMPT_PATH\" \"ralph@${VM_IP}:${VM_WORK_DIR}/PROMPT.md\"\n  fi\n  if [[ -n \"$SMITHERS_REVIEW_PROMPT_PATH\" ]]; then\n    scp \"$SMITHERS_REVIEW_PROMPT_PATH\" \"ralph@${VM_IP}:${VM_WORK_DIR}/REVIEW_PROMPT.md\"\n  fi\n  if [[ -n \"$SMITHERS_REVIEW_MODELS_FILE\" ]]; then\n    scp \"$SMITHERS_REVIEW_MODELS_FILE\" \"ralph@${VM_IP}:${VM_WORK_DIR}/reviewer-models.json\"\n  fi\n  if [[ -n \"$SMITHERS_REVIEWERS_DIR_SRC\" ]]; then\n    ssh \"ralph@${VM_IP}\" \"mkdir -p '${VM_WORK_DIR}/reviewers'\"\n    scp -r \"$SMITHERS_REVIEWERS_DIR_SRC/.\" \"ralph@${VM_IP}:${VM_WORK_DIR}/reviewers/\"\n  fi\n  python3 - \"$SMITHERS_SPEC_PATH\" \"$SMITHERS_TODO_PATH\" \"$SMITHERS_PROMPT_PATH\" \"$SMITHERS_REVIEW_PROMPT_PATH\" \"$SMITHERS_REVIEWERS_DIR_SRC\" \"$SMITHERS_REVIEW_MODELS_FILE\" \"$VM_NAME\" \"$RUN_ID\" <<'PY' > /tmp/ralph-run-context.json\nimport hashlib\nimport json\nimport os\nimport sys\nfrom datetime import datetime, timezone\n\ndef read_text(path: str) -> str:\n    if not path:\n        return \"\"\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            return f.read()\n    except Exception:\n        return \"\"\n\ndef sha256(path: str) -> str:\n    if not path or not os.path.exists(path):\n        return \"\"\n    h = hashlib.sha256()\n    with open(path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(8192), b\"\"):\n            h.update(chunk)\n    return h.hexdigest()\n\nspec_path, todo_path, prompt_path, review_prompt_path, reviewers_dir, review_models_path, vm, run_id = sys.argv[1:9]\n\nreviewers = []\nif reviewers_dir and os.path.isdir(reviewers_dir):\n    for name in sorted(os.listdir(reviewers_dir)):\n        if not name.lower().endswith(\".md\"):\n            continue\n        path = os.path.join(reviewers_dir, name)\n        reviewers.append({\n            \"file\": name,\n            \"path\": path,\n            \"sha256\": sha256(path)\n        })\npayload = {\n    \"v\": 1,\n    \"run_id\": int(run_id),\n    \"vm\": vm,\n    \"created_at\": datetime.now(timezone.utc).isoformat(),\n    \"spec_path\": spec_path,\n    \"todo_path\": todo_path,\n    \"prompt_path\": prompt_path or None,\n    \"review_prompt_path\": review_prompt_path or None,\n    \"spec_sha256\": sha256(spec_path),\n    \"todo_sha256\": sha256(todo_path),\n    \"prompt_sha256\": sha256(prompt_path),\n    \"review_prompt_sha256\": sha256(review_prompt_path),\n    \"review_models_path\": review_models_path or None,\n    \"review_models_sha256\": sha256(review_models_path),\n    \"prompt_text\": read_text(prompt_path).strip(),\n    \"review_prompt_text\": read_text(review_prompt_path).strip(),\n    \"review_models_text\": read_text(review_models_path).strip(),\n    \"reviewers\": reviewers\n}\nprint(json.dumps(payload, indent=2))\nPY\n  scp /tmp/ralph-run-context.json \"ralph@${VM_IP}:${VM_WORK_DIR}/reports/run-context.json\"\n  rm -f /tmp/ralph-run-context.json\n\n  if [[ -n \"$PROJECT_DIR\" ]]; then\n    echo \"[$VM_NAME] Syncing project directory...\"\n\n    # Build rsync exclude options\n    RSYNC_EXCLUDES=\"--exclude='node_modules'\"\n    if [[ \"$INCLUDE_GIT\" == \"false\" ]]; then\n      RSYNC_EXCLUDES=\"$RSYNC_EXCLUDES --exclude='.git'\"\n    fi\n\n    eval \"rsync -az --delete $RSYNC_EXCLUDES '$PROJECT_DIR/' 'ralph@${VM_IP}:${VM_WORK_DIR}/'\"\n    VM_PROJECT_DIR=\"${VM_WORK_DIR}\"\n\n    # If .git was included, verify git remote works and init jj\n    if [[ \"$INCLUDE_GIT\" == \"true\" && -d \"$PROJECT_DIR/.git\" ]]; then\n      echo \"[$VM_NAME] Verifying git remote access and initializing jj...\"\n      ssh \"ralph@${VM_IP}\" bash -c \"'\n        cd \\\"$VM_PROJECT_DIR\\\"\n\n        # Source ralph.env for GITHUB_TOKEN\n        if [[ -f ~/.config/ralph/ralph.env ]]; then\n          set -a\n          source ~/.config/ralph/ralph.env\n          set +a\n        fi\n\n        # Configure git to use GITHUB_TOKEN for GitHub HTTPS URLs\n        if [[ -n \\\"\\${GITHUB_TOKEN:-}\\\" ]]; then\n          git config --global url.\\\"https://oauth:\\${GITHUB_TOKEN}@github.com/\\\".insteadOf \\\"https://github.com/\\\"\n        fi\n\n        # Show current remote (redact tokens)\n        REMOTE_URL=\\$(git remote get-url origin 2>/dev/null || echo \\\"none\\\")\n        REMOTE_URL_SAFE=\\$(echo \\\"\\$REMOTE_URL\\\" | sed -E 's|://[^:]+:[^@]+@|://***@|')\n        echo \\\"[$VM_NAME] Git remote: \\$REMOTE_URL_SAFE\\\"\n\n        # Configure git user if not set\n        git config user.email >/dev/null 2>&1 || git config user.email \\\"ralph@local\\\"\n        git config user.name >/dev/null 2>&1 || git config user.name \\\"Ralph Agent\\\"\n\n        # Test that we can fetch (verifies credentials work)\n        if git ls-remote --exit-code origin HEAD >/dev/null 2>&1; then\n          echo \\\"[$VM_NAME] Git remote access: OK\\\"\n        else\n          echo \\\"[$VM_NAME] WARNING: Cannot access git remote. Push may fail.\\\"\n          echo \\\"[$VM_NAME] Ensure GITHUB_TOKEN is set in ~/.config/ralph/ralph.env\\\"\n        fi\n\n        # Initialize jj (colocated) if needed\n        if [[ ! -d .jj ]]; then\n          jj git init >/dev/null 2>&1 || true\n        fi\n        echo \\\"[$VM_NAME] JJ: \\$(jj status -s 2>/dev/null | head -1 || echo 'ready')\\\"\n      '\"\n    fi\n\n    # Install dependencies if package.json exists\n    if [[ -f \"$PROJECT_DIR/package.json\" ]]; then\n      echo \"[$VM_NAME] Installing dependencies (bun install)...\"\n      ssh \"ralph@${VM_IP}\" \"cd '${VM_PROJECT_DIR}' \\\n        && export PATH=\\\"\\$HOME/.bun/bin:\\$PATH\\\" \\\n        && export BUN_INSTALL_IGNORE_SCRIPTS=0 \\\n        && export npm_config_ignore_scripts=false \\\n        && BUN_CHECK_OUTPUT=\\$(bun --version 2>&1 || true) \\\n        && if echo \\\"\\$BUN_CHECK_OUTPUT\\\" | grep -q 'postinstall script was not run'; then \\\n             echo '[$VM_NAME] Fixing bun postinstall...'; \\\n             if command -v node >/dev/null 2>&1 && [[ -f \\\"\\$HOME/.bun/install/global/node_modules/bun/install.js\\\" ]]; then \\\n               node \\\"\\$HOME/.bun/install/global/node_modules/bun/install.js\\\"; \\\n             fi; \\\n           fi \\\n        && bun install\" 2>&1 | tail -5\n    fi\n  else\n    VM_PROJECT_DIR=\"$VM_WORK_DIR\"\n  fi\n\n  echo \"[$VM_NAME] Starting Smithers workflow (max iterations: $MAX_ITERATIONS)...\"\n  ssh \"ralph@${VM_IP}\" bash -c \"'\n    cd \\\"$VM_PROJECT_DIR\\\"\n    echo \\\"[$VM_NAME] Working in: \\$(pwd)\\\"\n    echo \\\"[$VM_NAME] Starting loop...\\\"\n    export PATH=\\\"\\$HOME/.bun/bin:\\$PATH\\\"\n    export MAX_ITERATIONS=$MAX_ITERATIONS\n    export RALPH_AGENT=$RALPH_AGENT\n\n    export SMITHERS_SPEC_PATH=\\\"${VM_WORK_DIR}/specs/spec.min.json\\\"\n    export SMITHERS_TODO_PATH=\\\"${VM_WORK_DIR}/specs/todo.min.json\\\"\n    export SMITHERS_REPORT_DIR=\\\"${SMITHERS_REPORT_DIR:-${VM_WORK_DIR}/reports}\\\"\n    export SMITHERS_AGENT=\\\"${RALPH_AGENT}\\\"\n    if [[ -n \\\"${SMITHERS_MODEL}\\\" ]]; then\n      export SMITHERS_MODEL=\\\"${SMITHERS_MODEL}\\\"\n    fi\n    if [[ -d \\\"${VM_WORK_DIR}/reviewers\\\" ]]; then\n      export SMITHERS_REVIEWERS_DIR=\\\"${VM_WORK_DIR}/reviewers\\\"\n    fi\n    if [[ -f \\\"${VM_WORK_DIR}/PROMPT.md\\\" ]]; then\n      export SMITHERS_PROMPT_PATH=\\\"${VM_WORK_DIR}/PROMPT.md\\\"\n    fi\n    if [[ -f \\\"${VM_WORK_DIR}/REVIEW_PROMPT.md\\\" ]]; then\n      export SMITHERS_REVIEW_PROMPT_PATH=\\\"${VM_WORK_DIR}/REVIEW_PROMPT.md\\\"\n    fi\n    if [[ -n \\\"${SMITHERS_REVIEW_MAX}\\\" ]]; then\n      export SMITHERS_REVIEW_MAX=\\\"${SMITHERS_REVIEW_MAX}\\\"\n    fi\n    if [[ -f \\\"${VM_WORK_DIR}/reviewer-models.json\\\" ]]; then\n      export SMITHERS_REVIEW_MODELS_FILE=\\\"${VM_WORK_DIR}/reviewer-models.json\\\"\n    fi\n    export SMITHERS_MAX_ITERATIONS=\\\"${MAX_ITERATIONS}\\\"\n    smithers \\\"${VM_WORK_DIR}/smithers-workflow.tsx\\\"\n    exit \\$?\n  '\"\n  EXIT_CODE=$?\n  python3 - \"$DB_PATH\" \"$RUN_ID\" \"$EXIT_CODE\" <<'PY'\nimport sqlite3\nimport sys\n\ndb_path, run_id, exit_code = sys.argv[1:4]\nstatus = \"success\" if exit_code == \"0\" else \"failed\"\nconn = sqlite3.connect(db_path)\nconn.execute(\"UPDATE runs SET status = ?, exit_code = ? WHERE id = ?\", (status, int(exit_code), int(run_id)))\nconn.commit()\nconn.close()\nPY\nfi\n", mode: 493 },
  { path: "scripts/cleanup-workdirs.sh", contents: "#!/usr/bin/env bash\n#\n# Cleanup old Smithers workdirs for a VM (immutable runs)\n# Usage: ./cleanup-workdirs.sh <vm-name> [--keep N] [--dry-run]\n#\nset -euo pipefail\n\nVM_NAME=\"${1:?Usage: $0 <vm-name> [--keep N] [--dry-run]}\"\nKEEP_COUNT=5\nDRY_RUN=false\n\nshift\nwhile [[ $# -gt 0 ]]; do\n  case \"$1\" in\n    --keep)\n      KEEP_COUNT=\"${2:-5}\"\n      shift 2\n      ;;\n    --dry-run)\n      DRY_RUN=true\n      shift\n      ;;\n    *)\n      echo \"Unknown option: $1\"\n      exit 1\n      ;;\n  esac\ndone\n\nDB_PATH=\"${RALPH_DB_PATH:-$HOME/.cache/ralph/ralph.db}\"\nDB_DIR=\"$(dirname \"$DB_PATH\")\"\nmkdir -p \"$DB_DIR\"\nchmod 700 \"$DB_DIR\" 2>/dev/null || true\nif [[ -e \"$DB_PATH\" ]]; then\n  chmod 600 \"$DB_PATH\" 2>/dev/null || true\nfi\nif [[ ! -f \"$DB_PATH\" ]]; then\n  echo \"No DB found at $DB_PATH\"\n  exit 0\nfi\n\nWORKDIRS=$(\n  python3 - \"$DB_PATH\" \"$VM_NAME\" \"$KEEP_COUNT\" <<'PY'\nimport sqlite3\nimport sys\n\ndb_path, vm, keep = sys.argv[1:4]\nkeep_n = int(keep)\nconn = sqlite3.connect(db_path)\ncur = conn.execute(\n  \"SELECT workdir FROM runs WHERE vm_name = ? ORDER BY started_at DESC\",\n  (vm,)\n)\nrows = [r[0] for r in cur.fetchall()]\nconn.close()\nfor workdir in rows[keep_n:]:\n  print(workdir)\nPY\n)\n\nif [[ -z \"$WORKDIRS\" ]]; then\n  echo \"Nothing to clean for $VM_NAME (keeping $KEEP_COUNT).\"\n  exit 0\nfi\n\ncase \"$(uname -s)\" in\n  Darwin) OS=\"macos\" ;;\n  Linux)  OS=\"linux\" ;;\n  *)\n    echo \"Unsupported OS\"\n    exit 1\n    ;;\nesac\n\nif [[ \"$OS\" == \"macos\" ]]; then\n  SSH_CMD=(limactl shell \"$VM_NAME\" sudo -u ralph -i --)\nelse\n  VM_IP=$(virsh domifaddr \"$VM_NAME\" 2>/dev/null | grep ipv4 | awk '{print $4}' | cut -d/ -f1)\n  if [[ -z \"$VM_IP\" ]]; then\n    echo \"Error: Could not get VM IP\"\n    exit 1\n  fi\n  SSH_CMD=(ssh \"ralph@${VM_IP}\")\nfi\n\necho \"Cleaning workdirs for $VM_NAME (keeping $KEEP_COUNT):\"\nwhile IFS= read -r workdir; do\n  [[ -z \"$workdir\" ]] && continue\n  case \"$workdir\" in\n    /home/ralph/work/\"$VM_NAME\"/*) ;;\n    *)\n      echo \"Skipping unexpected path: $workdir\"\n      continue\n      ;;\n  esac\n\n  if [[ \"$DRY_RUN\" == \"true\" ]]; then\n    echo \"[dry-run] rm -rf $workdir\"\n  else\n    echo \"rm -rf $workdir\"\n    \"${SSH_CMD[@]}\" bash -c \"rm -rf '$workdir'\"\n  fi\ndone <<< \"$WORKDIRS\"\n", mode: 493 },
  { path: "scripts/record-human-feedback.sh", contents: "#!/usr/bin/env bash\n#\n# Record human feedback for a spec run\n# Usage: ./record-human-feedback.sh --vm <vm> --spec <spec-path> --decision <approve|reject> --notes \"<text>\"\n#\nset -euo pipefail\n\nVM_NAME=\"\"\nSPEC_PATH=\"\"\nDECISION=\"\"\nNOTES=\"\"\n\nwhile [[ $# -gt 0 ]]; do\n  case \"$1\" in\n    --vm)\n      VM_NAME=\"${2:-}\"\n      shift 2\n      ;;\n    --spec)\n      SPEC_PATH=\"${2:-}\"\n      shift 2\n      ;;\n    --decision)\n      DECISION=\"${2:-}\"\n      shift 2\n      ;;\n    --notes)\n      NOTES=\"${2:-}\"\n      shift 2\n      ;;\n    *)\n      echo \"Unknown option: $1\"\n      exit 1\n      ;;\n  esac\ndone\n\nif [[ -z \"$VM_NAME\" || -z \"$SPEC_PATH\" || -z \"$DECISION\" ]]; then\n  echo \"Usage: $0 --vm <vm> --spec <spec-path> --decision <approve|reject> --notes \\\"...\\\"\"\n  exit 1\nfi\n\nSPEC_PATH=$(realpath \"$SPEC_PATH\")\nDB_PATH=\"${RALPH_DB_PATH:-$HOME/.cache/ralph/ralph.db}\"\nDB_DIR=\"$(dirname \"$DB_PATH\")\"\nmkdir -p \"$DB_DIR\"\nchmod 700 \"$DB_DIR\" 2>/dev/null || true\nif [[ -e \"$DB_PATH\" ]]; then\n  chmod 600 \"$DB_PATH\" 2>/dev/null || true\nfi\n\nRUN_INFO=$(\n  python3 - \"$DB_PATH\" \"$VM_NAME\" \"$SPEC_PATH\" <<'PY'\nimport sqlite3\nimport sys\n\ndb_path, vm, spec = sys.argv[1:4]\nconn = sqlite3.connect(db_path)\nconn.execute(\"\"\"\nCREATE TABLE IF NOT EXISTS human_feedback (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  run_id INTEGER,\n  vm_name TEXT NOT NULL,\n  spec_path TEXT NOT NULL,\n  decision TEXT NOT NULL,\n  notes TEXT NOT NULL,\n  created_at TEXT NOT NULL\n)\n\"\"\")\ncur = conn.execute(\n  \"SELECT id, workdir FROM runs WHERE vm_name = ? AND spec_path = ? ORDER BY started_at DESC LIMIT 1\",\n  (vm, spec)\n)\nrow = cur.fetchone()\nif not row:\n  print(\"\")\n  conn.close()\n  sys.exit(0)\nrun_id, workdir = row\nprint(f\"{run_id}|{workdir}\")\nconn.close()\nPY\n)\n\nif [[ -z \"$RUN_INFO\" ]]; then\n  echo \"No run found for vm=$VM_NAME spec=$SPEC_PATH\"\n  exit 1\nfi\n\nRUN_ID=\"${RUN_INFO%%|*}\"\nWORKDIR=\"${RUN_INFO#*|}\"\n\npython3 - \"$DB_PATH\" \"$RUN_ID\" \"$VM_NAME\" \"$SPEC_PATH\" \"$DECISION\" \"$NOTES\" <<'PY'\nimport sqlite3\nimport sys\nfrom datetime import datetime, timezone\n\ndb_path, run_id, vm, spec, decision, notes = sys.argv[1:7]\nconn = sqlite3.connect(db_path)\nconn.execute(\n  \"INSERT INTO human_feedback (run_id, vm_name, spec_path, decision, notes, created_at) VALUES (?, ?, ?, ?, ?, ?)\",\n  (int(run_id), vm, spec, decision, notes, datetime.now(timezone.utc).isoformat())\n)\nconn.commit()\nconn.close()\nPY\n\ncase \"$(uname -s)\" in\n  Darwin) OS=\"macos\" ;;\n  Linux)  OS=\"linux\" ;;\n  *)\n    echo \"Unsupported OS\"\n    exit 1\n    ;;\nesac\n\nif [[ \"$OS\" == \"macos\" ]]; then\n  SSH_CMD=(limactl shell \"$VM_NAME\" sudo -u ralph -i --)\nelse\n  VM_IP=$(virsh domifaddr \"$VM_NAME\" 2>/dev/null | grep ipv4 | awk '{print $4}' | cut -d/ -f1)\n  if [[ -z \"$VM_IP\" ]]; then\n    echo \"Error: Could not get VM IP\"\n    exit 1\n  fi\n  SSH_CMD=(ssh \"ralph@${VM_IP}\")\nfi\n\nJSON=$(python3 - \"$DECISION\" \"$NOTES\" <<'PY'\nimport json\nimport sys\n\ndecision, notes = sys.argv[1:3]\nprint(json.dumps({\"v\": 1, \"decision\": decision, \"notes\": notes}, indent=2))\nPY\n)\n\n\"${SSH_CMD[@]}\" bash -c \"mkdir -p '$WORKDIR/reports' && cat > '$WORKDIR/reports/human-feedback.json' <<'EOF'\n$JSON\nEOF\"\n\necho \"Recorded human feedback for run $RUN_ID.\"\n", mode: 493 },
  { path: "scripts/smithers-fleet.sh", contents: "#!/usr/bin/env bash\n#\n# Start multiple Smithers workflows (one per VM)\n# Usage: ./smithers-fleet.sh <specs-dir> <vm-prefix>\n#\n# Expects specs-dir structure:\n#   specs/\n#     001-foo.min.json\n#     001-foo.todo.min.json\n#     002-bar.min.json\n#     002-bar.todo.min.json\n#\n# Example:\n#   ./scripts/smithers-fleet.sh specs ralph\n#\nset -euo pipefail\n\nSPECS_DIR=\"${1:?Usage: $0 <specs-dir> <vm-prefix>}\"\nVM_PREFIX=\"${2:?Usage: $0 <specs-dir> <vm-prefix>}\"\nSPECS_DIR=$(realpath \"$SPECS_DIR\")\n\nSPECS=()\nfor spec in \"$SPECS_DIR\"/*.min.json; do\n  if [[ \"$spec\" == *.todo.min.json ]]; then\n    continue\n  fi\n  base=\"${spec%.min.json}\"\n  todo=\"${base}.todo.min.json\"\n  if [[ -f \"$todo\" ]]; then\n    SPECS+=(\"$spec\")\n  fi\ndone\n\nif [[ ${#SPECS[@]} -eq 0 ]]; then\n  echo \"No spec/todo pairs found in $SPECS_DIR\"\n  exit 1\nfi\n\ncase \"$(uname -s)\" in\n  Darwin) OS=\"macos\" ;;\n  Linux)  OS=\"linux\" ;;\n  *)\n    echo \"Unsupported OS\"\n    exit 1\n    ;;\nesac\n\nif [[ \"$OS\" == \"macos\" ]]; then\n  VMS=($(limactl list --format '{{.Name}}' 2>/dev/null | grep -E \"^${VM_PREFIX}\" || true))\nelse\n  VMS=($(virsh list --all --name 2>/dev/null | grep -E \"^${VM_PREFIX}\" || true))\nfi\n\nif [[ ${#VMS[@]} -eq 0 ]]; then\n  echo \"No VMs found with prefix '$VM_PREFIX'.\"\n  exit 1\nfi\n\necho \"Found ${#SPECS[@]} specs and ${#VMS[@]} VMs.\"\necho \"\"\n\nfor i in \"${!SPECS[@]}\"; do\n  if [[ $i -ge ${#VMS[@]} ]]; then\n    echo \"Warning: More specs than VMs. Skipping: ${SPECS[$i]}\"\n    continue\n  fi\n\n  VM=\"${VMS[$i]}\"\n  SPEC=\"${SPECS[$i]}\"\n  echo \"Dispatching $(basename \"$SPEC\") -> $VM\"\n  ./scripts/dispatch.sh --spec \"$SPEC\" \"$VM\" \"$SPEC\"\ndone\n", mode: 493 },
  { path: "scripts/smithers-spec-runner.tsx", contents: "#!/usr/bin/env smithers\n/** @jsxImportSource smithers-orchestrator */\nimport { readFileSync, mkdirSync, writeFileSync, existsSync, readdirSync } from \"node:fs\"\nimport { basename, join, resolve } from \"node:path\"\nimport * as Orchestrator from \"smithers-orchestrator\"\n\ntype Spec = {\n  id: string\n  title: string\n  goals: string[]\n  nonGoals: string[]\n  req: {\n    api: string[]\n    behavior: string[]\n    obs: string[]\n  }\n  accept: string[]\n  assume: string[]\n}\n\ntype TodoTask = { id: string; do: string; verify: string }\ntype Todo = { id: string; tdd: boolean; dod: string[]; tasks: TodoTask[] }\n\ntype Report = {\n  v: number\n  taskId: string\n  status: \"done\" | \"blocked\" | \"failed\"\n  work: string[]\n  files: string[]\n  tests: string[]\n  issues: string[]\n  next: string[]\n}\n\ntype Review = {\n  v: number\n  status: \"approved\" | \"changes_requested\"\n  issues: string[]\n  next: string[]\n}\n\ntype HumanGate = {\n  v: number\n  status: \"blocked\"\n  reason: string\n}\n\ntype ReviewTask = {\n  id: string\n  do: string\n  verify: string\n}\n\nconst {\n  createSmithersRoot,\n  createSmithersDB,\n  SmithersProvider,\n  Ralph,\n  Claude,\n  Codex,\n  If,\n  useSmithers,\n  useQueryValue\n} = Orchestrator\n\nconst OpenCodeComponent = Orchestrator.OpenCode ?? Codex\n\nconst env = process.env\nconst specPath = resolve(env.SMITHERS_SPEC_PATH ?? env.SPEC_PATH ?? \"specs/000-base.min.json\")\nconst todoPath = resolve(env.SMITHERS_TODO_PATH ?? env.TODO_PATH ?? \"specs/000-base.todo.min.json\")\nconst reportDir = resolve(env.SMITHERS_REPORT_DIR ?? env.REPORT_DIR ?? \"reports\")\nconst promptPath = env.SMITHERS_PROMPT_PATH\nconst reviewPromptPath = env.SMITHERS_REVIEW_PROMPT_PATH\nconst reviewersDir = env.SMITHERS_REVIEWERS_DIR\nconst reviewModelsPath = env.SMITHERS_REVIEW_MODELS_FILE\nconst execCwd = env.SMITHERS_CWD ? resolve(env.SMITHERS_CWD) : process.cwd()\nconst agentKind = (env.SMITHERS_AGENT ?? env.RALPH_AGENT ?? \"codex\").toLowerCase()\nconst model =\n  env.SMITHERS_MODEL ??\n  env.MODEL ??\n  (agentKind === \"codex\" ? \"gpt-5.2-codex\" : \"opus\")\nconst maxIterations = Number(env.SMITHERS_MAX_ITERATIONS ?? env.MAX_ITERATIONS ?? 100)\nconst runReview = true\nconst reviewMax = Number(env.SMITHERS_REVIEW_MAX ?? 2)\n\nif (!Orchestrator.OpenCode && agentKind === \"opencode\") {\n  console.log(\"[WARN] OpenCode export missing; falling back to Codex for opencode.\")\n}\n\nconst spec = JSON.parse(readFileSync(specPath, \"utf8\")) as Spec\nconst todo = JSON.parse(readFileSync(todoPath, \"utf8\")) as Todo\n\nconst smithersDir = resolve(\".smithers\")\nif (!existsSync(smithersDir)) {\n  mkdirSync(smithersDir, { recursive: true })\n}\nconst db = createSmithersDB({ path: join(smithersDir, `${spec.id}.db`) })\nconst executionId = db.execution.start(`${spec.id}: ${spec.title}`, basename(specPath))\n\nif (!existsSync(reportDir)) {\n  mkdirSync(reportDir, { recursive: true })\n}\n\nconst systemPrompt = [\n  `Spec ID: ${spec.id}`,\n  `Title: ${spec.title}`,\n  \"\",\n  \"Goals:\",\n  ...spec.goals.map((g) => `- ${g}`),\n  \"\",\n  \"Non-goals:\",\n  ...spec.nonGoals.map((g) => `- ${g}`),\n  \"\",\n  \"API requirements:\",\n  ...spec.req.api.map((r) => `- ${r}`),\n  \"\",\n  \"Behavior requirements:\",\n  ...spec.req.behavior.map((r) => `- ${r}`),\n  \"\",\n  \"Observability requirements:\",\n  ...spec.req.obs.map((r) => `- ${r}`),\n  \"\",\n  \"Acceptance criteria:\",\n  ...spec.accept.map((a) => `- ${a}`),\n  \"\",\n  \"Assumptions:\",\n  ...spec.assume.map((a) => `- ${a}`),\n  \"\",\n  `TDD required: ${todo.tdd ? \"yes\" : \"no\"}`,\n  \"Definition of done:\",\n  ...todo.dod.map((d) => `- ${d}`)\n].join(\"\\n\")\n\nconst loadPrompt = (path?: string): string => {\n  if (!path) return \"\"\n  try {\n    if (!existsSync(path)) return \"\"\n    return readFileSync(path, \"utf8\").trim()\n  } catch {\n    return \"\"\n  }\n}\n\nconst globalPrompt = loadPrompt(promptPath)\nconst reviewerPrompt = loadPrompt(reviewPromptPath)\n\nconst loadReviewModels = (): Record<string, string> => {\n  if (!reviewModelsPath) return {}\n  try {\n    if (!existsSync(reviewModelsPath)) return {}\n    const raw = readFileSync(reviewModelsPath, \"utf8\")\n    const parsed = JSON.parse(raw)\n    if (!parsed || typeof parsed !== \"object\") return {}\n    const map: Record<string, string> = {}\n    for (const [key, value] of Object.entries(parsed)) {\n      if (typeof value === \"string\") {\n        map[key.toLowerCase()] = value\n      }\n    }\n    return map\n  } catch {\n    return {}\n  }\n}\n\nconst reviewModels = loadReviewModels()\nconst reviewDefaultModel =\n  reviewModels._default ?? reviewModels.default ?? reviewModels[\"*\"] ?? model\n\nconst reviewModelFor = (id: string) =>\n  reviewModels[id.toLowerCase()] ?? reviewDefaultModel\n\nconst codexDefaults = {\n  reasoningEffort: \"medium\",\n  sandboxMode: \"danger-full-access\",\n  skipGitRepoCheck: true\n} as const\n\ntype Reviewer = {\n  id: string\n  title: string\n  prompt: string\n}\n\nconst defaultReviewers: Reviewer[] = [\n  { id: \"security\", title: \"Security\", prompt: \"\" },\n  { id: \"code-quality\", title: \"Code Quality\", prompt: \"\" },\n  { id: \"simplicity\", title: \"Minimal Simplicity\", prompt: \"\" },\n  { id: \"test-coverage\", title: \"Test Coverage\", prompt: \"\" },\n  { id: \"maintainability\", title: \"Maintainability\", prompt: \"\" }\n]\n\nconst loadReviewers = (): Reviewer[] => {\n  if (!reviewersDir || !existsSync(reviewersDir)) return defaultReviewers\n  const files = readdirSync(reviewersDir).filter((f) => f.toLowerCase().endsWith(\".md\"))\n  if (files.length === 0) return defaultReviewers\n  return files.map((file) => {\n    const id = file.replace(/\\.md$/i, \"\").toLowerCase()\n    const title = file.replace(/\\.md$/i, \"\").replace(/[-_]/g, \" \")\n    const prompt = loadPrompt(join(reviewersDir, file))\n    return { id, title, prompt }\n  })\n}\n\nconst reviewers = loadReviewers()\n\ntype ReviewResult = Review & { reviewer: string }\n\nconst writeReviewerResult = (reviewerId: string, review: Review) => {\n  const payload: ReviewResult = { ...review, reviewer: reviewerId }\n  const path = join(reportDir, `review-${reviewerId}.json`)\n  writeFileSync(path, `${JSON.stringify(payload, null, 2)}\\n`, \"utf8\")\n}\n\nconst combineReviews = (): Review => {\n  const reviews: Review[] = []\n  for (const reviewer of reviewers) {\n    const path = join(reportDir, `review-${reviewer.id}.json`)\n    if (!existsSync(path)) continue\n    try {\n      const raw = readFileSync(path, \"utf8\")\n      reviews.push(JSON.parse(raw) as Review)\n    } catch {\n      continue\n    }\n  }\n  const issues = reviews.flatMap((r) => r.issues ?? [])\n  const next = reviews.flatMap((r) => r.next ?? [])\n  const status = reviews.every((r) => r.status === \"approved\") ? \"approved\" : \"changes_requested\"\n  return { v: 1, status, issues, next }\n}\n\nconst buildReviewTasks = (): ReviewTask[] => {\n  const tasks: ReviewTask[] = []\n  for (const reviewer of reviewers) {\n    const path = join(reportDir, `review-${reviewer.id}.json`)\n    if (!existsSync(path)) continue\n    try {\n      const raw = readFileSync(path, \"utf8\")\n      const review = JSON.parse(raw) as Review\n      const items = [...(review.issues ?? []), ...(review.next ?? [])].filter(Boolean)\n      items.forEach((item, index) => {\n        tasks.push({\n          id: `review-${reviewer.id}-${index + 1}`,\n          do: `[${reviewer.title}] ${item}`,\n          verify: \"Update code/tests and verify relevant tests pass.\"\n        })\n      })\n    } catch {\n      continue\n    }\n  }\n  return tasks\n}\n\nconst defaultReport = (taskId: string, status: Report[\"status\"]): Report => ({\n  v: 1,\n  taskId,\n  status,\n  work: [],\n  files: [],\n  tests: [],\n  issues: [],\n  next: []\n})\n\nconst parseReport = (taskId: string, output?: string): Report => {\n  if (!output) {\n    return defaultReport(taskId, \"failed\")\n  }\n  const match = output.match(/\\{[\\s\\S]*\\}/)\n  if (!match) {\n    return defaultReport(taskId, \"failed\")\n  }\n  try {\n    const parsed = JSON.parse(match[0]) as Report\n    if (!parsed.taskId) parsed.taskId = taskId\n    if (!parsed.status) parsed.status = \"failed\"\n    if (!parsed.work) parsed.work = []\n    if (!parsed.files) parsed.files = []\n    if (!parsed.tests) parsed.tests = []\n    if (!parsed.issues) parsed.issues = []\n    if (!parsed.next) parsed.next = []\n    if (parsed.v !== 1) parsed.v = 1\n    return parsed\n  } catch {\n    return defaultReport(taskId, \"failed\")\n  }\n}\n\nconst writeReport = (report: Report) => {\n  const path = join(reportDir, `${report.taskId}.report.json`)\n  writeFileSync(path, `${JSON.stringify(report, null, 2)}\\n`, \"utf8\")\n}\n\nconst defaultReview = (status: Review[\"status\"]): Review => ({\n  v: 1,\n  status,\n  issues: [],\n  next: []\n})\n\nconst parseReview = (output?: string): Review => {\n  if (!output) {\n    return defaultReview(\"changes_requested\")\n  }\n  const match = output.match(/\\{[\\s\\S]*\\}/)\n  if (!match) {\n    return defaultReview(\"changes_requested\")\n  }\n  try {\n    const parsed = JSON.parse(match[0]) as Review\n    if (!parsed.status) parsed.status = \"changes_requested\"\n    if (!parsed.issues) parsed.issues = []\n    if (!parsed.next) parsed.next = []\n    if (parsed.v !== 1) parsed.v = 1\n    return parsed\n  } catch {\n    return defaultReview(\"changes_requested\")\n  }\n}\n\nconst writeReview = (review: Review) => {\n  const path = join(reportDir, \"review.json\")\n  writeFileSync(path, `${JSON.stringify(review, null, 2)}\\n`, \"utf8\")\n}\n\nconst writeHumanGate = (reason: string) => {\n  const gate: HumanGate = { v: 1, status: \"blocked\", reason }\n  const path = join(reportDir, \"human-gate.json\")\n  writeFileSync(path, `${JSON.stringify(gate, null, 2)}\\n`, \"utf8\")\n}\n\nconst writeReviewTodo = (tasks: ReviewTask[]) => {\n  const path = join(reportDir, \"review-todo.json\")\n  writeFileSync(path, `${JSON.stringify({ v: 1, tasks }, null, 2)}\\n`, \"utf8\")\n}\n\nconst readReviewTodo = (): ReviewTask[] => {\n  const path = join(reportDir, \"review-todo.json\")\n  if (!existsSync(path)) return []\n  try {\n    const raw = readFileSync(path, \"utf8\")\n    const json = JSON.parse(raw) as { tasks?: ReviewTask[] }\n    return Array.isArray(json.tasks) ? json.tasks : []\n  } catch {\n    return []\n  }\n}\n\nconst readReports = (): string => {\n  try {\n    if (!existsSync(reportDir)) return \"No reports found.\"\n    const entries = readFileSync(join(reportDir, \".index\"), \"utf8\")\n    return entries\n  } catch {\n    try {\n      const files = readdirSync(reportDir)\n      const reportFiles = files.filter((f) => f.endsWith(\".report.json\"))\n      const summaries = reportFiles.slice(0, 20).map((f) => {\n        const raw = readFileSync(join(reportDir, f), \"utf8\")\n        return `${f}:\\n${raw}`\n      })\n      return summaries.length > 0 ? summaries.join(\"\\n\\n\") : \"No reports found.\"\n    } catch {\n      return \"No reports found.\"\n    }\n  }\n}\n\nfunction TaskRunner() {\n  const { db, reactiveDb } = useSmithers()\n  const { data: indexRaw } = useQueryValue<number>(\n    reactiveDb,\n    \"SELECT CAST(value AS INTEGER) FROM state WHERE key = 'task.index'\"\n  )\n  const { data: doneRaw } = useQueryValue<number>(\n    reactiveDb,\n    \"SELECT CAST(value AS INTEGER) FROM state WHERE key = 'task.done'\"\n  )\n  const { data: phaseRaw } = useQueryValue<string>(\n    reactiveDb,\n    \"SELECT value FROM state WHERE key = 'phase'\"\n  )\n  const { data: reviewIndexRaw } = useQueryValue<number>(\n    reactiveDb,\n    \"SELECT CAST(value AS INTEGER) FROM state WHERE key = 'review.index'\"\n  )\n  const { data: reviewRetryRaw } = useQueryValue<number>(\n    reactiveDb,\n    \"SELECT CAST(value AS INTEGER) FROM state WHERE key = 'review.retry'\"\n  )\n  const { data: reviewTaskIndexRaw } = useQueryValue<number>(\n    reactiveDb,\n    \"SELECT CAST(value AS INTEGER) FROM state WHERE key = 'review.task.index'\"\n  )\n  const index = indexRaw ?? 0\n  const done = Boolean(doneRaw ?? 0)\n  const phase = phaseRaw ?? \"tasks\"\n  const reviewIndex = reviewIndexRaw ?? 0\n  const reviewRetry = reviewRetryRaw ?? 0\n  const reviewTaskIndex = reviewTaskIndexRaw ?? 0\n\n  if (phase === \"review\") {\n    const reviewer = reviewers[reviewIndex]\n    if (!reviewer) {\n      const combined = combineReviews()\n      if (combined.status === \"approved\") {\n        writeReview(combined)\n        writeHumanGate(\"Human review required before next spec run.\")\n        db.state.set(\"phase\", \"done\", \"review_done\")\n        db.state.set(\"task.done\", 1, \"review_done\")\n        return <review status=\"complete\" />\n      }\n\n      if (reviewRetry >= reviewMax) {\n        writeReview(combined)\n        writeHumanGate(\"Reviewers requested changes. Max retries reached; human decision required.\")\n        db.state.set(\"phase\", \"done\", \"review_done\")\n        db.state.set(\"task.done\", 1, \"review_done\")\n        return <review status=\"complete\" />\n      }\n\n      const reviewTasks = buildReviewTasks()\n      writeReviewTodo(reviewTasks)\n      db.state.set(\"review.retry\", reviewRetry + 1, \"review_retry\")\n      db.state.set(\"review.task.index\", 0, \"review_task_start\")\n      db.state.set(\"phase\", \"review-tasks\", \"review_task_start\")\n      return <review status=\"review-tasks\" />\n    }\n    const prompt = [\n      reviewerPrompt,\n      reviewer.prompt,\n      systemPrompt,\n      \"\",\n      `Reviewer: ${reviewer.title}`,\n      \"Review the implementation against the spec, todo, and task reports.\",\n      \"Focus on correctness, tests, security, and strict spec compliance.\",\n      \"Verify changes were pushed (jj git push --change @) if applicable.\",\n      \"\",\n      \"Reports:\",\n      readReports(),\n      \"\",\n      \"Output:\",\n      \"Return a single JSON object that matches this schema:\",\n      JSON.stringify(\n        {\n          v: 1,\n          status: \"approved | changes_requested\",\n          issues: [\"...\"],\n          next: [\"...\"]\n        },\n        null,\n        2\n      )\n    ]\n      .filter((line) => line !== \"\")\n      .join(\"\\n\")\n\n    const handleReviewFinished = (result: { output?: string }) => {\n      const review = parseReview(result.output)\n      writeReviewerResult(reviewer.id, review)\n      db.state.set(\"review.index\", reviewIndex + 1, \"review_advance\")\n    }\n\n    const defaultProps = { onFinished: handleReviewFinished } as const\n    const claudeProps = { ...defaultProps, model: reviewModelFor(reviewer.id) } as const\n    const codexProps = {\n      ...defaultProps,\n      model: reviewModelFor(reviewer.id),\n      ...codexDefaults,\n      cwd: execCwd\n    } as const\n    const openCodeProps = { ...defaultProps, model: reviewModelFor(reviewer.id) } as const\n\n    return (\n      <review status=\"running\">\n        <If condition={agentKind === \"claude\"}>\n          <Claude {...claudeProps}>{prompt}</Claude>\n        </If>\n        <If condition={agentKind === \"codex\"}>\n          <Codex {...codexProps}>{prompt}</Codex>\n        </If>\n        <If condition={agentKind === \"opencode\"}>\n          <OpenCodeComponent {...openCodeProps}>{prompt}</OpenCodeComponent>\n        </If>\n      </review>\n    )\n  }\n\n  if (phase === \"review-tasks\") {\n    const reviewTasks = readReviewTodo()\n    if (reviewTasks.length === 0) {\n      writeHumanGate(\"Reviewer changes requested but no tasks were generated. Human decision required.\")\n      db.state.set(\"phase\", \"done\", \"review_done\")\n      db.state.set(\"task.done\", 1, \"review_done\")\n      return <review status=\"review-tasks-empty\" />\n    }\n\n    const task = reviewTasks[reviewTaskIndex]\n    if (!task) {\n      db.state.set(\"phase\", \"review\", \"review_restart\")\n      db.state.set(\"review.index\", 0, \"review_restart\")\n      return <review status=\"review-restart\" />\n    }\n\n    const prompt = [\n      globalPrompt,\n      systemPrompt,\n      \"\",\n      `Review Task ${reviewTaskIndex + 1}/${reviewTasks.length}: ${task.id}`,\n      \"\",\n      \"Do:\",\n      task.do,\n      \"\",\n      \"Verify:\",\n      task.verify,\n      \"\",\n      \"Version control:\",\n      \"- Use jj (not git).\",\n      \"- Create a new change before work: `jj new main`.\",\n      \"- Update the change description with `jj describe`.\",\n      \"- Push with `jj git push --change @` when ready.\",\n      \"\",\n      \"Output:\",\n      \"Return a single JSON object that matches this schema:\",\n      JSON.stringify(\n        {\n          v: 1,\n          taskId: task.id,\n          status: \"done | blocked | failed\",\n          work: [\"...\"],\n          files: [\"...\"],\n          tests: [\"...\"],\n          issues: [\"...\"],\n          next: [\"...\"]\n        },\n        null,\n        2\n      )\n    ]\n      .filter((line) => line !== \"\")\n      .join(\"\\n\")\n\n    const handleFinished = (result: { output?: string }) => {\n      const report = parseReport(task.id, result.output)\n      writeReport(report)\n\n      if (report.status !== \"done\") {\n        db.state.set(\"task.done\", 1, \"review_task_failed\")\n        db.state.set(\"phase\", \"done\", \"review_task_failed\")\n        return\n      }\n\n      db.state.set(\"review.task.index\", reviewTaskIndex + 1, \"review_task_advance\")\n    }\n\n    const defaultProps = { onFinished: handleFinished } as const\n    const claudeProps = { ...defaultProps, model } as const\n    const codexProps = { ...defaultProps, model, ...codexDefaults, cwd: execCwd } as const\n    const openCodeProps = { ...defaultProps, model } as const\n\n    return (\n      <review-task id={task.id} index={reviewTaskIndex}>\n        <If condition={agentKind === \"claude\"}>\n          <Claude {...claudeProps}>{prompt}</Claude>\n        </If>\n        <If condition={agentKind === \"codex\"}>\n          <Codex {...codexProps}>{prompt}</Codex>\n        </If>\n        <If condition={agentKind === \"opencode\"}>\n          <OpenCodeComponent {...openCodeProps}>{prompt}</OpenCodeComponent>\n        </If>\n      </review-task>\n    )\n  }\n\n  if (done || index >= todo.tasks.length) {\n    if (!done) {\n      db.state.set(\"task.done\", 1, \"complete\")\n    }\n    if (runReview) {\n      db.state.set(\"phase\", \"review\", \"review_start\")\n      return <review status=\"pending\" />\n    }\n    db.state.set(\"phase\", \"done\", \"complete\")\n    return <done status=\"complete\" />\n  }\n\n  const task = todo.tasks[index]\n  const prompt = [\n    globalPrompt,\n    systemPrompt,\n    \"\",\n    `Task ${index + 1}/${todo.tasks.length}: ${task.id}`,\n    \"\",\n    \"Do:\",\n    task.do,\n    \"\",\n    \"Verify:\",\n    task.verify,\n    \"\",\n    \"Version control:\",\n    \"- Use jj (not git).\",\n    \"- Create a new change before work: `jj new main`.\",\n    \"- Update the change description with `jj describe`.\",\n    \"- Push with `jj git push --change @` when ready.\",\n    \"\",\n    \"Output:\",\n    \"Return a single JSON object that matches this schema:\",\n    JSON.stringify(\n      {\n        v: 1,\n        taskId: task.id,\n        status: \"done | blocked | failed\",\n        work: [\"...\"],\n        files: [\"...\"],\n        tests: [\"...\"],\n        issues: [\"...\"],\n        next: [\"...\"]\n      },\n      null,\n      2\n    )\n  ]\n    .filter((line) => line !== \"\")\n    .join(\"\\n\")\n\n  const handleFinished = (result: { output?: string }) => {\n    const report = parseReport(task.id, result.output)\n    writeReport(report)\n\n    if (report.status === \"blocked\") {\n      db.state.set(\"task.blocked\", 1, \"blocked\")\n      db.state.set(\"task.done\", 1, \"blocked\")\n      db.state.set(\"phase\", \"done\", \"blocked\")\n      return\n    }\n\n    if (report.status === \"failed\") {\n      db.state.set(\"task.failed\", 1, \"failed\")\n      db.state.set(\"task.done\", 1, \"failed\")\n      db.state.set(\"phase\", \"done\", \"failed\")\n      return\n    }\n\n    db.state.set(\"task.index\", index + 1, \"advance\")\n    if (index + 1 >= todo.tasks.length) {\n      db.state.set(\"task.done\", 1, \"complete\")\n    }\n  }\n\n  const defaultProps = { onFinished: handleFinished } as const\n  const claudeProps = { ...defaultProps, model } as const\n  const codexProps = { ...defaultProps, model, ...codexDefaults, cwd: execCwd } as const\n  const openCodeProps = { ...defaultProps, model } as const\n\n  return (\n    <task id={task.id} index={index}>\n      <If condition={agentKind === \"claude\"}>\n        <Claude {...claudeProps}>{prompt}</Claude>\n      </If>\n      <If condition={agentKind === \"codex\"}>\n        <Codex {...codexProps}>{prompt}</Codex>\n      </If>\n      <If condition={agentKind === \"opencode\"}>\n        <OpenCodeComponent {...openCodeProps}>{prompt}</OpenCodeComponent>\n      </If>\n    </task>\n  )\n}\n\nfunction SpecWorkflowInner() {\n  const { reactiveDb } = useSmithers()\n  const { data: doneRaw } = useQueryValue<number>(\n    reactiveDb,\n    \"SELECT CAST(value AS INTEGER) FROM state WHERE key = 'task.done'\"\n  )\n  const done = Boolean(doneRaw ?? 0)\n\n  return (\n    <Ralph id=\"spec-ralph\" condition={() => !done} maxIterations={maxIterations}>\n      <TaskRunner />\n    </Ralph>\n  )\n}\n\nfunction SpecWorkflow() {\n  return (\n    <SmithersProvider db={db} executionId={executionId}>\n      <SpecWorkflowInner />\n    </SmithersProvider>\n  )\n}\n\nconst root = createSmithersRoot()\ntry {\n  await root.mount(SpecWorkflow)\n  db.execution.complete(executionId, { summary: \"Spec workflow complete\" })\n} catch (error) {\n  db.execution.fail(executionId, String(error))\n  throw error\n} finally {\n  db.close()\n}\n" },
  { path: "scripts/smithers-reviewer.tsx", contents: "#!/usr/bin/env smithers\n/** @jsxImportSource smithers-orchestrator */\nimport { readFileSync, mkdirSync, writeFileSync, existsSync, readdirSync } from \"node:fs\"\nimport { join, resolve, basename } from \"node:path\"\nimport * as Orchestrator from \"smithers-orchestrator\"\n\ntype Spec = {\n  id: string\n  title: string\n  goals: string[]\n  nonGoals: string[]\n  req: { api: string[]; behavior: string[]; obs: string[] }\n  accept: string[]\n  assume: string[]\n}\n\ntype Review = {\n  v: number\n  status: \"approved\" | \"changes_requested\"\n  issues: string[]\n  next: string[]\n}\n\nconst {\n  createSmithersRoot,\n  createSmithersDB,\n  SmithersProvider,\n  Ralph,\n  Claude,\n  Codex,\n  If,\n  useSmithers,\n  useQueryValue\n} = Orchestrator\n\nconst OpenCodeComponent = Orchestrator.OpenCode ?? Codex\n\nconst env = process.env\nconst specPath = resolve(env.SMITHERS_SPEC_PATH ?? env.SPEC_PATH ?? \"specs/000-base.min.json\")\nconst todoPath = resolve(env.SMITHERS_TODO_PATH ?? env.TODO_PATH ?? \"specs/000-base.todo.min.json\")\nconst reportDir = resolve(env.SMITHERS_REPORT_DIR ?? env.REPORT_DIR ?? \"reports\")\nconst reviewPromptPath = env.SMITHERS_REVIEW_PROMPT_PATH\nconst agentKind = (env.SMITHERS_AGENT ?? env.RALPH_AGENT ?? \"codex\").toLowerCase()\nconst execCwd = env.SMITHERS_CWD ? resolve(env.SMITHERS_CWD) : process.cwd()\nconst model =\n  env.SMITHERS_MODEL ??\n  env.MODEL ??\n  (agentKind === \"codex\" ? \"gpt-5.2-codex\" : \"opus\")\nconst maxIterations = Number(env.SMITHERS_MAX_ITERATIONS ?? env.MAX_ITERATIONS ?? 3)\n\nif (!Orchestrator.OpenCode && agentKind === \"opencode\") {\n  console.log(\"[WARN] OpenCode export missing; falling back to Codex for opencode.\")\n}\n\nconst spec = JSON.parse(readFileSync(specPath, \"utf8\")) as Spec\n\nconst smithersDir = resolve(\".smithers\")\nif (!existsSync(smithersDir)) {\n  mkdirSync(smithersDir, { recursive: true })\n}\nconst db = createSmithersDB({ path: join(smithersDir, `${spec.id}.review.db`) })\nconst executionId = db.execution.start(`${spec.id}: review`, basename(specPath))\n\nif (!existsSync(reportDir)) {\n  mkdirSync(reportDir, { recursive: true })\n}\n\nconst systemPrompt = [\n  `Spec ID: ${spec.id}`,\n  `Title: ${spec.title}`,\n  \"\",\n  \"Goals:\",\n  ...spec.goals.map((g) => `- ${g}`),\n  \"\",\n  \"Non-goals:\",\n  ...spec.nonGoals.map((g) => `- ${g}`),\n  \"\",\n  \"API requirements:\",\n  ...spec.req.api.map((r) => `- ${r}`),\n  \"\",\n  \"Behavior requirements:\",\n  ...spec.req.behavior.map((r) => `- ${r}`),\n  \"\",\n  \"Observability requirements:\",\n  ...spec.req.obs.map((r) => `- ${r}`),\n  \"\",\n  \"Acceptance criteria:\",\n  ...spec.accept.map((a) => `- ${a}`),\n  \"\",\n  \"Assumptions:\",\n  ...spec.assume.map((a) => `- ${a}`)\n].join(\"\\n\")\n\nconst loadPrompt = (path?: string): string => {\n  if (!path) return \"\"\n  try {\n    if (!existsSync(path)) return \"\"\n    return readFileSync(path, \"utf8\").trim()\n  } catch {\n    return \"\"\n  }\n}\n\nconst reviewerPrompt = loadPrompt(reviewPromptPath)\n\nconst codexDefaults = {\n  reasoningEffort: \"medium\",\n  sandboxMode: \"danger-full-access\",\n  skipGitRepoCheck: true\n} as const\n\nconst readReports = (): string => {\n  try {\n    const files = readdirSync(reportDir)\n    const reportFiles = files.filter((f) => f.endsWith(\".report.json\"))\n    const summaries = reportFiles.slice(0, 30).map((f) => {\n      const raw = readFileSync(join(reportDir, f), \"utf8\")\n      return `${f}:\\n${raw}`\n    })\n    return summaries.length > 0 ? summaries.join(\"\\n\\n\") : \"No reports found.\"\n  } catch {\n    return \"No reports found.\"\n  }\n}\n\nconst defaultReview = (status: Review[\"status\"]): Review => ({\n  v: 1,\n  status,\n  issues: [],\n  next: []\n})\n\nconst parseReview = (output?: string): Review => {\n  if (!output) return defaultReview(\"changes_requested\")\n  const match = output.match(/\\{[\\s\\S]*\\}/)\n  if (!match) return defaultReview(\"changes_requested\")\n  try {\n    const parsed = JSON.parse(match[0]) as Review\n    if (!parsed.status) parsed.status = \"changes_requested\"\n    if (!parsed.issues) parsed.issues = []\n    if (!parsed.next) parsed.next = []\n    if (parsed.v !== 1) parsed.v = 1\n    return parsed\n  } catch {\n    return defaultReview(\"changes_requested\")\n  }\n}\n\nconst writeReview = (review: Review) => {\n  const path = join(reportDir, \"review.json\")\n  writeFileSync(path, `${JSON.stringify(review, null, 2)}\\n`, \"utf8\")\n}\n\nfunction ReviewRunner() {\n  const { db, reactiveDb } = useSmithers()\n  const { data: doneRaw } = useQueryValue<number>(\n    reactiveDb,\n    \"SELECT CAST(value AS INTEGER) FROM state WHERE key = 'review.done'\"\n  )\n  const done = Boolean(doneRaw ?? 0)\n\n  if (done) {\n    return <done status=\"reviewed\" />\n  }\n\n  const prompt = [\n    reviewerPrompt,\n    systemPrompt,\n    \"\",\n    \"Review the implementation against the spec, todo, and task reports.\",\n    \"Focus on correctness, tests, security, and strict spec compliance.\",\n    \"Verify changes were pushed (jj git push --change @) if applicable.\",\n    \"\",\n    \"Reports:\",\n    readReports(),\n    \"\",\n    \"Output:\",\n    \"Return a single JSON object that matches this schema:\",\n    JSON.stringify(\n      {\n        v: 1,\n        status: \"approved | changes_requested\",\n        issues: [\"...\"],\n        next: [\"...\"]\n      },\n      null,\n      2\n    )\n  ]\n    .filter((line) => line !== \"\")\n    .join(\"\\n\")\n\n  const handleFinished = (result: { output?: string }) => {\n    const review = parseReview(result.output)\n    writeReview(review)\n    db.state.set(\"review.done\", 1, \"review_done\")\n  }\n\n  const defaultProps = { onFinished: handleFinished } as const\n  const claudeProps = { ...defaultProps, model } as const\n  const codexProps = { ...defaultProps, model, ...codexDefaults, cwd: execCwd } as const\n  const openCodeProps = { ...defaultProps, model } as const\n\n  return (\n    <review status=\"running\">\n      <If condition={agentKind === \"claude\"}>\n        <Claude {...claudeProps}>{prompt}</Claude>\n      </If>\n      <If condition={agentKind === \"codex\"}>\n        <Codex {...codexProps}>{prompt}</Codex>\n      </If>\n        <If condition={agentKind === \"opencode\"}>\n          <OpenCodeComponent {...openCodeProps}>{prompt}</OpenCodeComponent>\n        </If>\n    </review>\n  )\n}\n\nfunction ReviewWorkflowInner() {\n  const { reactiveDb } = useSmithers()\n  const { data: doneRaw } = useQueryValue<number>(\n    reactiveDb,\n    \"SELECT CAST(value AS INTEGER) FROM state WHERE key = 'review.done'\"\n  )\n  const done = Boolean(doneRaw ?? 0)\n\n  return (\n    <Ralph id=\"review\" condition={() => !done} maxIterations={maxIterations}>\n      <ReviewRunner />\n    </Ralph>\n  )\n}\n\nfunction ReviewWorkflow() {\n  return (\n    <SmithersProvider db={db} executionId={executionId}>\n      <ReviewWorkflowInner />\n    </SmithersProvider>\n  )\n}\n\nconst root = createSmithersRoot()\ntry {\n  await root.mount(ReviewWorkflow)\n  db.execution.complete(executionId, { summary: \"Review complete\" })\n} catch (error) {\n  db.execution.fail(executionId, String(error))\n  throw error\n} finally {\n  db.close()\n}\n" },
  { path: "scripts/validate-specs.ts", contents: "import { readdir, readFile, stat } from \"node:fs/promises\"\nimport { join } from \"node:path\"\n\nconst isJson = (name: string) => name.endsWith(\".json\") && !name.endsWith(\".min.json\")\n\nconst isStringArray = (value: unknown): value is string[] =>\n  Array.isArray(value) && value.every((item) => typeof item === \"string\")\n\nconst onlyKeys = (obj: object, keys: string[]) =>\n  Object.keys(obj).every((key) => keys.includes(key))\n\nconst validateSpec = (file: string, obj: Record<string, unknown>, errors: string[]) => {\n  const keys = [\n    \"v\",\n    \"id\",\n    \"title\",\n    \"status\",\n    \"version\",\n    \"lastUpdated\",\n    \"supersedes\",\n    \"dependsOn\",\n    \"goals\",\n    \"nonGoals\",\n    \"req\",\n    \"cfg\",\n    \"accept\",\n    \"assume\"\n  ]\n\n  if (!onlyKeys(obj, keys)) {\n    errors.push(`${file}: unexpected top-level keys`)\n  }\n\n  for (const key of [\"v\", \"id\", \"title\", \"status\", \"version\", \"lastUpdated\", \"goals\", \"nonGoals\", \"req\", \"accept\", \"assume\"]) {\n    if (!(key in obj)) {\n      errors.push(`${file}: missing ${key}`)\n    }\n  }\n\n  if (obj.v !== 1) errors.push(`${file}: v must be 1`)\n  for (const key of [\"id\", \"title\", \"status\", \"version\", \"lastUpdated\"]) {\n    if (typeof obj[key] !== \"string\") errors.push(`${file}: ${key} must be string`)\n  }\n\n  for (const key of [\"supersedes\", \"dependsOn\", \"goals\", \"nonGoals\", \"accept\", \"assume\"]) {\n    const value = obj[key]\n    if (value !== undefined && !isStringArray(value)) {\n      errors.push(`${file}: ${key} must be string[]`)\n    }\n  }\n\n  const req = obj.req\n  if (typeof req !== \"object\" || req === null) {\n    errors.push(`${file}: req must be object`)\n  } else {\n    const reqKeys = [\"api\", \"behavior\", \"obs\"]\n    if (!onlyKeys(req, reqKeys)) errors.push(`${file}: req has unexpected keys`)\n    for (const key of reqKeys) {\n      const value = (req as Record<string, unknown>)[key]\n      if (value === undefined) errors.push(`${file}: req missing ${key}`)\n      else if (!isStringArray(value)) errors.push(`${file}: req.${key} must be string[]`)\n    }\n  }\n\n  const cfg = obj.cfg\n  if (cfg !== undefined) {\n    if (typeof cfg !== \"object\" || cfg === null) {\n      errors.push(`${file}: cfg must be object`)\n    } else {\n      const cfgKeys = [\"env\"]\n      if (!onlyKeys(cfg, cfgKeys)) errors.push(`${file}: cfg has unexpected keys`)\n      const env = (cfg as Record<string, unknown>).env\n      if (env !== undefined && !isStringArray(env)) errors.push(`${file}: cfg.env must be string[]`)\n    }\n  }\n}\n\nconst validateTodo = (file: string, obj: Record<string, unknown>, errors: string[]) => {\n  const keys = [\"v\", \"id\", \"tdd\", \"dod\", \"tasks\"]\n  if (!onlyKeys(obj, keys)) errors.push(`${file}: unexpected top-level keys`)\n  for (const key of keys) {\n    if (!(key in obj)) errors.push(`${file}: missing ${key}`)\n  }\n  if (obj.v !== 1) errors.push(`${file}: v must be 1`)\n  if (typeof obj.id !== \"string\") errors.push(`${file}: id must be string`)\n  if (typeof obj.tdd !== \"boolean\") errors.push(`${file}: tdd must be boolean`)\n  if (!isStringArray(obj.dod)) errors.push(`${file}: dod must be string[]`)\n\n  if (!Array.isArray(obj.tasks)) {\n    errors.push(`${file}: tasks must be array`)\n  } else {\n    for (const [index, task] of obj.tasks.entries()) {\n      if (typeof task !== \"object\" || task === null) {\n        errors.push(`${file}: tasks[${index}] must be object`)\n        continue\n      }\n      const taskKeys = [\"id\", \"do\", \"verify\"]\n      if (!onlyKeys(task, taskKeys)) errors.push(`${file}: tasks[${index}] unexpected keys`)\n      for (const key of taskKeys) {\n        const value = (task as Record<string, unknown>)[key]\n        if (value === undefined) errors.push(`${file}: tasks[${index}] missing ${key}`)\n        else if (typeof value !== \"string\") errors.push(`${file}: tasks[${index}].${key} must be string`)\n      }\n    }\n  }\n}\n\nconst validateDir = async (dir: string) => {\n  const entries = await readdir(dir)\n  const errors: string[] = []\n\n  for (const entry of entries) {\n    const fullPath = join(dir, entry)\n    const info = await stat(fullPath)\n    if (!info.isFile()) continue\n    if (!isJson(entry)) continue\n\n    const raw = await readFile(fullPath, \"utf8\")\n    const json = JSON.parse(raw) as Record<string, unknown>\n    if (entry.endsWith(\".todo.json\")) validateTodo(entry, json, errors)\n    else validateSpec(entry, json, errors)\n  }\n\n  if (errors.length > 0) {\n    console.error(`Schema validation errors:\\n${errors.join(\"\\n\")}`)\n    process.exit(1)\n  }\n\n  console.log(\"All spec/todo JSON files passed schema checks.\")\n}\n\nconst target = process.argv[2] ?? \"specs\"\n\nvalidateDir(target).catch((error) => {\n  console.error(error)\n  process.exit(1)\n})\n" },
  { path: "scripts/minify-specs.ts", contents: "import { readdir, readFile, writeFile, stat } from \"node:fs/promises\"\nimport { join } from \"node:path\"\n\nconst isJson = (name: string) => name.endsWith(\".json\") && !name.endsWith(\".min.json\")\n\nconst minifyFile = async (filePath: string) => {\n  const raw = await readFile(filePath, \"utf8\")\n  const json = JSON.parse(raw)\n  const minPath = filePath.replace(/\\.json$/, \".min.json\")\n  await writeFile(minPath, JSON.stringify(json), \"utf8\")\n}\n\nconst minifyDir = async (dir: string) => {\n  const entries = await readdir(dir)\n  for (const entry of entries) {\n    const fullPath = join(dir, entry)\n    const info = await stat(fullPath)\n    if (!info.isFile()) {\n      continue\n    }\n    if (isJson(entry)) {\n      await minifyFile(fullPath)\n    }\n  }\n}\n\nconst target = process.argv[2] ?? \"specs\"\n\nminifyDir(target)\n  .then(() => {\n    console.log(`Minified JSON in ${target}`)\n  })\n  .catch((error) => {\n    console.error(error)\n    process.exit(1)\n  })\n" },
  { path: "prompts/DEFAULT-IMPLEMENTER.md", contents: "# Default Implementer Prompt\n\nStudy /docs to become familiar with the codebase architecture.\n\nStudy the spec and todo JSON to learn the goal at hand.\n\nLook at recent commits to see what has been done.\n\nPick the most important task from the TODO list for implementation of the spec and implement that. Focus on completion of that task. If you encounter blocking errors, fix them, verify them, commit them, get the task done.\n\nBefore making changes search codebase (don't assume an item is not implemented) using parallel subagents. Think hard.\n\nWrite tests, verify your work builds, run the dev server (you can access the logs) and use chrome dev tools mcp to check the website at the very end, going through the user flow.\n\nImportant: When authoring documentation (ie. ts doc, tests or documentation) capture the why tests and the backing implementation is important.\n\nAfter implementing functionality or resolving problems, run the tests for that unit of code that was improved.\nWhen all tests and verifications pass commit your work. If functionality is missing then it's your job to add it as per the application specifications\n\nUpdate the TODO.md file noting what has been done, attach a screenshot of the UI confirming it's done for frontend changes.\n" },
  { path: "prompts/DEFAULT-REVIEWER.md", contents: "# Default Reviewer Prompt\n\nReview the implementation against the spec and todo. Focus on:\n\n- Correctness and completeness\n- Tests and verification steps\n- Security risks and edge cases\n- Strict spec compliance\n\nConfirm changes were pushed (`jj git push --change @`) when applicable.\n\nReport issues clearly and suggest next steps.\n" },
  { path: "prompts/reviewers/SECURITY.md", contents: "# Security Reviewer\n\nReview for security:\n- Input validation and sanitization\n- Auth/authz correctness\n- Secrets handling\n- OWASP-style issues\n" },
  { path: "prompts/reviewers/CODE-QUALITY.md", contents: "# Code Quality Reviewer\n\nReview for code quality:\n- Clarity and readability\n- Proper naming and structure\n- Avoid overengineering\n- Error handling and edge cases\n" },
  { path: "prompts/reviewers/SIMPLICITY.md", contents: "# Minimal Simplicity Reviewer\n\nReview for minimal, principled simplicity:\n- Prefer simple, boring solutions\n- Avoid unnecessary abstractions\n- Keep APIs small and clear\n" },
  { path: "prompts/reviewers/TEST-COVERAGE.md", contents: "# Test Coverage Reviewer\n\nReview for test completeness:\n- Missing test cases or edge cases\n- Incorrect assumptions in tests\n- Changes that make tests pass for the wrong reason\n" },
  { path: "prompts/reviewers/MAINTAINABILITY.md", contents: "# Maintainability Reviewer\n\nReview for long-term maintainability:\n- Clear separation of concerns\n- Low coupling, high cohesion\n- Consistent patterns\n- Friendly to future engineers\n" },
  { path: "README.md", contents: "# Local Ralph/Wisp Development Environment\n\n**Humans write specs. Agents ship features.**\n\nRun a workforce of isolated coding agents locally. Write a specification, dispatch it to your Ralph fleet, get notified when it ships. Smithers is required.\n\n## The Vision\n\n```\n\n                                                                     \n   Human writes spec  Ralphs implement  Ralphs review      \n                                                                   \n                                 iterate                  \n                                                                    \n                                                                    \n                              \"Feature X shipped\"  Human          \n                                                                     \n\n```\n\nYou stay in the loop for:\n- Writing specifications\n- Answering questions when agents get stuck\n- Receiving \"shipped\" notifications\n\nAgents handle:\n- Implementation\n- Code review (agent-to-agent)\n- Iteration on feedback\n- PR creation\n\n## Architecture\n\n```\n\n  Host Machine                                                    \n   LAOS (Grafana/Loki/Tempo/Prometheus/Sentry/PostHog)      \n     all agents report here                                     \n   Message queue (filesystem)  agents coordinate           \n                                                                 \n   ralph-1 (VM)  Smithers workflow  feat/auth           \n   ralph-2 (VM)  Smithers workflow  feat/dashboard      \n   ralph-3 (VM)  Smithers workflow  fix/api-error       \n                                                                 \n   ralph-review (VM)  reviews reports, sends feedback       \n\n```\n\nEach VM has the repo cloned and works on its own branch. For advanced parallel work, use [Jujutsu (jj)](https://github.com/martinvonz/jj) which handles multiple changes natively.\n\n## Quick Start\n\n### 1. Setup infrastructure\n\n```bash\n# Start LAOS (shared host observability stack)\n# Source of truth: https://github.com/dtechvision/laos\nmkdir -p ~/git\nif [[ -d ~/git/laos/.git ]]; then\n  (cd ~/git/laos && git pull)\nelse\n  git clone https://github.com/dtechvision/laos.git ~/git/laos\nfi\ncd ~/git/laos\ndocker compose up -d\n\n# Optional: create a shared env file so LAOS endpoints get copied into VMs\ncd /path/to/local-isolated-ralph\n./scripts/create-ralph-env.sh\n# Edit ~/.config/ralph/ralph.env and set:\n# macOS (Lima):  LAOS_HOST=host.lima.internal\n# Linux (libvirt): LAOS_HOST=192.168.122.1\n\n# Create VMs (4 implementers + 1 reviewer)\nfor i in 1 2 3 4; do ./scripts/create-ralph.sh ralph-$i 2 4 20; done\n./scripts/create-ralph.sh ralph-review 2 4 20\n\n# Setup base image in one VM, then snapshot for cloning\n./scripts/setup-base-vm.sh  # Run inside VM\n```\n\n### 2. Prepare a task (Spec + TODO)\n\n```bash\n# Use the JSON spec/todo workflow (minified inputs for Smithers)\nbun run scripts/validate-specs.ts\nbun run scripts/minify-specs.ts\n```\n\n### 3. Launch Smithers\n\n```bash\n# Run a Smithers workflow (spec/todo minified JSON)\n./scripts/dispatch.sh --spec specs/010-weekly-summary.min.json ralph-1 specs/010-weekly-summary.min.json\n\n# With local project directory synced to VM\n./scripts/dispatch.sh --spec specs/010-weekly-summary.min.json ralph-1 specs/010-weekly-summary.min.json ~/projects/my-app\n\n# With iteration limit (stops after 20 Smithers iterations)\n./scripts/dispatch.sh --spec specs/010-weekly-summary.min.json ralph-1 specs/010-weekly-summary.min.json ~/projects/my-app 20\n\n# Or start multiple Ralphs on different specs (fleet)\n./scripts/smithers-fleet.sh specs ralph\n```\n\n### 4. Watch and wait\n\n```bash\n# Grafana for logs/traces\nopen http://localhost:3010\n\n# Or attach to a VM session directly\n# limactl shell <vm> or ssh ralph@<ip>\n```\n\nWhen done, Smithers writes `reports/<task>.report.json` per task and exits when all tasks are done.\n\n## Workflows\n\n| Pattern | Use Case | Setup |\n|---------|----------|-------|\n| **Single Ralph** | One feature at a time | 1 VM, feature branch |\n| **Multi-Ralph Fleet** | Parallel features | N VMs, each on own branch |\n| **Multi-Ralph per VM** | Resource constrained | 2-4 Ralphs in 1 VM |\n| **Implementer + Reviewer** | Reduce human review | Agents review each other |\n\nSee **[WORKFLOW.md](./WORKFLOW.md)** for detailed patterns.\n\n## Documentation\n\n| Document | Description |\n|----------|-------------|\n| [QUICKSTART.md](./QUICKSTART.md) | End-to-end tutorial |\n| [WORKFLOW.md](./WORKFLOW.md) | Workflow patterns, multi-agent coordination |\n| [SETUP-MACOS.md](./SETUP-MACOS.md) | macOS setup with Colima |\n| [SETUP-LINUX.md](./SETUP-LINUX.md) | Linux setup with libvirt/QEMU |\n| [dtechvision/laos](https://github.com/dtechvision/laos) | Shared observability stack |\n| [specs/templates/](./specs/templates/) | Spec/TODO JSON templates |\n\n## Scripts\n\n| Script | Purpose |\n|--------|---------|\n| `dispatch.sh` | Send spec/todo to VM and run Smithers workflow (see options below) |\n| `create-ralph.sh` | Create a new Ralph VM |\n| `setup-base-vm.sh` | Install tools inside VM (run once, snapshot) |\n| `smithers-fleet.sh` | Dispatch multiple Smithers workflows |\n| `smithers-spec-runner.tsx` | Default Smithers workflow for spec/todo |\n| `smithers-reviewer.tsx` | Smithers reviewer workflow template |\n| `cleanup-workdirs.sh` | Cleanup old immutable workdirs |\n| `record-human-feedback.sh` | Record human review decision/notes |\n| `list-ralphs.sh` | Show all VMs and status |\n| `cleanup-ralphs.sh` | Delete VMs |\n\n## CLI (Fabrik)\n\nBuild and run the single binary CLI:\n\n```bash\nbun install\nbun run build\n./dist/fabrik flow\n```\n\n### Standalone binary (embedded assets)\n\nThe `fabrik` binary embeds:\n- default prompts + reviewer prompts\n- default Smithers workflows\n- helper scripts (dispatch/cleanup/fleet)\n- docs (README/WORKFLOW/QUICKSTART/specs README)\n\nIf `LOCAL_RALPH_HOME` (or `~/git/local-isolated-ralph`) is missing, `fabrik` writes embedded assets\nto `~/.cache/fabrik/embedded/<hash>/` and runs from there.\n\nCommon commands:\n\n```bash\n# Validate + minify specs in current repo\nfabrik spec validate\nfabrik spec minify\n\n# Dispatch a run (from another repo)\nfabrik run --spec specs/feature.min.json --vm ralph-1\n\n# Run with custom prompts\nfabrik run --spec specs/feature.min.json --vm ralph-1 \\\n  --prompt ./prompts/PROMPT-implementer.md \\\n  --review-prompt ./prompts/PROMPT-reviewer.md\n\n# Run with custom reviewer models + retry cap\nfabrik run --spec specs/feature.min.json --vm ralph-1 \\\n  --review-max 3 \\\n  --review-models ./prompts/reviewer-models.json\n\n# Record human feedback\nfabrik feedback --vm ralph-1 --spec specs/feature.min.json --decision approve --notes \"OK\"\n\n# Fleet\nfabrik fleet --specs-dir specs --vm-prefix ralph\n\n# Docs\nfabrik docs --topic workflow\n\n# Runs\nfabrik runs list --limit 10\nfabrik runs show --id 42\nfabrik runs feedback --id 42 --decision approve --notes \"OK\"\n\n# Observability stack (LAOS)\nfabrik laos up\nfabrik laos status\nfabrik laos logs --follow\nfabrik laos down\n\n# Credentials sync\nfabrik credentials sync --vm ralph-1\n```\n\n`fabrik laos` clones/pulls `https://github.com/dtechvision/laos` with **jj** (or `git` if jj is missing)\ninto `~/.cache/fabrik/laos` and runs `docker compose`.\n\n### Use the CLI from another repo\n\nFrom any repo (e.g. `~/git/<your-repo>`):\n\n```bash\n# Build once (in local-ralph)\ncd ~/git/local-isolated-ralph\nbun install\nbun build src/fabrik/bin.ts --compile --outfile dist/fabrik\n\n# Use from another repo\ncd ~/git/<your-repo>\n~/git/local-isolated-ralph/dist/fabrik spec validate\n~/git/local-isolated-ralph/dist/fabrik spec minify\n~/git/local-isolated-ralph/dist/fabrik run --spec specs/001-foo.min.json --vm ralph-1\n```\n\n### Binary Releases (GitHub)\n\nThe repo ships prebuilt `fabrik` binaries for:\n- macOS ARM64 (`darwin-arm64`)\n- Linux x64 (`linux-x64`)\n- Linux ARM64 (`linux-arm64`)\n\nRelease process:\n\n```bash\ngit tag v0.1.0\ngit push origin v0.1.0\n```\n\nOr trigger the workflow manually with a tag (GitHub Actions UI).\n\nIf your local-ralph repo lives elsewhere, set:\n\n```bash\nexport LOCAL_RALPH_HOME=/path/to/local-isolated-ralph\n```\n\n### Smithers (Required Orchestration + JJ)\n\nSmithers is required. It consumes minified spec/todo JSON and executes tasks with durable state. It always runs an agent reviewer and writes `reports/review.json`, then writes `reports/human-gate.json` to block for human approval. Version control is JJ (colocated Git backend).\n\nDefault models:\n- Claude: `opus`\n- Codex: `gpt-5.2-codex` (reasoning `medium`, sandbox `danger-full-access`)\n\nPROMPT control:\n- Pass `--prompt` to prepend a per-run `PROMPT.md` (implementation instructions).\n- Pass `--review-prompt` to prepend reviewer instructions.\nThese files are prepended before the spec/todo content in Smithers.\nDefaults live in `prompts/DEFAULT-IMPLEMENTER.md` and `prompts/DEFAULT-REVIEWER.md`.\nReview pipeline (default):\n- Security\n- Code Quality\n- Minimal Simplicity\n- Test Coverage\n- Maintainability\n\nReviewer prompts live in `prompts/reviewers/*.md` and are copied into each run.\n\nReviewer model config (optional):\nCreate `reviewer-models.json` to map reviewers to models:\n\n```json\n{\n  \"_default\": \"sonnet\",\n  \"security\": \"sonnet\",\n  \"code-quality\": \"sonnet\",\n  \"simplicity\": \"sonnet\",\n  \"test-coverage\": \"sonnet\",\n  \"maintainability\": \"sonnet\"\n}\n```\n\nBackpressure:\n- If any reviewer requests changes, Smithers generates `reports/review-todo.json`\n  and runs those review tasks only.\n- The review pipeline reruns after review tasks.\n- Only when all reviewers approve does the human gate appear.\n\nRun context audit:\n- Each run writes `reports/run-context.json` with prompt contents + hashes.\n\n```bash\n# Install in VM if missing\n# bun add -g smithers-orchestrator\n\n# Local workflow (uses scripts/smithers-spec-runner.tsx by default)\n./scripts/dispatch.sh --spec specs/000-base.min.json ralph-1 specs/000-base.min.json\n\n# With custom prompts\n./scripts/dispatch.sh --spec specs/000-base.min.json ralph-1 specs/000-base.min.json \\\n  --prompt ./prompts/PROMPT-implementer.md \\\n  --review-prompt ./prompts/PROMPT-reviewer.md\n\n# Custom TODO and workflow\n./scripts/dispatch.sh --spec specs/010-weekly-summary.min.json --todo specs/010-weekly-summary.todo.min.json \\\n  --workflow scripts/smithers-spec-runner.tsx --model sonnet ralph-1 specs/010-weekly-summary.min.json\n\n# Review runs automatically after tasks; Smithers writes reports/review.json and reports/human-gate.json.\n```\n\n### Smithers Workflow Diagram\n\n```\nspec.min.json + todo.min.json\n          \n          \n  Smithers workflow\n  (Ralph loop in React)\n          \n           task 1  report.json\n           task 2  report.json\n           task N  report.json\n          \n          \n     DONE / BLOCKED / FAILED\n```\n\n### Reviewer Template (Standalone)\n\nUse the built-in Smithers reviewer workflow:\n\n```bash\n./scripts/dispatch.sh --spec specs/feature.min.json --workflow scripts/smithers-reviewer.tsx \\\n  ralph-review specs/feature.min.json\n```\n\n### JJ Primer (Required VCS)\n\nJJ uses a colocated Git backend. The repo still has `.git`, but you use `jj` commands.\n\n```\nClone:              jj git clone <url> <dir>\nInit in repo:       jj git init\nStart change:       jj new main\nStatus:             jj status\nDiff:               jj diff\nDescribe change:    jj describe\nPush change:        jj git push --change @\n```\n\n### Changesets + JJ\n\nChangesets stays the same; JJ only replaces Git commands locally:\n\n```bash\n# Create a changeset for your PR\nbunx changeset\n\n# Work in a new JJ change\njj new main\n\n# Review + commit\njj status\njj diff\njj describe\n\n# Push the change\njj git push --change @\n```\n\n### dispatch.sh Options\n\n```bash\n./scripts/dispatch.sh [--include-git] [--spec <path>] [--todo <path>] \\\n  [--workflow <path>] [--report-dir <path>] [--model <name>] \\\n  [--prompt <path>] [--review-prompt <path>] \\\n  <vm-name> <spec-file> [project-dir] [max-iterations]\n\n# Example with .git included (enables push from synced project)\nRALPH_AGENT=codex ./scripts/dispatch.sh --include-git --spec specs/000-base.min.json ralph-1 specs/000-base.min.json ~/projects/app 20\n```\n\n- `--include-git` - Include `.git` in sync (otherwise agent must clone from repo URL)\n- `--spec` - Spec JSON (minified recommended) for Smithers mode\n- `--todo` - TODO JSON (minified recommended) for Smithers mode\n- `--workflow` - Smithers workflow script (default: `scripts/smithers-spec-runner.tsx`)\n- `--report-dir` - Report output directory inside VM (default: workdir/reports)\n- `--model` - Model name for Smithers agent\n- `--prompt` - PROMPT.md prepended to every task prompt\n- `--review-prompt` - Reviewer PROMPT.md prepended to review prompt\n- `--review-max` - Max review reruns before human gate (default: 2)\n- `--review-models` - JSON map of reviewer_id -> model\n- `RALPH_AGENT` - Agent to use: `codex` (default), `claude`, `opencode`\n- `MAX_ITERATIONS` - Max loops (default: 100, 0 = unlimited)\n\nEach dispatch creates a timestamped work directory (`/home/ralph/work/<vm>/<project>-<timestamp>/`), enabling parallel dispatches to the same VM.\n\n## Resource Planning\n\n| Host RAM | Recommended Setup |\n|----------|-------------------|\n| 16GB | 4 light VMs (2 CPU, 4GB each) |\n| 32GB | 8 light VMs or 4 medium VMs |\n| 64GB+ | 8+ medium VMs, or density mode |\n\n**Density mode:** Run 2-4 Ralphs per VM when working on separate directories.\n\n## Credentials Setup\n\nAgents need `GITHUB_TOKEN` to push code and create PRs.\n\n1. Create token: https://github.com/settings/tokens/new (scopes: `repo`, `workflow`)\n2. Add to `~/.config/ralph/ralph.env`:\n   ```bash\n   export GITHUB_TOKEN=\"ghp_your_token_here\"\n   ```\n3. Run `./scripts/create-ralph-env.sh` to create the env file, or `./scripts/sync-credentials.sh <vm>` to update existing VMs\n\nThe token is used by both `git push/pull` (credential helper) and `gh` CLI (auto-detects env var).\n\n## Prerequisites\n\n```bash\n# Docker (for LAOS)\ndocker --version\n\n# SSH key (for VM access)\nls ~/.ssh/id_rsa.pub || ssh-keygen -t rsa -b 4096\n\n# macOS: Colima 0.6+\nbrew install colima docker\n\n# Linux: libvirt + KVM\nsudo apt install qemu-kvm libvirt-daemon-system virtinst\n```\n\n## The Goal\n\n```\nBefore:  Human writes code, human reviews code, human ships\nAfter:   Human writes spec  Human gets \"shipped\" notification\n                           (agents do the rest)\n```\n\n## Disk Usage\n\nDisk usage to watch:\n  - ~/.lima/ - VM disks (20GB+ per VM)\n  - ~/.cache/ralph/ - Downloaded images (~6GB per\n  architecture)\n  - ~/vms/ralph/ - libvirt VM disks on Linux\n\nFor the cloud-hosted version of this, see [Sprites](https://sprites.dev) + [Wisp](https://github.com/thruflo/wisp).\n### Immutable Runs + Local DB\n\nEach Smithers run gets a new workdir. Runs are tracked in a local SQLite DB:\n\n```\n~/.cache/ralph/ralph.db\n```\n\nCleanup old runs:\n\n```bash\n./scripts/cleanup-workdirs.sh ralph-1 --keep 5\n```\n\nRecord human feedback:\n\n```bash\n./scripts/record-human-feedback.sh --vm ralph-1 --spec specs/010-weekly-summary.min.json \\\n  --decision approve --notes \"Looks good.\"\n```\nSpec is explicit:\n- You choose the spec with `--spec`, not inside the prompt.\n\nContext stack now:\n\n```\n[\n  PROMPT.md (global instructions, if provided),\n  spec.json-derived system prompt,\n  task.do / task.verify,\n  JJ instructions,\n  report schema\n]\n```\n\nReviewer stack:\n\n```\n[\n  REVIEW_PROMPT.md (if provided),\n  reviewer-specific prompt (from prompts/reviewers/*.md),\n  spec.json-derived system prompt,\n  reports/*.report.json,\n  review schema\n]\n```\n" },
  { path: "WORKFLOW.md", contents: "# Ralph Workflow Guide\n\nSmithers is required; the legacy bash loop is not used.\n\nHow to run single and multi-Ralph setups efficiently.\n\n## Smithers Full-Orchestration Mode (Required)\n\nSmithers replaces the bash loop inside each VM. The host still handles VM lifecycle and sync, but Smithers runs the plan. The legacy bash loop is no longer used. JJ is the required VCS (colocated Git backend).\n\n## Prompt Control\n\nProvide per-run instructions with `PROMPT.md` and reviewer instructions with `REVIEW_PROMPT.md`:\n\n```bash\n./scripts/dispatch.sh --spec specs/feature.min.json ralph-1 specs/feature.min.json \\\n  --prompt ./prompts/PROMPT-implementer.md \\\n  --review-prompt ./prompts/PROMPT-reviewer.md\n```\n\n## JJ Primer (Required)\n\n```\nClone:              jj git clone <url> <dir>\nInit in repo:       jj git init\nStart change:       jj new main\nStatus:             jj status\nDiff:               jj diff\nDescribe change:    jj describe\nPush change:        jj git push --change @\n```\n\n```\nHost dispatch.sh\n     \n     \nVM workdir (spec.min.json + todo.min.json + workflow.tsx)\n     \n     \nsmithers workflow.tsx\n   runs tasks sequentially or in parallel\n   writes reports/<task>.report.json\n   persists state in .smithers/*.db\n```\n\nRecommended when you want durable, inspectable multi-step plans with deterministic replay.\n\n## Git Strategies for Parallel Work\n\n### Single Ralph: Feature Branches\n\nOne Ralph, one branch, simple:\n\n```bash\n# Ralph works on a feature branch\ngit checkout -b feat/user-auth\n# ... Ralph implements ...\ngit push -u origin feat/user-auth\ngh pr create\n```\n\n### Multi-Ralph: Separate VMs, Separate Branches\n\nEach VM clones the repo and works on its own branch:\n\n```bash\n# In ralph-1 VM:\ngit clone git@github.com:org/repo.git\ncd repo\ngit checkout -b feat/auth\n# ... Ralph implements ...\n\n# In ralph-2 VM:\ngit clone git@github.com:org/repo.git\ncd repo\ngit checkout -b feat/dashboard\n# ... Ralph implements ...\n```\n\nEach Ralph pushes to its own branch  creates its own PR. Simple.\n\n### Multi-Ralph: Jujutsu (jj) - Advanced Parallel Work\n\n[Jujutsu](https://github.com/martinvonz/jj) handles parallel changes natively (no worktrees needed):\n\n```bash\n# Initialize or clone\njj git clone git@github.com:org/repo.git\ncd repo\n\n# Create changes for each Ralph (no explicit branches needed)\njj new main -m \"feat: user auth\"      # Creates change A\njj new main -m \"feat: dashboard\"      # Creates change B\njj new main -m \"fix: api error\"       # Creates change C\n\n# Each Ralph works on a different change\n# jj handles rebasing automatically when main updates\n```\n\n**Benefits:**\n- No branch name juggling\n- Automatic rebasing when main updates\n- First-class parallel changes in a single working directory\n- Easier to squash/reorganize before PR\n\n### Multi-Ralph: Same Spec, Different Tasks (jj)\n\nMultiple Ralphs can work on ONE large spec, each picking different tasks:\n\n```bash\n# One spec with multiple tasks\n# specs/big-feature.md:\n#   - Task 1: Add user model\n#   - Task 2: Add auth endpoints\n#   - Task 3: Add tests\n#   - Task 4: Add documentation\n\n# All Ralphs start from main, work on different tasks\njj new main -m \"task-1: user model\"     # Ralph-1 picks this\njj new main -m \"task-2: auth endpoints\" # Ralph-2 picks this\njj new main -m \"task-3: tests\"          # Ralph-3 picks this\njj new main -m \"task-4: docs\"           # Ralph-4 picks this\n\n# jj automatically handles when tasks touch same files\n# Conflicts surface immediately, agents can coordinate\n```\n\n**How it works:**\n1. Orchestrator parses spec, creates jj changes for each task\n2. Each Ralph gets assigned a change to work on\n3. Ralphs commit to their change as they work\n4. jj auto-rebases when main updates or other changes land\n5. When all tasks done, squash or merge as needed\n\n```bash\n# After all Ralphs complete, combine changes\njj rebase -s task-1 -d main\njj rebase -s task-2 -d task-1\njj rebase -s task-3 -d task-2\njj rebase -s task-4 -d task-3\n\n# Or keep parallel and merge all at once\njj git push --all\n# Create PR that includes all changes\n```\n\n**Conflict handling:**\n- jj shows conflicts immediately (even uncommitted)\n- Ralphs can see \"task-2 conflicts with your changes\"\n- Orchestrator can pause one Ralph while another resolves\n- Or let both continue and resolve conflicts at merge time\n\n---\n\n## Shared Spec Workflow (Swarm on One Feature)\n\nMultiple Ralphs work on the same large feature, each owning a task:\n\n```\n\n  specs/big-feature.md                                           \n   Task 1: Add user model (Ralph-1)                          \n   Task 2: Add auth endpoints (Ralph-2)                       \n   Task 3: Add tests (Ralph-3)                                \n   Task 4: Add documentation (Ralph-4)                        \n\n                             \n                    jj new main (4)\n                             \n         \n                                              \n          \n     Ralph-1   Ralph-2      Ralph-3   Ralph-4 \n     task-1    task-2       task-3    task-4  \n     model     api          tests     docs    \n          \n                                              \n         \n                             \n                    jj squash / merge\n                             \n                             \n                    \n                      Single PR      \n                      \"Big Feature\"  \n                    \n```\n\n### Setup\n\n```bash\n# 1. Write your spec with clear task breakdown\ncat > specs/big-feature.md << 'EOF'\n# Big Feature Spec\n\n## Overview\nAdd complete user authentication system.\n\n## Tasks\n\n### Task 1: User Model\n- Add User entity with email, password hash, created_at\n- Add migration\n- Files: src/models/user.ts, src/db/migrations/\n\n### Task 2: Auth Endpoints\n- POST /auth/register\n- POST /auth/login\n- POST /auth/refresh\n- Files: src/routes/auth.ts, src/services/auth.ts\n\n### Task 3: Tests\n- Unit tests for auth service\n- Integration tests for endpoints\n- Files: tests/\n\n### Task 4: Documentation\n- API docs for auth endpoints\n- README updates\n- Files: docs/, README.md\nEOF\n\n# 2. Create jj changes for each task\ncd ~/projects/myapp\njj new main -m \"task-1: user model\"\njj new main -m \"task-2: auth endpoints\"\njj new main -m \"task-3: tests\"\njj new main -m \"task-4: documentation\"\n\n# 3. Prepare spec/todo JSON for each task\n#    (store in specs/, then validate + minify)\nbun run scripts/validate-specs.ts\nbun run scripts/minify-specs.ts\n\n# 4. Launch swarm (fleet)\n./scripts/smithers-fleet.sh specs ralph\n```\n\n### Dependency Handling\n\nTasks often depend on each other. Handle this with jj stacking:\n\n```bash\n# Task 2 depends on Task 1? Stack them:\njj rebase -s task-2 -d task-1\n\n# Now task-2 sees task-1's changes\n# Ralph-2 can continue working\n\n# When task-1 updates, task-2 auto-rebases\n```\n\n### Merging Results\n\n```bash\n# Option A: Linear history (rebase chain)\njj rebase -s task-1 -d main\njj rebase -s task-2 -d task-1\njj rebase -s task-3 -d task-2\njj rebase -s task-4 -d task-3\n\n# Option B: Merge commit (parallel history)\njj new task-1 task-2 task-3 task-4 -m \"feat: big feature complete\"\n\n# Push and create PR\njj git push -c @\ngh pr create --title \"Big Feature\" --body \"Implements auth system\"\n```\n\n---\n\n## Single Ralph Workflow (Smithers Required)\n\n```\n\n  Human writes spec + todo            \n   specs/feature-x.json/.todo.json \n\n                   \n\n  Ralph implements                    \n   Commits to feat/feature-x      \n   Creates PR when done            \n\n                   \n\n  Human reviews reports               \n   Approves or requests changes    \n\n                   \n\n  Merge & ship                        \n   Human gets \"shipped\" notice     \n\n```\n\n### Setup\n\n```bash\n# Create VM\n./scripts/create-ralph.sh ralph-1\n\n# Prepare spec + todo\ncp specs/templates/spec.json specs/feature-x.json\ncp specs/templates/todo.json specs/feature-x.todo.json\n# Edit both files, then validate + minify\nbun run scripts/validate-specs.ts\nbun run scripts/minify-specs.ts\n\n# Start Smithers workflow\n./scripts/dispatch.sh --spec specs/feature-x.min.json ralph-1 specs/feature-x.min.json\n\n# Watch\ntmux attach -t ralph-1\n```\n\n---\n\n## Multi-Ralph Parallel Workflow (Smithers Required)\n\n```\n\n  Human writes specs + todos                                \n   specs/auth.json, specs/dashboard.json, specs/api.json \n\n                             \n\n  Ralph-1      Ralph-2      Ralph-3      Ralph-4        \n  (VM)         (VM)         (VM)         (VM)           \n  feat/auth    feat/dash    fix/api      feat/notifs    \n\n                                                \n                                                \n\n  4 PRs created in parallel                               \n\n```\n\n### Setup\n\n```bash\n# Prepare specs + todos\ncp specs/templates/spec.json specs/auth.json\ncp specs/templates/todo.json specs/auth.todo.json\ncp specs/templates/spec.json specs/dashboard.json\ncp specs/templates/todo.json specs/dashboard.todo.json\ncp specs/templates/spec.json specs/api-fix.json\ncp specs/templates/todo.json specs/api-fix.todo.json\n\n# Edit files, then validate + minify\nbun run scripts/validate-specs.ts\nbun run scripts/minify-specs.ts\n\n# Create VMs\nfor i in 1 2 3; do\n  ./scripts/create-ralph.sh ralph-$i 2 4 20\ndone\n\n# Start fleet (fleet)\n./scripts/smithers-fleet.sh specs ralph\n\n# Monitor via logs/LAOS or VM tmux if you start a local session\n```\n\n---\n\n## Multi-Agent Coordination (Implementer + Reviewer)\n\nReviewer agents provide code quality, security, and spec-compliance feedback. After review, a human approves before the next spec run.\n\nRuns are immutable: every dispatch creates a new workdir. Track runs in `~/.cache/ralph/ralph.db` and clean old workdirs when needed.\n\n```\n\n  Human writes spec                                              \n\n                                \n\n  Implementer Smithers                                           \n   Implements feature                                         \n   Writes reports/<task>.report.json                          \n\n                                \n                    \n                      Reports Directory    \n                      reports/*.json       \n                    \n                                \n\n  Reviewer Smithers                                              \n   Reviews code vs spec + reports                             \n   Writes reports/review.json                                 \n\n                                \n                    \n                      Feedback loops back  \n                      to Implementer       \n                    \n                                \n\n  Human                                                         \n   Reviews reports/review.json                                \n   Approves or updates spec/todo                              \n   Starts next spec run                                       \n\n                                \n\n  Human gets notified: \"Feature X shipped\"                       \n   Only intervenes for spec questions                         \n\n```\n\n### Setup\n\n```bash\n# Create implementer VM\n./scripts/create-ralph.sh ralph-impl 4 6 30\n\n# Create reviewer VM\n./scripts/create-ralph.sh ralph-review 2 4 20\n\n# Start reviewer workflow (Smithers)\n./scripts/dispatch.sh --spec specs/reviewer.min.json --workflow scripts/smithers-reviewer.tsx ralph-review specs/reviewer.min.json\n\n# Review runs automatically after tasks in scripts/smithers-spec-runner.tsx.\n```\n\n### Review Output\n\n**Reviewer Output:**\n```json\n// reports/review.json\n{\n  \"v\": 1,\n  \"status\": \"approved\",\n  \"issues\": [],\n  \"next\": []\n}\n```\n\n**Human Gate:**\n```json\n// reports/human-gate.json\n{\n  \"v\": 1,\n  \"status\": \"blocked\",\n  \"reason\": \"Human review required before next spec run.\"\n}\n```\n\n**Record Human Feedback (host):**\n```bash\n./scripts/record-human-feedback.sh --vm ralph-1 --spec specs/feature-x.min.json \\\n  --decision approve --notes \"Spec satisfied.\"\n```\n\n---\n\n## Human Touchpoints\n\nWith this setup, humans only need to:\n\n| Action | When |\n|--------|------|\n| **Write specs** | Start of feature |\n| **Answer questions** | When a task report or human gate is `blocked` |\n| **Final merge approval** | After review.json and human approval |\n| **Receive shipped notification** | Feature complete |\n\nThe goal: **Humans write specs, agents ship features.**\n\n---\n\n## Directory Structure\n\n```\n~/\n specs/                        # Spec + TODO JSON (on host)\n    auth.json\n    auth.todo.json\n    auth.min.json\n    auth.todo.min.json\n    ...\n\n vms/                          # VM storage (Linux only)\n     wisp/\n```\n\nInside each VM:\n```\n~/\n repo/                         # Cloned repository\n    (working on feature branch)\n specs/                        # Copied from host\n reports/                      # task reports\n .smithers/                    # SQLite state\n```\n\n---\n\n## Quick Commands\n\n```bash\n# Single Ralph\n./scripts/dispatch.sh --spec specs/feature.min.json ralph-1 specs/feature.min.json\n\n# Multi-Ralph (fleet)\n./scripts/smithers-fleet.sh specs ralph\n\n# Multi-Ralph in single VM (density mode)\n./scripts/dispatch.sh --spec specs/auth.min.json ralph-1 specs/auth.min.json\n./scripts/dispatch.sh --spec specs/dashboard.min.json ralph-1 specs/dashboard.min.json\n\n# List all Ralphs\n./scripts/list-ralphs.sh\n\n# Cleanup\n./scripts/cleanup-ralphs.sh --all\n```\n" },
  { path: "QUICKSTART.md", contents: "# Quickstart: Your First Ralph Agent\n\nThis guide walks you through setting up and running your first autonomous coding agent in about 15 minutes.\n\n## Prerequisites Checklist\n\nBefore starting, ensure you have:\n\n- [ ] **macOS 13+** (Ventura) or **Linux** with KVM support\n- [ ] **Docker** installed and running\n- [ ] **SSH key** generated (`ls ~/.ssh/id_*.pub`)\n- [ ] **Claude subscription** with Claude Code CLI authenticated (`claude auth login` on host)\n\n**macOS specific:**\n```bash\nbrew install colima docker\ncolima version  # Should be 0.6.0+\n```\n\n**Linux specific:**\n```bash\nsudo apt install qemu-kvm libvirt-daemon-system virtinst cloud-image-utils\nvirsh list --all  # Should work without errors\n```\n\n---\n\n## Step 1: Start LAOS (Optional but Recommended)\n\nThe LAOS stack lets you monitor your agent's progress in Grafana, plus Sentry/PostHog.\n\n```bash\n# Source of truth: https://github.com/dtechvision/laos\nmkdir -p ~/git\nif [[ -d ~/git/laos/.git ]]; then\n  (cd ~/git/laos && git pull)\nelse\n  git clone https://github.com/dtechvision/laos.git ~/git/laos\nfi\ncd ~/git/laos\ndocker compose up -d\n\n# Verify it's running\ncurl http://localhost:3010/api/health  # Grafana\n```\n\nOpen http://localhost:3010 (login: admin/admin) to see dashboards.\n\nOptional: create a shared env file so LAOS endpoints get copied into VMs:\n\n```bash\ncd /path/to/local-isolated-ralph\n./scripts/create-ralph-env.sh\n# Edit ~/.config/ralph/ralph.env and set:\n# macOS (Lima):  LAOS_HOST=host.lima.internal\n# Linux (libvirt): LAOS_HOST=192.168.122.1\n```\n\n---\n\n## Step 2: Authenticate Claude on Your Host\n\nIf you haven't already, authenticate Claude Code on your host machine:\n\n```bash\nclaude auth login\n```\n\nThis creates `~/.claude` which will be copied to your VMs.\n\n---\n\n## Step 3: Set Up GitHub Token\n\nCreate a token at https://github.com/settings/tokens/new (scopes: `repo`, `workflow`) and add to `~/.config/ralph/ralph.env`:\n\n```bash\n./scripts/create-ralph-env.sh\n# Edit the file and add: export GITHUB_TOKEN=\"ghp_your_token\"\n```\n\n---\n\n## Step 4: Create Your First Ralph VM\n\n```bash\ncd /path/to/local-isolated-ralph\n\n# Create a VM (this takes ~1-2 minutes)\n./scripts/create-ralph.sh ralph-1\n\n# The script will:\n# - Create a VM with 4 CPU, 6GB RAM, 30GB disk\n# - Copy your ~/.claude auth folder to the VM\n# - Install Smithers (required)\n# - Copy ~/.config/ralph/ralph.env (with GITHUB_TOKEN)\n```\n\n---\n\n## Step 5: Set Up the VM\n\nSSH into the VM and run the setup script:\n\n**macOS:**\n```bash\ncolima ssh -p ralph-1\n\n# Inside VM:\ncurl -fsSL https://raw.githubusercontent.com/your-org/local-isolated-ralph/main/scripts/setup-base-vm.sh | bash\n# Or if you have the repo mounted:\n# bash /path/to/scripts/setup-base-vm.sh\n```\n\n**Linux:**\n```bash\n# Get VM IP\nVM_IP=$(virsh domifaddr ralph-1 | grep ipv4 | awk '{print $4}' | cut -d/ -f1)\nssh dev@$VM_IP\n\n# Inside VM:\ncurl -fsSL https://raw.githubusercontent.com/your-org/local-isolated-ralph/main/scripts/setup-base-vm.sh | bash\n```\n\nThe setup script installs Node.js, Claude CLI, GitHub CLI, Playwright, and more.\n\n**Configure git identity:**\n```bash\ngit config --global user.name \"Your Name\"\ngit config --global user.email \"your@email.com\"\n```\n\n**Verify Claude auth works:**\n```bash\nclaude --version\n# Should show version without auth errors\n```\n\n**Install Smithers (required):**\n```bash\nbun add -g smithers-orchestrator\n```\n\n**Verify JJ is available (required):**\n```bash\njj --version\n```\n\nExit the VM when done: `exit`\n\nIf you need to re-sync credentials later:\n\n```bash\n./scripts/sync-credentials.sh ralph-1\n# Or via CLI\nfabrik credentials sync --vm ralph-1\n```\n\nTo store a Claude Code token for syncing:\n\n```bash\n./scripts/create-ralph-env.sh\n# Edit ~/.config/ralph/ralph.env and set:\n# export CLAUDE_CODE_OAUTH_TOKEN=\"...\"\n```\n\nNote: Claude CLI auth is stored in `~/.claude.json` on the host. Make sure it exists (or set `ANTHROPIC_API_KEY` in `ralph.env`) before syncing.\n\n---\n\n## Step 6: Write Your First Spec\n\nCreate a JSON spec and TODO, then minify:\n\n```bash\n# Use templates as a starting point\ncp specs/templates/spec.json specs/001-hello-world.json\ncp specs/templates/todo.json specs/001-hello-world.todo.json\n\n# Edit both files, then validate + minify\nbun run scripts/validate-specs.ts\nbun run scripts/minify-specs.ts\n```\n\n---\n\n## Step 7: Run Smithers\n\n**Use the dispatch script (runs from host)**\n\n```bash\n# Smithers mode (spec/todo minified JSON)\n./scripts/dispatch.sh --spec specs/001-hello-world.min.json ralph-1 specs/001-hello-world.min.json\n\n# Sync a local project directory to the VM\n./scripts/dispatch.sh --spec specs/001-hello-world.min.json ralph-1 specs/001-hello-world.min.json ~/projects/my-app\n\n# Limit iterations (stops after 20 Smithers iterations)\n./scripts/dispatch.sh --spec specs/001-hello-world.min.json ralph-1 specs/001-hello-world.min.json ~/projects/my-app 20\n\n# Or use environment variable\nMAX_ITERATIONS=10 ./scripts/dispatch.sh --spec specs/001-hello-world.min.json ralph-1 specs/001-hello-world.min.json\n```\n\n**Smithers loop at a glance:**\n```\nspec.min.json + todo.min.json  smithers workflow  report.json (per task)\n```\n\n---\n\n## Step 8: Watch and Wait\n\nThe workflow will:\n1. Read `spec.min.json` + `todo.min.json`\n2. Implement tasks in order\n3. Write `reports/<task>.report.json` per task\n4. Run an agent reviewer\n5. Write `reports/review.json` and `reports/human-gate.json`\n6. Stop for human review\n\n**Monitor progress:**\n\n- Watch the terminal output directly\n- Or check Grafana at http://localhost:3010 for logs\n- Check iteration status: `cat ~/work/state/status`\n\n**Human review gate:**\n\nAfter the reviewer runs, `reports/human-gate.json` is written with `status: \"blocked\"`.\nHuman approves, then starts the next spec run.\n\n**Custom prompts:**\n\n```bash\n./scripts/dispatch.sh --spec specs/001-hello-world.min.json ralph-1 specs/001-hello-world.min.json \\\n  --prompt ./prompts/PROMPT-implementer.md \\\n  --review-prompt ./prompts/PROMPT-reviewer.md\n```\n\nRecord feedback:\n\n```bash\n./scripts/record-human-feedback.sh --vm ralph-1 --spec specs/001-hello-world.min.json \\\n  --decision approve --notes \"Matches spec.\"\n```\n\n**Immutable runs:**\n\nEach run gets a new workdir and is tracked in `~/.cache/ralph/ralph.db`.\n\n---\n\n## Step 9: Cleanup\n\nWhen done, you can stop or delete the VM:\n\n**macOS:**\n```bash\ncolima stop -p ralph-1     # Stop (preserves state)\ncolima delete -p ralph-1   # Delete completely\n```\n\nCleanup old workdirs:\n\n```bash\n./scripts/cleanup-workdirs.sh ralph-1 --keep 5\n```\n\n**Linux:**\n```bash\nvirsh shutdown ralph-1                              # Stop\nvirsh destroy ralph-1; virsh undefine ralph-1 --remove-all-storage  # Delete\n```\n\n---\n\n## Next Steps\n\n- **Run multiple Ralphs**: See [WORKFLOW.md](./WORKFLOW.md) for fleet patterns\n- **Create a VM template**: Set up once, snapshot, clone quickly\n- **Use Jujutsu (jj)**: For advanced parallel work on the same repo\n- **Set up Implementer + Reviewer**: Agents review each other's code\n\n---\n\n## Quick Reference\n\n| Task | macOS | Linux |\n|------|-------|-------|\n| Create VM | `./scripts/create-ralph.sh ralph-1` | Same |\n| SSH into VM | `colima ssh -p ralph-1` | `ssh dev@<IP>` |\n| Get VM IP | N/A (use colima ssh) | `virsh domifaddr ralph-1` |\n| Stop VM | `colima stop -p ralph-1` | `virsh shutdown ralph-1` |\n| Delete VM | `colima delete -p ralph-1` | `virsh undefine ralph-1 --remove-all-storage` |\n| List VMs | `colima list` | `virsh list --all` |\n\n---\n\n## Troubleshooting\n\n### VM creation fails\n\n**macOS**: Try falling back to QEMU:\n```bash\ncolima start -p ralph-1 --vm-type qemu --cpu 4 --memory 6\n```\n\n**Linux**: Check KVM is enabled:\n```bash\nlscpu | grep Virtualization  # Should show VT-x or AMD-V\n```\n\n### Claude auth not working in VM\n\nRe-copy the auth folder:\n```bash\n# macOS\ntar -C ~ -cf - .claude | colima ssh -p ralph-1 -- tar -C ~ -xf -\n\n# Linux\nscp -r ~/.claude dev@<VM_IP>:~/\n```\n\n### Agent loops forever\n\n- Check `~/work/state/status` for current state\n- The workflow stops when all tasks are done or when a task is blocked/failed\n- Set `MAX_ITERATIONS=10` to limit loops during testing\n\n### Can't reach LAOS from VM\n\n**macOS**: Use `host.lima.internal`\n**Linux**: Use `192.168.122.1` (libvirt default gateway)\n\nTest from inside VM:\n```bash\ncurl http://host.lima.internal:3010/api/health   # macOS\ncurl http://192.168.122.1:3010/api/health        # Linux\n```\n" },
  { path: "specs/README.md", contents: "# Specs Workflow (Human Guide)\n\nThis repo follows a strict, test-driven flow for all features.\n\n## Flow\n1) **Interview  Spec**\n   - A human prompts an interview agent.\n   - Agent drafts `spec.json`.\n   - Human reviews and edits `spec.json`.\n\n2) **Spec  TODO**\n   - Agent generates `todo.json` from the approved spec.\n\n3) **TODO  Implementation (Smithers)**\n   - Smithers runs tasks in order with tests first.\n   - Emit `report.json` per task.\n\n4) **Manual Review Checkpoints**\n   - Review after each spec before proceeding to the next.\n\n## Diagram\n\n```\nInterview  spec.json  todo.json  Smithers workflow  report.json\n                       (minify)      (tasks, TDD, DOD)   (per task)\n```\n\n## Files\n- Specs (human): `specs/*.json`\n- Specs (Smithers input): `specs/*.min.json`\n- TODOs (human): `specs/*.todo.json`\n- TODOs (Smithers input): `specs/*.todo.min.json`\n\n## Minified Inputs (Smithers)\n- Humans generate minified JSON for token-efficient runs.\n- Smithers consumes `*.min.json` and does **not** regenerate them.\n\nGenerate minified files:\n\n```bash\nbun run scripts/minify-specs.ts\n```\n\n## Testing Requirements\n- TDD is mandatory.\n- Use `@effect/vitest` and Effect DI for external services.\n- Definition of Done: `bun test`, `bun run typecheck`.\n\n## Start Here\n- Read `specs/000-base.json` and `specs/000-base.todo.json`.\n- Implement in order, with tests first.\n" }
]
